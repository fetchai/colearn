{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the Fetch.ai Collective Learning Library \u00b6 Colearn is a library that enables privacy-preserving decentralized machine learning tasks on the FET network. This blockchain-mediated collective learning system enables multiple stakeholders to build a shared machine learning model without needing to rely on a central authority, and without revealing their dataset to the other stakeholders. This library is currently in development. How collective learning works \u00b6 A group of learners comes together, each of whom have their own datasets and want to collaborate on training a machine learning model over a set number of rounds. We refer to this as an 'experiment'. In each round of collective learning: One learner is selected to train the model and propose a new set of model weights. The other learners vote on whether the weights are an improvement. If the majority vote that the new weights are better than the old ones then the new weights are accepted by all the learners. Otherwise the new weights are discarded. The next round begins. For more information on the Collective Learning Protocol see here . Current Version \u00b6 We have released v.0.2.8 of the Colearn Machine Learning Interface, the first version of an interface that allows developers to define their own model architectures that can then be used in collective learning. Together with the interface we provide a simple backend for local experiments. This is a prototype backend with upcoming blockchain ledger based backends to follow. Future releases will use similar interfaces so that learners built with the current system will work on a different backend that integrates a distributed ledger and provides other improvements. The current framework will then be used mainly for model development and debugging. We invite all users to experiment with the framework, develop their own models, and provide feedback! Getting Started \u00b6 To use the latest stable release we recommend installing the package from PyPi To install with support for Keras and Pytorch: pip install colearn [ all ] To install with just support for Keras or Pytorch: pip install colearn [ keras ] pip install colearn [ pytorch ] For more installation options or get the latest (development) version see Installation Then run the standalone demo: python -m colearn_examples.ml_interface.run_demo For plenty of other examples see the Examples . Writing your own models \u00b6 We encourage users to try out the system by writing their own models. Models need to implement the collective learning interface, which provides functions for training and voting on updates. More instructions can be found in the Getting Started section.","title":"Colearn"},{"location":"#welcome-to-the-fetchai-collective-learning-library","text":"Colearn is a library that enables privacy-preserving decentralized machine learning tasks on the FET network. This blockchain-mediated collective learning system enables multiple stakeholders to build a shared machine learning model without needing to rely on a central authority, and without revealing their dataset to the other stakeholders. This library is currently in development.","title":"Welcome to the Fetch.ai Collective Learning Library"},{"location":"#how-collective-learning-works","text":"A group of learners comes together, each of whom have their own datasets and want to collaborate on training a machine learning model over a set number of rounds. We refer to this as an 'experiment'. In each round of collective learning: One learner is selected to train the model and propose a new set of model weights. The other learners vote on whether the weights are an improvement. If the majority vote that the new weights are better than the old ones then the new weights are accepted by all the learners. Otherwise the new weights are discarded. The next round begins. For more information on the Collective Learning Protocol see here .","title":"How collective learning works"},{"location":"#current-version","text":"We have released v.0.2.8 of the Colearn Machine Learning Interface, the first version of an interface that allows developers to define their own model architectures that can then be used in collective learning. Together with the interface we provide a simple backend for local experiments. This is a prototype backend with upcoming blockchain ledger based backends to follow. Future releases will use similar interfaces so that learners built with the current system will work on a different backend that integrates a distributed ledger and provides other improvements. The current framework will then be used mainly for model development and debugging. We invite all users to experiment with the framework, develop their own models, and provide feedback!","title":"Current Version"},{"location":"#getting-started","text":"To use the latest stable release we recommend installing the package from PyPi To install with support for Keras and Pytorch: pip install colearn [ all ] To install with just support for Keras or Pytorch: pip install colearn [ keras ] pip install colearn [ pytorch ] For more installation options or get the latest (development) version see Installation Then run the standalone demo: python -m colearn_examples.ml_interface.run_demo For plenty of other examples see the Examples .","title":"Getting Started"},{"location":"#writing-your-own-models","text":"We encourage users to try out the system by writing their own models. Models need to implement the collective learning interface, which provides functions for training and voting on updates. More instructions can be found in the Getting Started section.","title":"Writing your own models"},{"location":"about/","text":"How collective learning works \u00b6 A Colearn experiment begins when a group of entities, referred to as learners , decide on a model architecture and begin learning. Together they will train a single global model. The goal is to train a model that performs better than any of the learners can produce by training on their private data set. How Training Works \u00b6 Training occurs in rounds; during each round the learners attempt to improve the performance of the global shared model. To do so each round an update of the global model (for example new set of weights in a neural network) is proposed. The learners then validate the update and decide if the new model is better than the current global model. If enough learners approve the update then the global model is updated. After an update is approved or rejected a new round begins. The detailed steps of a round updating a global model M are as follows: One of the learners is selected and proposes a new updated model M' The rest of the learners validate M' If M' has better performance than M against their private data set then the learner votes to approve If not, the learner votes to reject The total votes are tallied If more than some threshold (typically 50%) of learners approve then M' becomes the new global model. If not, M continues to be the global model A new round begins. By using a decentralized ledger (a blockchain) this learning process can be run in a completely decentralized, secure and auditable way. Further security can be provided by using differential privacy to avoid exposing your private data set when generating an update. Learning algorithms that work for collective learning \u00b6 Collective learning is not just for neural networks; any learning algorithm that can be trained on subsets of the data and which can use the results of previous training rounds as the basis for subsequent rounds can be used. Neural networks fit both these constraints: training can be done on mini-batches of data and each training step uses the weights of the previous training step as its starting point. More generally, any model that is trained using mini-batch stochastic gradient descent is fine. Other algorithms can be made to work with collective learning as well. For example, a random forest can be trained iteratively by having each learner add new trees (see example in mli_random_forest_iris.py ). For more discussion, see here . The driver \u00b6 The driver implements the voting protocol, so it handles selecting a learner to train, sending the update out for voting, calculating the vote and accepting or declining the update. Here we have a very minimal driver that doesn't use networking or a blockchain. Eventually the driver will be a smart contract. This is the code that implements one round of voting: def run_one_round ( round_index : int , learners : Sequence [ MachineLearningInterface ], vote_threshold = 0.5 ): proposer = round_index % len ( learners ) new_weights = learners [ proposer ] . mli_propose_weights () prop_weights_list = [ ln . mli_test_weights ( new_weights ) for ln in learners ] approves = sum ( 1 if v . vote else 0 for v in prop_weights_list ) vote = False if approves >= len ( learners ) * vote_threshold : vote = True for j , learner in enumerate ( learners ): learner . mli_accept_weights ( prop_weights_list [ j ]) return prop_weights_list , vote The driver has a list of learners, and each round it selects one learner to be the proposer. The proposer does some training and proposes an updated set of weights. The driver then sends the proposed weights to each of the learners, and they each vote on whether this is an improvement. If the number of approving votes is greater than the vote threshold the proposed weights are accepted, and if not they're rejected. The Machine Learning Interface \u00b6 # ------------------------------------------------------------------------------ # # Copyright 2021 Fetch.AI Limited # # Licensed under the Creative Commons Attribution-NonCommercial International # License, Version 4.0 (the \"License\"); you may not use this file except in # compliance with the License. You may obtain a copy of the License at # # http://creativecommons.org/licenses/by-nc/4.0/legalcode # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # ------------------------------------------------------------------------------ import abc from enum import Enum from typing import Any , Optional import onnx import onnxmltools import sklearn import tensorflow as tf import torch from pydantic import BaseModel from tensorflow import keras model_classes_keras = ( tf . keras . Model , keras . Model , tf . estimator . Estimator ) model_classes_scipy = ( torch . nn . Module ) model_classes_sklearn = ( sklearn . base . ClassifierMixin ) def convert_model_to_onnx ( model : Any ): \"\"\" Helper function to convert a ML model to onnx format \"\"\" if isinstance ( model , model_classes_keras ): return onnxmltools . convert_keras ( model ) if isinstance ( model , model_classes_sklearn ): return onnxmltools . convert_sklearn ( model ) if 'xgboost' in model . __repr__ (): return onnxmltools . convert_sklearn ( model ) if isinstance ( model , model_classes_scipy ): raise Exception ( \"Pytorch models not yet supported to onnx\" ) else : raise Exception ( \"Attempt to convert unsupported model to onnx: {model} \" ) class DiffPrivBudget ( BaseModel ): target_epsilon : float target_delta : float consumed_epsilon : float consumed_delta : float class ErrorCodes ( Enum ): DP_BUDGET_EXCEEDED = 1 class TrainingSummary ( BaseModel ): dp_budget : Optional [ DiffPrivBudget ] error_code : Optional [ ErrorCodes ] class Weights ( BaseModel ): weights : Any training_summary : Optional [ TrainingSummary ] class DiffPrivConfig ( BaseModel ): target_epsilon : float target_delta : float max_grad_norm : float noise_multiplier : float class ProposedWeights ( BaseModel ): weights : Weights vote_score : float test_score : float vote : Optional [ bool ] class ModelFormat ( Enum ): PICKLE_WEIGHTS_ONLY = 1 ONNX = 2 class ColearnModel ( BaseModel ): model_format : ModelFormat model_file : Optional [ str ] model : Optional [ Any ] def deser_model ( model : Any ) -> onnx . ModelProto : \"\"\" Helper function to recover a onnx model from its deserialized form \"\"\" return onnx . load_model_from_string ( model ) class MachineLearningInterface ( abc . ABC ): @abc . abstractmethod def mli_propose_weights ( self ) -> Weights : \"\"\" Trains the model. Returns new weights. Does not change the current weights of the model. \"\"\" pass @abc . abstractmethod def mli_test_weights ( self , weights : Weights ) -> ProposedWeights : \"\"\" Tests the proposed weights and fills in the rest of the fields \"\"\" @abc . abstractmethod def mli_accept_weights ( self , weights : Weights ): \"\"\" Updates the model with the proposed set of weights :param weights: The new weights \"\"\" pass @abc . abstractmethod def mli_get_current_weights ( self ) -> Weights : \"\"\" Returns the current weights of the model \"\"\" pass @abc . abstractmethod def mli_get_current_model ( self ) -> ColearnModel : \"\"\" Returns the current model \"\"\" pass There are four methods that need to be implemented: propose_weights causes the model to do some training and then return a new set of weights that are proposed to the other learners. This method shouldn't change the current weights of the model - that only happens when accept_weights is called. test_weights - the models takes some new weights and returns a vote on whether the new weights are an improvement. As with propose_weights, this shouldn't change the current weights of the model - that only happens when accept_weights is called. accept_weights - the models accepts some weights that have been voted on and approved by the set of learners. The old weights of the model are discarded and replaced by the new weights. current_weights should return the current weights of the model. For more details about directly implementing the machine learning interface see the tutorial here","title":"Collective Learning Protocol"},{"location":"about/#how-collective-learning-works","text":"A Colearn experiment begins when a group of entities, referred to as learners , decide on a model architecture and begin learning. Together they will train a single global model. The goal is to train a model that performs better than any of the learners can produce by training on their private data set.","title":"How collective learning works"},{"location":"about/#how-training-works","text":"Training occurs in rounds; during each round the learners attempt to improve the performance of the global shared model. To do so each round an update of the global model (for example new set of weights in a neural network) is proposed. The learners then validate the update and decide if the new model is better than the current global model. If enough learners approve the update then the global model is updated. After an update is approved or rejected a new round begins. The detailed steps of a round updating a global model M are as follows: One of the learners is selected and proposes a new updated model M' The rest of the learners validate M' If M' has better performance than M against their private data set then the learner votes to approve If not, the learner votes to reject The total votes are tallied If more than some threshold (typically 50%) of learners approve then M' becomes the new global model. If not, M continues to be the global model A new round begins. By using a decentralized ledger (a blockchain) this learning process can be run in a completely decentralized, secure and auditable way. Further security can be provided by using differential privacy to avoid exposing your private data set when generating an update.","title":"How Training Works"},{"location":"about/#learning-algorithms-that-work-for-collective-learning","text":"Collective learning is not just for neural networks; any learning algorithm that can be trained on subsets of the data and which can use the results of previous training rounds as the basis for subsequent rounds can be used. Neural networks fit both these constraints: training can be done on mini-batches of data and each training step uses the weights of the previous training step as its starting point. More generally, any model that is trained using mini-batch stochastic gradient descent is fine. Other algorithms can be made to work with collective learning as well. For example, a random forest can be trained iteratively by having each learner add new trees (see example in mli_random_forest_iris.py ). For more discussion, see here .","title":"Learning algorithms that work for collective learning"},{"location":"about/#the-driver","text":"The driver implements the voting protocol, so it handles selecting a learner to train, sending the update out for voting, calculating the vote and accepting or declining the update. Here we have a very minimal driver that doesn't use networking or a blockchain. Eventually the driver will be a smart contract. This is the code that implements one round of voting: def run_one_round ( round_index : int , learners : Sequence [ MachineLearningInterface ], vote_threshold = 0.5 ): proposer = round_index % len ( learners ) new_weights = learners [ proposer ] . mli_propose_weights () prop_weights_list = [ ln . mli_test_weights ( new_weights ) for ln in learners ] approves = sum ( 1 if v . vote else 0 for v in prop_weights_list ) vote = False if approves >= len ( learners ) * vote_threshold : vote = True for j , learner in enumerate ( learners ): learner . mli_accept_weights ( prop_weights_list [ j ]) return prop_weights_list , vote The driver has a list of learners, and each round it selects one learner to be the proposer. The proposer does some training and proposes an updated set of weights. The driver then sends the proposed weights to each of the learners, and they each vote on whether this is an improvement. If the number of approving votes is greater than the vote threshold the proposed weights are accepted, and if not they're rejected.","title":"The driver"},{"location":"about/#the-machine-learning-interface","text":"# ------------------------------------------------------------------------------ # # Copyright 2021 Fetch.AI Limited # # Licensed under the Creative Commons Attribution-NonCommercial International # License, Version 4.0 (the \"License\"); you may not use this file except in # compliance with the License. You may obtain a copy of the License at # # http://creativecommons.org/licenses/by-nc/4.0/legalcode # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # ------------------------------------------------------------------------------ import abc from enum import Enum from typing import Any , Optional import onnx import onnxmltools import sklearn import tensorflow as tf import torch from pydantic import BaseModel from tensorflow import keras model_classes_keras = ( tf . keras . Model , keras . Model , tf . estimator . Estimator ) model_classes_scipy = ( torch . nn . Module ) model_classes_sklearn = ( sklearn . base . ClassifierMixin ) def convert_model_to_onnx ( model : Any ): \"\"\" Helper function to convert a ML model to onnx format \"\"\" if isinstance ( model , model_classes_keras ): return onnxmltools . convert_keras ( model ) if isinstance ( model , model_classes_sklearn ): return onnxmltools . convert_sklearn ( model ) if 'xgboost' in model . __repr__ (): return onnxmltools . convert_sklearn ( model ) if isinstance ( model , model_classes_scipy ): raise Exception ( \"Pytorch models not yet supported to onnx\" ) else : raise Exception ( \"Attempt to convert unsupported model to onnx: {model} \" ) class DiffPrivBudget ( BaseModel ): target_epsilon : float target_delta : float consumed_epsilon : float consumed_delta : float class ErrorCodes ( Enum ): DP_BUDGET_EXCEEDED = 1 class TrainingSummary ( BaseModel ): dp_budget : Optional [ DiffPrivBudget ] error_code : Optional [ ErrorCodes ] class Weights ( BaseModel ): weights : Any training_summary : Optional [ TrainingSummary ] class DiffPrivConfig ( BaseModel ): target_epsilon : float target_delta : float max_grad_norm : float noise_multiplier : float class ProposedWeights ( BaseModel ): weights : Weights vote_score : float test_score : float vote : Optional [ bool ] class ModelFormat ( Enum ): PICKLE_WEIGHTS_ONLY = 1 ONNX = 2 class ColearnModel ( BaseModel ): model_format : ModelFormat model_file : Optional [ str ] model : Optional [ Any ] def deser_model ( model : Any ) -> onnx . ModelProto : \"\"\" Helper function to recover a onnx model from its deserialized form \"\"\" return onnx . load_model_from_string ( model ) class MachineLearningInterface ( abc . ABC ): @abc . abstractmethod def mli_propose_weights ( self ) -> Weights : \"\"\" Trains the model. Returns new weights. Does not change the current weights of the model. \"\"\" pass @abc . abstractmethod def mli_test_weights ( self , weights : Weights ) -> ProposedWeights : \"\"\" Tests the proposed weights and fills in the rest of the fields \"\"\" @abc . abstractmethod def mli_accept_weights ( self , weights : Weights ): \"\"\" Updates the model with the proposed set of weights :param weights: The new weights \"\"\" pass @abc . abstractmethod def mli_get_current_weights ( self ) -> Weights : \"\"\" Returns the current weights of the model \"\"\" pass @abc . abstractmethod def mli_get_current_model ( self ) -> ColearnModel : \"\"\" Returns the current model \"\"\" pass There are four methods that need to be implemented: propose_weights causes the model to do some training and then return a new set of weights that are proposed to the other learners. This method shouldn't change the current weights of the model - that only happens when accept_weights is called. test_weights - the models takes some new weights and returns a vote on whether the new weights are an improvement. As with propose_weights, this shouldn't change the current weights of the model - that only happens when accept_weights is called. accept_weights - the models accepts some weights that have been voted on and approved by the set of learners. The old weights of the model are discarded and replaced by the new weights. current_weights should return the current weights of the model. For more details about directly implementing the machine learning interface see the tutorial here","title":"The Machine Learning Interface"},{"location":"demo/","text":"How to run the demo \u00b6 You can try collective learning for yourself using the simple demo in run_demo . This demo creates n learners for one of six learning tasks and co-ordinates the collective learning between them. There are six potential models for the demo KERAS_MNIST is the Tensorflow implementation of a small model for the standard handwritten digits recognition dataset KERAS_MNIST_RESNET is the Tensorflow implementation of a Resnet model for the standard handwritten digits recognition dataset KERAS_CIFAR10 is the Tensorflow implementation of the classical image recognition dataset PYTORCH_XRAY is Pytorch implementation of a binary classification task that requires predicting pneumonia from images of chest X-rays. The data need to be downloaded from Kaggle PYTORCH_COVID_XRAY is Pytorch implementation of a 3 class classification task that requires predicting no finding, covid or pneumonia from images of chest X-rays. This dataset is not currently publicly available. FRAUD The fraud dataset consists of information about credit card transactions, and the task is to predict whether transactions are fraudulent or not. The data need to be downloaded from Kaggle Use the -h flag to see the options: python -m colearn_examples.ml_interface.run_demo -h Arguments to run the demo: --data_dir: Directory containing training data, not required for MNIST and CIFAR10 --test_dir: Optional directory containing test data. A fraction of the training set will be used as a test set when not specified --model: Model to train, options are KERAS_MNIST KERAS_MNIST_RESNET KERAS_CIFAR10 PYTORCH_XRAY PYTORCH_COVID_XRAY FRAUD --n_learners: Number of individual learners --n_rounds: Number of training rounds --vote_threshold: Minimum fraction of positive votes to accept the new model --train_ratio: Fraction of training dataset to be used as test-set when no test-set is specified --seed: Seed for initialising model and shuffling datasets --learning_rate: Learning rate for optimiser --batch_size: Size of training batch Running MNIST \u00b6 The simplest task to run is MNIST because the data are downloaded automatically from tensorflow_datasets . The command below runs the MNIST task with five learners for 15 rounds. python -m colearn_examples.ml_interface.run_demo --model KERAS_MNIST --n_learners 5 --n_rounds 15 You should see a graph of the vote score and the test score (the score used here is categorical accuracy). The new model is accepted if the fraction of positive votes (green colour) is higher than 0.5. The new model is rejected if the fraction of negative votes (red color) is lower than 0.5. As you can see, there are five learners, and initially they perform poorly. In round one, learner 0 is selected to propose a new set of weights. Other datasets \u00b6 To run the CIFAR10 dataset: python -m colearn_examples.ml_interface.run_demo --model KERAS_CIFAR10 --n_learners 5 --n_rounds 15 The Fraud and X-ray datasets need to be downloaded from kaggle (this requires a kaggle account). To run the fraud dataset: python -m colearn_examples.ml_interface.run_demo --model FRAUD --n_learners 5 --n_rounds 15 --data_dir ./data/fraud To run the X-ray dataset: python -m colearn_examples.ml_interface.run_demo --model PYTORCH_XRAY --n_learners 5 --n_rounds 15 --data_dir ./data/xray","title":"Demo"},{"location":"demo/#how-to-run-the-demo","text":"You can try collective learning for yourself using the simple demo in run_demo . This demo creates n learners for one of six learning tasks and co-ordinates the collective learning between them. There are six potential models for the demo KERAS_MNIST is the Tensorflow implementation of a small model for the standard handwritten digits recognition dataset KERAS_MNIST_RESNET is the Tensorflow implementation of a Resnet model for the standard handwritten digits recognition dataset KERAS_CIFAR10 is the Tensorflow implementation of the classical image recognition dataset PYTORCH_XRAY is Pytorch implementation of a binary classification task that requires predicting pneumonia from images of chest X-rays. The data need to be downloaded from Kaggle PYTORCH_COVID_XRAY is Pytorch implementation of a 3 class classification task that requires predicting no finding, covid or pneumonia from images of chest X-rays. This dataset is not currently publicly available. FRAUD The fraud dataset consists of information about credit card transactions, and the task is to predict whether transactions are fraudulent or not. The data need to be downloaded from Kaggle Use the -h flag to see the options: python -m colearn_examples.ml_interface.run_demo -h Arguments to run the demo: --data_dir: Directory containing training data, not required for MNIST and CIFAR10 --test_dir: Optional directory containing test data. A fraction of the training set will be used as a test set when not specified --model: Model to train, options are KERAS_MNIST KERAS_MNIST_RESNET KERAS_CIFAR10 PYTORCH_XRAY PYTORCH_COVID_XRAY FRAUD --n_learners: Number of individual learners --n_rounds: Number of training rounds --vote_threshold: Minimum fraction of positive votes to accept the new model --train_ratio: Fraction of training dataset to be used as test-set when no test-set is specified --seed: Seed for initialising model and shuffling datasets --learning_rate: Learning rate for optimiser --batch_size: Size of training batch","title":"How to run the demo"},{"location":"demo/#running-mnist","text":"The simplest task to run is MNIST because the data are downloaded automatically from tensorflow_datasets . The command below runs the MNIST task with five learners for 15 rounds. python -m colearn_examples.ml_interface.run_demo --model KERAS_MNIST --n_learners 5 --n_rounds 15 You should see a graph of the vote score and the test score (the score used here is categorical accuracy). The new model is accepted if the fraction of positive votes (green colour) is higher than 0.5. The new model is rejected if the fraction of negative votes (red color) is lower than 0.5. As you can see, there are five learners, and initially they perform poorly. In round one, learner 0 is selected to propose a new set of weights.","title":"Running MNIST"},{"location":"demo/#other-datasets","text":"To run the CIFAR10 dataset: python -m colearn_examples.ml_interface.run_demo --model KERAS_CIFAR10 --n_learners 5 --n_rounds 15 The Fraud and X-ray datasets need to be downloaded from kaggle (this requires a kaggle account). To run the fraud dataset: python -m colearn_examples.ml_interface.run_demo --model FRAUD --n_learners 5 --n_rounds 15 --data_dir ./data/fraud To run the X-ray dataset: python -m colearn_examples.ml_interface.run_demo --model PYTORCH_XRAY --n_learners 5 --n_rounds 15 --data_dir ./data/xray","title":"Other datasets"},{"location":"dev_notes/","text":"Developer Notes \u00b6 These are some notes for developers working on the colearn code repo Google Cloud Storage \u00b6 To have access to the google cloud storage you need to set up your google authentication and have the $GOOGLE_APPLICATION_CREDENTIALS set up correctly. For more details ask or see the contract-learn documentation Build image \u00b6 To build ML server image and push to google cloud use the following command: cd docker python3 ./build.py --publish --allow_dirty # Check this worked correctly docker images","title":"Developer Notes"},{"location":"dev_notes/#developer-notes","text":"These are some notes for developers working on the colearn code repo","title":"Developer Notes"},{"location":"dev_notes/#google-cloud-storage","text":"To have access to the google cloud storage you need to set up your google authentication and have the $GOOGLE_APPLICATION_CREDENTIALS set up correctly. For more details ask or see the contract-learn documentation","title":"Google Cloud Storage"},{"location":"dev_notes/#build-image","text":"To build ML server image and push to google cloud use the following command: cd docker python3 ./build.py --publish --allow_dirty # Check this worked correctly docker images","title":"Build image"},{"location":"differential_privacy/","text":"What is differential privacy? \u00b6 To make a machine learning system that protects privacy we first need to have a definition of what privacy is. Differential privacy (DP) is one such definition. First we need to have three concepts: the database is a collection of data about individuals (for example, their medical records), and we want to make a query about that data (for example \"How much does smoking increase someone's risk of cancer?\"). DP says that privacy is preserved if the result of the query cannot be used to determine if any particular individual is present in the database. So if person A has their medical data in a database, and the query that we want to make on that database is \"How much does smoking increase someone's risk of cancer\" then the result of that query shouldn't disclose whether or not person A's details are in the database. From this comes the idea of sensitivity of a query. The sensitivity of a query determines how much the result of the query depends on an individual's data. For example, the query \"How much does smoking increase the risk of cancer for adults in the UK?\" is less sensitive than the query \"How much does smoking increase the risk of cancer for men aged 50-55 in Cambridge?\" because the second query uses a smaller set of individuals. Epsilon-differential privacy \u00b6 EDP is a scheme for preserving differential privacy. In EDP all queries have random noise added to them, so they are no longer deterministic. So if the query was \"What fraction of people in the database are male\", and the true result is 0.5 then the results of calling this query three times might be 0.53, 0.49 and 0.51. This makes it harder to tell if an individual's data is in the database, because the effect of adding a person can't be distinguished from the effect of the random noise. Intuitively this is a bit like blurring an image: adding noise obscures personal information. The amount of personal information that is revealed isn't zero, but it is guaranteed to be below a certain threshold. The level of privacy that is provided is controlled by the parameter epsilon; the greater epsilon is the more noise is added and the more privacy is preserved. Queries that are more sensitive have more noise added, because they reveal more information about individuals. It is important to add as little noise as possible, because adding more noise obscures the patterns that you want to extract from the data. Differential privacy when training neural networks \u00b6 Each training step for a neural network can be though of as a complicated query on a database of training data. Differential privacy mechanisms tell you how much noise you need to add to guarantee a certain level of privacy. The opacus and tensorflow-privacy libraries implement epsilon-differential privacy for training neural networks for pytorch and keras respectively. How to use differential privacy with colearn \u00b6 By using opacus and tensorflow-privacy we can make collective learning use differential privacy. The learner that is proposing weights does so using a DP-enabled optimiser. To see an example of using this see dp_pytorch and dp_keras .","title":"Differential Privacy"},{"location":"differential_privacy/#what-is-differential-privacy","text":"To make a machine learning system that protects privacy we first need to have a definition of what privacy is. Differential privacy (DP) is one such definition. First we need to have three concepts: the database is a collection of data about individuals (for example, their medical records), and we want to make a query about that data (for example \"How much does smoking increase someone's risk of cancer?\"). DP says that privacy is preserved if the result of the query cannot be used to determine if any particular individual is present in the database. So if person A has their medical data in a database, and the query that we want to make on that database is \"How much does smoking increase someone's risk of cancer\" then the result of that query shouldn't disclose whether or not person A's details are in the database. From this comes the idea of sensitivity of a query. The sensitivity of a query determines how much the result of the query depends on an individual's data. For example, the query \"How much does smoking increase the risk of cancer for adults in the UK?\" is less sensitive than the query \"How much does smoking increase the risk of cancer for men aged 50-55 in Cambridge?\" because the second query uses a smaller set of individuals.","title":"What is differential privacy?"},{"location":"differential_privacy/#epsilon-differential-privacy","text":"EDP is a scheme for preserving differential privacy. In EDP all queries have random noise added to them, so they are no longer deterministic. So if the query was \"What fraction of people in the database are male\", and the true result is 0.5 then the results of calling this query three times might be 0.53, 0.49 and 0.51. This makes it harder to tell if an individual's data is in the database, because the effect of adding a person can't be distinguished from the effect of the random noise. Intuitively this is a bit like blurring an image: adding noise obscures personal information. The amount of personal information that is revealed isn't zero, but it is guaranteed to be below a certain threshold. The level of privacy that is provided is controlled by the parameter epsilon; the greater epsilon is the more noise is added and the more privacy is preserved. Queries that are more sensitive have more noise added, because they reveal more information about individuals. It is important to add as little noise as possible, because adding more noise obscures the patterns that you want to extract from the data.","title":"Epsilon-differential privacy"},{"location":"differential_privacy/#differential-privacy-when-training-neural-networks","text":"Each training step for a neural network can be though of as a complicated query on a database of training data. Differential privacy mechanisms tell you how much noise you need to add to guarantee a certain level of privacy. The opacus and tensorflow-privacy libraries implement epsilon-differential privacy for training neural networks for pytorch and keras respectively.","title":"Differential privacy when training neural networks"},{"location":"differential_privacy/#how-to-use-differential-privacy-with-colearn","text":"By using opacus and tensorflow-privacy we can make collective learning use differential privacy. The learner that is proposing weights does so using a DP-enabled optimiser. To see an example of using this see dp_pytorch and dp_keras .","title":"How to use differential privacy with colearn"},{"location":"examples/","text":"Examples that use Collective Learning \u00b6 This is a list of examples that we've implemented to show you how to use Collective Learning locally. See and example of the gRPC server for the next step towards decentralized Colearn. Mnist \u00b6 Uses the standard Mnist database of handwritten images mnist_keras . Uses the KerasLearner helper class. Discussed in more detail here . mnist_pytorch . Uses the PytorchLearner helper class. Discussed in more detail here . Fraud \u00b6 The fraud dataset consists of information about credit card transactions. The task is to predict whether transactions are fraudulent or not. The data needs to be downloaded from Kaggle , and the data directory passed in with the flag --data_dir . fraud_mli . Uses the MachineLearningInterface directly and detects fraud in bank transactions. fraud_keras . Loads data from numpy arrays and uses KerasLearner . Cifar10 \u00b6 Uses the standard Cifar10 database of images cifar_keras . Uses the KerasLearner helper class. cifar_pytorch . Uses the PytorchLearner helper class. Xray \u00b6 A binary classification task that requires predicting pneumonia from images of chest X-rays. The data need to be downloaded from Kaggle , and the data directory passed in with the flag --data_dir xray_keras . Uses the KerasLearner helper class. xray_pytorch . Uses the PytorchLearner helper class. Iris \u00b6 Uses the standard Iris dataset. The aim of this task is to classify examples into one of three iris species based on measurements of the flower. iris_random_forest . Uses the MachineLearningInterface directly and a random forest for classification.","title":"Standalone examples"},{"location":"examples/#examples-that-use-collective-learning","text":"This is a list of examples that we've implemented to show you how to use Collective Learning locally. See and example of the gRPC server for the next step towards decentralized Colearn.","title":"Examples that use Collective Learning"},{"location":"examples/#mnist","text":"Uses the standard Mnist database of handwritten images mnist_keras . Uses the KerasLearner helper class. Discussed in more detail here . mnist_pytorch . Uses the PytorchLearner helper class. Discussed in more detail here .","title":"Mnist"},{"location":"examples/#fraud","text":"The fraud dataset consists of information about credit card transactions. The task is to predict whether transactions are fraudulent or not. The data needs to be downloaded from Kaggle , and the data directory passed in with the flag --data_dir . fraud_mli . Uses the MachineLearningInterface directly and detects fraud in bank transactions. fraud_keras . Loads data from numpy arrays and uses KerasLearner .","title":"Fraud"},{"location":"examples/#cifar10","text":"Uses the standard Cifar10 database of images cifar_keras . Uses the KerasLearner helper class. cifar_pytorch . Uses the PytorchLearner helper class.","title":"Cifar10"},{"location":"examples/#xray","text":"A binary classification task that requires predicting pneumonia from images of chest X-rays. The data need to be downloaded from Kaggle , and the data directory passed in with the flag --data_dir xray_keras . Uses the KerasLearner helper class. xray_pytorch . Uses the PytorchLearner helper class.","title":"Xray"},{"location":"examples/#iris","text":"Uses the standard Iris dataset. The aim of this task is to classify examples into one of three iris species based on measurements of the flower. iris_random_forest . Uses the MachineLearningInterface directly and a random forest for classification.","title":"Iris"},{"location":"grpc_examples/","text":"Mnist gRPC Example \u00b6 To run the Keras Mnist gRPC example run: python -m colearn_examples.grpc.run_grpc_demo --n_learners 5 --dataloader_tag KERAS_MNIST --model_tag KERAS_MNIST \\ --data_locations /tmp/mnist/0,/tmp/mnist/1,/tmp/mnist/2,/tmp/mnist/3,/tmp/mnist/4 Note This requires colearn[keras] You can verify that the example is working correctly by running the probe: python -m colearn_grpc.scripts.probe_grpc_server --port 9995 For more about the gRPC components of Colearn see the gRPC Tutorial","title":"gRPC example"},{"location":"grpc_examples/#mnist-grpc-example","text":"To run the Keras Mnist gRPC example run: python -m colearn_examples.grpc.run_grpc_demo --n_learners 5 --dataloader_tag KERAS_MNIST --model_tag KERAS_MNIST \\ --data_locations /tmp/mnist/0,/tmp/mnist/1,/tmp/mnist/2,/tmp/mnist/3,/tmp/mnist/4 Note This requires colearn[keras] You can verify that the example is working correctly by running the probe: python -m colearn_grpc.scripts.probe_grpc_server --port 9995 For more about the gRPC components of Colearn see the gRPC Tutorial","title":"Mnist gRPC Example"},{"location":"grpc_tutorial/","text":"gRPC tutorial \u00b6 This tutorial explains how to set up the gRPC learner server. It assumes that you can already run colearn locally, and that you have already defined your own models and dataloaders (if you're going to do so). If you haven't done this then see the tutorials in the Getting Started section. Architecture of colearn \u00b6 There are two main parts to a collective learning system: the learner and the backend. The backend controls the learner, and manages the smart contracts and IPFS, and acts as a control hub for all the associated learners. The learner is the part that executes machine learning code. This consists of proposing, evaluating and accepting new weights as detailed in the Machine Learning Interface. The learner and the backend communicate via gRPC ; the learner runs a gRPC server, and the backend runs a gRPC client that makes requests of the learner. This separation means that the learner can run on specialised hardware (e.g. a compute server) and does not need to be co-located with the backend. Architecture of gRPC server \u00b6 The gRPC interface is defined in colearn_grpc/proto/interface.proto . This defines the functions that the gRPC server exposes and the format for messages between the server and the client. As we covered in the earlier tutorials, the machine learning part of colearn is contained inside the MachineLearningInterface (MLI). To recap: the MLI provides methods for proposing, evaluating and accepting weights. If you want to use your own models with colearn then you need to write an object that implements the MLI (for example, an instance of a python class that inherits from MachineLearningInterface ). For more about the MLI see the MLI tutorial . The gRPC server has an MLI factory, and it uses its MLI factory to make objects that implement the MachineLearningInterface . The MLI factory needs to implement the MLI factory interface. You could write your own MLI factory, but it's easier to use the one we provide. Below we will discuss the MLI factory interface and then talk about how to use the example factory. MLI Factory interface \u00b6 The MLI Factory (as the name suggests) is a factory class for creating objects that implement the machine learning interface: # ------------------------------------------------------------------------------ # # Copyright 2021 Fetch.AI Limited # # Licensed under the Creative Commons Attribution-NonCommercial International # License, Version 4.0 (the \"License\"); you may not use this file except in # compliance with the License. You may obtain a copy of the License at # # http://creativecommons.org/licenses/by-nc/4.0/legalcode # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # ------------------------------------------------------------------------------ import abc from typing import Dict , Set , Any import os.path from pkg_resources import get_distribution , DistributionNotFound from colearn.ml_interface import MachineLearningInterface class MliFactory ( abc . ABC ): \"\"\" Interface a class must implement to be used as a factory by the GRPC Server \"\"\" _version = \"0.0.0\" # https://stackoverflow.com/questions/17583443 try : _dist = get_distribution ( 'colearn' ) # Normalize case for Windows systems dist_loc = os . path . normcase ( _dist . location ) here = os . path . normcase ( __file__ ) if not here . startswith ( os . path . join ( dist_loc , 'colearn' )): # not installed, but there is another version that *is* raise DistributionNotFound except DistributionNotFound : pass else : _version = _dist . version def get_version ( self ) -> str : \"\"\" Returns the version of this library.... \"\"\" return self . _version @abc . abstractmethod def get_models ( self ) -> Dict [ str , Dict [ str , Any ]]: \"\"\" Returns the models this factory produces. The key is the name of the model and the values are their default parameters \"\"\" pass @abc . abstractmethod def get_dataloaders ( self ) -> Dict [ str , Dict [ str , Any ]]: \"\"\" Returns the dataloaders this factory produces. The key is the name of the dataloader and the values are their default parameters \"\"\" pass @abc . abstractmethod def get_compatibilities ( self ) -> Dict [ str , Set [ str ]]: \"\"\" A model is compatible with a dataloader if they can be used together to construct a MachineLearningInterface with the get_MLI function. Returns a dictionary that defines which model is compatible with which dataloader. \"\"\" pass @abc . abstractmethod def get_mli ( self , model_name : str , model_params : str , dataloader_name : str , dataset_params : str ) -> MachineLearningInterface : \"\"\" @param model_name: name of a model, must be in the set return by get_models @param model_params: user defined parameters for the model @param dataloader_name: name of a dataloader to be used: - must be in the set returned by get_dataloaders - must be compatible with model_name as defined by get_compatibilities @param dataset_params: user defined parameters for the dataset @return: Instance of MachineLearningInterface Constructs an object that implements MachineLearningInterface whose underlying model is model_name and dataset is loaded by dataloader_name. \"\"\" pass The MLI Factory stores the constructors for dataloaders and models and also a list of the dataloaders that are compatible with each model. Each constructor is stored under a specific name. For example, \"KERAS_MNIST_MODEL\" is the model for keras mnist. The gRPC server uses the MLI factory to construct MLI objects. The MLI Factory needs to implement four methods: get_models - returns the names of the models that are registered with the factory and their parameters. get_dataloaders - returns the names of the dataloaders that are registered with the factory and their parameters. get_compatibilities - returns a list of dataloaders for each model that can be used with that model. get_mli - takes the name and parameters for the model and dataloader and constructs the MLI object. Returns the MLI object. Using the example MLI Factory \u00b6 The example MLI factory is defined in colearn_grpc/example_mli_factory.py . It stores the models and dataloaders that it knows about in factoryRegistry.py To add a new model and dataloader to the factory you need to do the following things: Define a function that loads the dataset given the location of the dataset. Define a function that takes in the dataset and loads the MLI model. Register both these functions with the factory registry. Registering a dataloader looks like this: @FactoryRegistry . register_dataloader ( dataloader_tag ) def prepare_data_loaders ( location : str , train_ratio : float = 0.9 , batch_size : int = 32 ) -> Tuple [ PrefetchDataset , PrefetchDataset ]: Registering a model is similar, but you additionally have to specify the dataloaders that this model is compatible with. @FactoryRegistry . register_model_architecture ( model_tag , [ dataloader_tag ]) def prepare_learner ( data_loaders : Tuple [ PrefetchDataset , PrefetchDataset ], steps_per_epoch : int = 100 , vote_batches : int = 10 , learning_rate : float = 0.001 ) -> KerasLearner : You can see an example of how to do this in colearn_examples/grpc/mnist_grpc.py . The FactoryRegistry decorators get evaluated when the functions are imported, so ensure that the functions are imported before constructing the gRPC server (more on that later). Constraints on the dataloader function: The first parameter should be a mandatory parameter called \"location\" which stores the location of the dataset. The subsequent parameters should have default arguments. The return type should be specified with a type annotation, and this should be the same type that is expected by the model functions that use this dataloader. The arguments that you pass to the dataloader function must be JSON-encodable . Native python types are fine (e.g. str, dict, list, float). Constraints on the model function: The first parameter should be a mandatory parameter called \"data_loaders\". This must have the same type as the return type of the compatible dataloaders. The subsequent parameters should have default arguments. The return type of model_function should be MachineLearningInterface or a subclass of it (e.g. KerasLearner ). The dataloaders listed as being compatible with the model should already be registered with FactoryRegistry before the model is registered. The arguments that you pass to the model function must be JSON-encodable . Native python types are fine (e.g. str, dict, list, float). Making it all work together \u00b6 It can be challenging to ensure that all the parts talk to each other, so we have provided some examples and helper scripts. It is recommended to first make an all-in-one script following the example of colearn_examples/grpc/mnist_grpc.py . Once this is working you can run colearn_grpc/scripts/run_n_servers.py or colearn_grpc/scripts/run_grpc_server.py to run the server(s). The script colearn_grpc/scripts/probe_grpc_server.py will connect to a gRPC server and print the dataloaders and models that are registered on it (pass in the address as a parameter). The client side of the gRPC communication can then be run using colearn_examples/grpc/run_grpc_demo.py . More details are given below. A note about running tensorflow in multiple processes: on a system with a GPU, tensorflow will try to get all the GPU memory when it starts up. This means that running tensorflow in multiple processes on the same machine will fail. To prevent this happening, tensorflow should be told to use only the CPU by setting the environment variable CUDA_VISIBLE_DEVIES to -1 . This can be done in a python script (before importing tensorflow) by using: import os os . environ [ \"CUDA_VISIBLE_DEVICES\" ] = \"-1\" Testing locally with an all-in-one script \u00b6 You can test this locally by following the example in colearn_examples/grpc/mnist_grpc.py . Define your dataloader and model functions as specified above, and register them with the factory. Then create n_learners gRPC servers: n_learners = 5 first_server_port = 9995 # make n servers for i in range ( n_learners ): port = first_server_port + i server = GRPCServer ( mli_factory = ExampleMliFactory (), port = port ) server_process = Process ( target = server . run ) server_process . start () And then create n_learners gRPC clients: all_learner_models = [] for i in range ( n_learners ): port = first_server_port + i ml_system = ExampleGRPCLearnerClient ( f \"client { i } \" , f \"127.0.0.1: { port } \" ) ml_system . start () dataloader_params = { \"location\" : data_folders [ i ]} ml_system . setup_ml ( dataset_loader_name = dataloader_tag , dataset_loader_parameters = json . dumps ( dataloader_params ), model_arch_name = model_tag , model_parameters = json . dumps ({})) all_learner_models . append ( ml_system ) ExampleGRPCLearnerClient inherits from the MachineLearningInterface so you can use it with the training functions as before: for round_index in range ( n_rounds ): results . data . append ( collective_learning_round ( all_learner_models , vote_threshold , round_index ) ) Testing remotely \u00b6 We expect that the gRPC learner part will often be on a compute cluster and be separate from the gRPC client side. To test the gRPC in a setup like this you can start the servers on the computer side and the client part separately. For one gRPC server: python3 ./colearn_grpc/scripts/run_grpc_server.py --port 9995 --metrics_port 9091 For multiple gRPC servers: python3 ./colearn_grpc/scrips/run_n_grpc_servers.py --n_learners 5 --port 9995 --metrics_port 9091 The servers by default will start on port 9995 and use subsequent ports from there, so if three servers are required they will run on ports 9995, 9996 and 9997. If you have written your own dataloaders and models then you need to make sure that those functions are defined or imported before the server is created. These are the imports of the default dataloaders and models in colearn_grpc/scripts/run_grpc_server.py : # These are imported so that they are registered in the FactoryRegistry import colearn_keras.keras_mnist import colearn_keras.keras_cifar10 import colearn_pytorch.pytorch_xray import colearn_pytorch.pytorch_covid_xray import colearn_other.fraud_dataset Once the gRPC server(s) are running, set up whatever networking and port forwarding is required. You can check that the gRPC server is accessible by using the probe script: python3 ./colearn_grpc/scripts/probe_grpc_server.py --port 9995 If the connection is successful this will print a list of the models and datasets registered on the server. These are the defaults that are registered: info: Attempt number 0 to connect to 127.0.0.1:9995 info: Successfully connected to 127.0.0.1:9995! {'compatibilities': {'FRAUD': ['FRAUD'], 'KERAS_CIFAR10': ['KERAS_CIFAR10'], 'KERAS_MNIST': ['KERAS_MNIST'], 'KERAS_MNIST_RESNET': ['KERAS_MNIST'], 'PYTORCH_COVID_XRAY': ['PYTORCH_COVID_XRAY'], 'PYTORCH_XRAY': ['PYTORCH_XRAY']}, 'data_loaders': {'FRAUD': '{\"train_ratio\": 0.8}', 'KERAS_CIFAR10': '{\"train_ratio\": 0.9, \"batch_size\": 32}', 'KERAS_MNIST': '{\"train_ratio\": 0.9, \"batch_size\": 32}', 'PYTORCH_COVID_XRAY': '{\"train_ratio\": 0.8, \"batch_size\": 8, ' '\"no_cuda\": false}', 'PYTORCH_XRAY': '{\"test_location\": null, \"train_ratio\": 0.96, ' '\"batch_size\": 8, \"no_cuda\": false}'}, 'model_architectures': {'FRAUD': '{}', 'KERAS_CIFAR10': '{\"steps_per_epoch\": 100, ' '\"vote_batches\": 10, ' '\"learning_rate\": 0.001}', 'KERAS_MNIST': '{\"steps_per_epoch\": 100, ' '\"vote_batches\": 10, \"learning_rate\": ' '0.001}', 'KERAS_MNIST_RESNET': '{\"steps_per_epoch\": 100, ' '\"vote_batches\": 10, ' '\"learning_rate\": 0.001}', 'PYTORCH_COVID_XRAY': '{\"learning_rate\": 0.001, ' '\"steps_per_epoch\": 40, ' '\"vote_batches\": 10, \"no_cuda\": ' 'false, \"vote_on_accuracy\": ' 'true}', 'PYTORCH_XRAY': '{\"learning_rate\": 0.001, ' '\"steps_per_epoch\": 40, ' '\"vote_batches\": 10, \"no_cuda\": ' 'false, \"vote_on_accuracy\": true}'}} Then run python -m colearn_examples.grpc.run_grpc_demo on the other side to run the usual demo. The script takes as arguments the model name and dataset name that should be run, along with the number of learners and the data location for each learner. python -m colearn_examples.grpc.run_grpc_demo --n_learners 5 --dataloader_tag KERAS_MNIST --model_tag KERAS_MNIST \\ --data_locations /tmp/mnist/0,/tmp/mnist/1,/tmp/mnist/2,/tmp/mnist/3,/tmp/mnist/4 Using the MLI Factory interface \u00b6 An alternative method of using your own dataloaders and models with the gRPC server is to use the MLI Factory interface. This is defined in colearn_grpc/mli_factory_interface.py . An example is given in colearn_examples/grpc/mlifactory_grpc_mnist.py . The MLI Factory is implemented as shown: dataloader_tag = \"KERAS_MNIST_EXAMPLE_DATALOADER\" model_tag = \"KERAS_MNIST_EXAMPLE_MODEL\" class SimpleFactory ( MliFactory ): def get_dataloaders ( self ) -> Dict [ str , Dict [ str , Any ]]: return { dataloader_tag : dict ( train_ratio = 0.9 , batch_size = 32 )} def get_models ( self ) -> Dict [ str , Dict [ str , Any ]]: return { model_tag : dict ( steps_per_epoch = 100 , vote_batches = 10 , learning_rate = 0.001 )} def get_compatibilities ( self ) -> Dict [ str , Set [ str ]]: return { model_tag : { dataloader_tag }} def get_mli ( self , model_name : str , model_params : str , dataloader_name : str , dataset_params : str ) -> MachineLearningInterface : dataloader_params = json . loads ( dataset_params ) data_loaders = prepare_data_loaders ( ** dataloader_params ) model_params = json . loads ( model_params ) mli_model = prepare_learner ( data_loaders = data_loaders , ** model_params ) return mli_model An instance of the SimpleFactory class needs to be passed to the gRPC server on creation: n_learners = 5 first_server_port = 9995 # make n servers server_processes = [] for i in range ( n_learners ): port = first_server_port + i server = GRPCServer ( mli_factory = SimpleFactory (), port = port ) server_process = Process ( target = server . run ) print ( \"starting server\" , i ) server_process . start () server_processes . append ( server_process ) The rest of the example follows the grpc_mnist.py example.","title":"gRPC server"},{"location":"grpc_tutorial/#grpc-tutorial","text":"This tutorial explains how to set up the gRPC learner server. It assumes that you can already run colearn locally, and that you have already defined your own models and dataloaders (if you're going to do so). If you haven't done this then see the tutorials in the Getting Started section.","title":"gRPC tutorial"},{"location":"grpc_tutorial/#architecture-of-colearn","text":"There are two main parts to a collective learning system: the learner and the backend. The backend controls the learner, and manages the smart contracts and IPFS, and acts as a control hub for all the associated learners. The learner is the part that executes machine learning code. This consists of proposing, evaluating and accepting new weights as detailed in the Machine Learning Interface. The learner and the backend communicate via gRPC ; the learner runs a gRPC server, and the backend runs a gRPC client that makes requests of the learner. This separation means that the learner can run on specialised hardware (e.g. a compute server) and does not need to be co-located with the backend.","title":"Architecture of colearn"},{"location":"grpc_tutorial/#architecture-of-grpc-server","text":"The gRPC interface is defined in colearn_grpc/proto/interface.proto . This defines the functions that the gRPC server exposes and the format for messages between the server and the client. As we covered in the earlier tutorials, the machine learning part of colearn is contained inside the MachineLearningInterface (MLI). To recap: the MLI provides methods for proposing, evaluating and accepting weights. If you want to use your own models with colearn then you need to write an object that implements the MLI (for example, an instance of a python class that inherits from MachineLearningInterface ). For more about the MLI see the MLI tutorial . The gRPC server has an MLI factory, and it uses its MLI factory to make objects that implement the MachineLearningInterface . The MLI factory needs to implement the MLI factory interface. You could write your own MLI factory, but it's easier to use the one we provide. Below we will discuss the MLI factory interface and then talk about how to use the example factory.","title":"Architecture of gRPC server"},{"location":"grpc_tutorial/#mli-factory-interface","text":"The MLI Factory (as the name suggests) is a factory class for creating objects that implement the machine learning interface: # ------------------------------------------------------------------------------ # # Copyright 2021 Fetch.AI Limited # # Licensed under the Creative Commons Attribution-NonCommercial International # License, Version 4.0 (the \"License\"); you may not use this file except in # compliance with the License. You may obtain a copy of the License at # # http://creativecommons.org/licenses/by-nc/4.0/legalcode # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # ------------------------------------------------------------------------------ import abc from typing import Dict , Set , Any import os.path from pkg_resources import get_distribution , DistributionNotFound from colearn.ml_interface import MachineLearningInterface class MliFactory ( abc . ABC ): \"\"\" Interface a class must implement to be used as a factory by the GRPC Server \"\"\" _version = \"0.0.0\" # https://stackoverflow.com/questions/17583443 try : _dist = get_distribution ( 'colearn' ) # Normalize case for Windows systems dist_loc = os . path . normcase ( _dist . location ) here = os . path . normcase ( __file__ ) if not here . startswith ( os . path . join ( dist_loc , 'colearn' )): # not installed, but there is another version that *is* raise DistributionNotFound except DistributionNotFound : pass else : _version = _dist . version def get_version ( self ) -> str : \"\"\" Returns the version of this library.... \"\"\" return self . _version @abc . abstractmethod def get_models ( self ) -> Dict [ str , Dict [ str , Any ]]: \"\"\" Returns the models this factory produces. The key is the name of the model and the values are their default parameters \"\"\" pass @abc . abstractmethod def get_dataloaders ( self ) -> Dict [ str , Dict [ str , Any ]]: \"\"\" Returns the dataloaders this factory produces. The key is the name of the dataloader and the values are their default parameters \"\"\" pass @abc . abstractmethod def get_compatibilities ( self ) -> Dict [ str , Set [ str ]]: \"\"\" A model is compatible with a dataloader if they can be used together to construct a MachineLearningInterface with the get_MLI function. Returns a dictionary that defines which model is compatible with which dataloader. \"\"\" pass @abc . abstractmethod def get_mli ( self , model_name : str , model_params : str , dataloader_name : str , dataset_params : str ) -> MachineLearningInterface : \"\"\" @param model_name: name of a model, must be in the set return by get_models @param model_params: user defined parameters for the model @param dataloader_name: name of a dataloader to be used: - must be in the set returned by get_dataloaders - must be compatible with model_name as defined by get_compatibilities @param dataset_params: user defined parameters for the dataset @return: Instance of MachineLearningInterface Constructs an object that implements MachineLearningInterface whose underlying model is model_name and dataset is loaded by dataloader_name. \"\"\" pass The MLI Factory stores the constructors for dataloaders and models and also a list of the dataloaders that are compatible with each model. Each constructor is stored under a specific name. For example, \"KERAS_MNIST_MODEL\" is the model for keras mnist. The gRPC server uses the MLI factory to construct MLI objects. The MLI Factory needs to implement four methods: get_models - returns the names of the models that are registered with the factory and their parameters. get_dataloaders - returns the names of the dataloaders that are registered with the factory and their parameters. get_compatibilities - returns a list of dataloaders for each model that can be used with that model. get_mli - takes the name and parameters for the model and dataloader and constructs the MLI object. Returns the MLI object.","title":"MLI Factory interface"},{"location":"grpc_tutorial/#using-the-example-mli-factory","text":"The example MLI factory is defined in colearn_grpc/example_mli_factory.py . It stores the models and dataloaders that it knows about in factoryRegistry.py To add a new model and dataloader to the factory you need to do the following things: Define a function that loads the dataset given the location of the dataset. Define a function that takes in the dataset and loads the MLI model. Register both these functions with the factory registry. Registering a dataloader looks like this: @FactoryRegistry . register_dataloader ( dataloader_tag ) def prepare_data_loaders ( location : str , train_ratio : float = 0.9 , batch_size : int = 32 ) -> Tuple [ PrefetchDataset , PrefetchDataset ]: Registering a model is similar, but you additionally have to specify the dataloaders that this model is compatible with. @FactoryRegistry . register_model_architecture ( model_tag , [ dataloader_tag ]) def prepare_learner ( data_loaders : Tuple [ PrefetchDataset , PrefetchDataset ], steps_per_epoch : int = 100 , vote_batches : int = 10 , learning_rate : float = 0.001 ) -> KerasLearner : You can see an example of how to do this in colearn_examples/grpc/mnist_grpc.py . The FactoryRegistry decorators get evaluated when the functions are imported, so ensure that the functions are imported before constructing the gRPC server (more on that later). Constraints on the dataloader function: The first parameter should be a mandatory parameter called \"location\" which stores the location of the dataset. The subsequent parameters should have default arguments. The return type should be specified with a type annotation, and this should be the same type that is expected by the model functions that use this dataloader. The arguments that you pass to the dataloader function must be JSON-encodable . Native python types are fine (e.g. str, dict, list, float). Constraints on the model function: The first parameter should be a mandatory parameter called \"data_loaders\". This must have the same type as the return type of the compatible dataloaders. The subsequent parameters should have default arguments. The return type of model_function should be MachineLearningInterface or a subclass of it (e.g. KerasLearner ). The dataloaders listed as being compatible with the model should already be registered with FactoryRegistry before the model is registered. The arguments that you pass to the model function must be JSON-encodable . Native python types are fine (e.g. str, dict, list, float).","title":"Using the example MLI Factory"},{"location":"grpc_tutorial/#making-it-all-work-together","text":"It can be challenging to ensure that all the parts talk to each other, so we have provided some examples and helper scripts. It is recommended to first make an all-in-one script following the example of colearn_examples/grpc/mnist_grpc.py . Once this is working you can run colearn_grpc/scripts/run_n_servers.py or colearn_grpc/scripts/run_grpc_server.py to run the server(s). The script colearn_grpc/scripts/probe_grpc_server.py will connect to a gRPC server and print the dataloaders and models that are registered on it (pass in the address as a parameter). The client side of the gRPC communication can then be run using colearn_examples/grpc/run_grpc_demo.py . More details are given below. A note about running tensorflow in multiple processes: on a system with a GPU, tensorflow will try to get all the GPU memory when it starts up. This means that running tensorflow in multiple processes on the same machine will fail. To prevent this happening, tensorflow should be told to use only the CPU by setting the environment variable CUDA_VISIBLE_DEVIES to -1 . This can be done in a python script (before importing tensorflow) by using: import os os . environ [ \"CUDA_VISIBLE_DEVICES\" ] = \"-1\"","title":"Making it all work together"},{"location":"grpc_tutorial/#testing-locally-with-an-all-in-one-script","text":"You can test this locally by following the example in colearn_examples/grpc/mnist_grpc.py . Define your dataloader and model functions as specified above, and register them with the factory. Then create n_learners gRPC servers: n_learners = 5 first_server_port = 9995 # make n servers for i in range ( n_learners ): port = first_server_port + i server = GRPCServer ( mli_factory = ExampleMliFactory (), port = port ) server_process = Process ( target = server . run ) server_process . start () And then create n_learners gRPC clients: all_learner_models = [] for i in range ( n_learners ): port = first_server_port + i ml_system = ExampleGRPCLearnerClient ( f \"client { i } \" , f \"127.0.0.1: { port } \" ) ml_system . start () dataloader_params = { \"location\" : data_folders [ i ]} ml_system . setup_ml ( dataset_loader_name = dataloader_tag , dataset_loader_parameters = json . dumps ( dataloader_params ), model_arch_name = model_tag , model_parameters = json . dumps ({})) all_learner_models . append ( ml_system ) ExampleGRPCLearnerClient inherits from the MachineLearningInterface so you can use it with the training functions as before: for round_index in range ( n_rounds ): results . data . append ( collective_learning_round ( all_learner_models , vote_threshold , round_index ) )","title":"Testing locally with an all-in-one script"},{"location":"grpc_tutorial/#testing-remotely","text":"We expect that the gRPC learner part will often be on a compute cluster and be separate from the gRPC client side. To test the gRPC in a setup like this you can start the servers on the computer side and the client part separately. For one gRPC server: python3 ./colearn_grpc/scripts/run_grpc_server.py --port 9995 --metrics_port 9091 For multiple gRPC servers: python3 ./colearn_grpc/scrips/run_n_grpc_servers.py --n_learners 5 --port 9995 --metrics_port 9091 The servers by default will start on port 9995 and use subsequent ports from there, so if three servers are required they will run on ports 9995, 9996 and 9997. If you have written your own dataloaders and models then you need to make sure that those functions are defined or imported before the server is created. These are the imports of the default dataloaders and models in colearn_grpc/scripts/run_grpc_server.py : # These are imported so that they are registered in the FactoryRegistry import colearn_keras.keras_mnist import colearn_keras.keras_cifar10 import colearn_pytorch.pytorch_xray import colearn_pytorch.pytorch_covid_xray import colearn_other.fraud_dataset Once the gRPC server(s) are running, set up whatever networking and port forwarding is required. You can check that the gRPC server is accessible by using the probe script: python3 ./colearn_grpc/scripts/probe_grpc_server.py --port 9995 If the connection is successful this will print a list of the models and datasets registered on the server. These are the defaults that are registered: info: Attempt number 0 to connect to 127.0.0.1:9995 info: Successfully connected to 127.0.0.1:9995! {'compatibilities': {'FRAUD': ['FRAUD'], 'KERAS_CIFAR10': ['KERAS_CIFAR10'], 'KERAS_MNIST': ['KERAS_MNIST'], 'KERAS_MNIST_RESNET': ['KERAS_MNIST'], 'PYTORCH_COVID_XRAY': ['PYTORCH_COVID_XRAY'], 'PYTORCH_XRAY': ['PYTORCH_XRAY']}, 'data_loaders': {'FRAUD': '{\"train_ratio\": 0.8}', 'KERAS_CIFAR10': '{\"train_ratio\": 0.9, \"batch_size\": 32}', 'KERAS_MNIST': '{\"train_ratio\": 0.9, \"batch_size\": 32}', 'PYTORCH_COVID_XRAY': '{\"train_ratio\": 0.8, \"batch_size\": 8, ' '\"no_cuda\": false}', 'PYTORCH_XRAY': '{\"test_location\": null, \"train_ratio\": 0.96, ' '\"batch_size\": 8, \"no_cuda\": false}'}, 'model_architectures': {'FRAUD': '{}', 'KERAS_CIFAR10': '{\"steps_per_epoch\": 100, ' '\"vote_batches\": 10, ' '\"learning_rate\": 0.001}', 'KERAS_MNIST': '{\"steps_per_epoch\": 100, ' '\"vote_batches\": 10, \"learning_rate\": ' '0.001}', 'KERAS_MNIST_RESNET': '{\"steps_per_epoch\": 100, ' '\"vote_batches\": 10, ' '\"learning_rate\": 0.001}', 'PYTORCH_COVID_XRAY': '{\"learning_rate\": 0.001, ' '\"steps_per_epoch\": 40, ' '\"vote_batches\": 10, \"no_cuda\": ' 'false, \"vote_on_accuracy\": ' 'true}', 'PYTORCH_XRAY': '{\"learning_rate\": 0.001, ' '\"steps_per_epoch\": 40, ' '\"vote_batches\": 10, \"no_cuda\": ' 'false, \"vote_on_accuracy\": true}'}} Then run python -m colearn_examples.grpc.run_grpc_demo on the other side to run the usual demo. The script takes as arguments the model name and dataset name that should be run, along with the number of learners and the data location for each learner. python -m colearn_examples.grpc.run_grpc_demo --n_learners 5 --dataloader_tag KERAS_MNIST --model_tag KERAS_MNIST \\ --data_locations /tmp/mnist/0,/tmp/mnist/1,/tmp/mnist/2,/tmp/mnist/3,/tmp/mnist/4","title":"Testing remotely"},{"location":"grpc_tutorial/#using-the-mli-factory-interface","text":"An alternative method of using your own dataloaders and models with the gRPC server is to use the MLI Factory interface. This is defined in colearn_grpc/mli_factory_interface.py . An example is given in colearn_examples/grpc/mlifactory_grpc_mnist.py . The MLI Factory is implemented as shown: dataloader_tag = \"KERAS_MNIST_EXAMPLE_DATALOADER\" model_tag = \"KERAS_MNIST_EXAMPLE_MODEL\" class SimpleFactory ( MliFactory ): def get_dataloaders ( self ) -> Dict [ str , Dict [ str , Any ]]: return { dataloader_tag : dict ( train_ratio = 0.9 , batch_size = 32 )} def get_models ( self ) -> Dict [ str , Dict [ str , Any ]]: return { model_tag : dict ( steps_per_epoch = 100 , vote_batches = 10 , learning_rate = 0.001 )} def get_compatibilities ( self ) -> Dict [ str , Set [ str ]]: return { model_tag : { dataloader_tag }} def get_mli ( self , model_name : str , model_params : str , dataloader_name : str , dataset_params : str ) -> MachineLearningInterface : dataloader_params = json . loads ( dataset_params ) data_loaders = prepare_data_loaders ( ** dataloader_params ) model_params = json . loads ( model_params ) mli_model = prepare_learner ( data_loaders = data_loaders , ** model_params ) return mli_model An instance of the SimpleFactory class needs to be passed to the gRPC server on creation: n_learners = 5 first_server_port = 9995 # make n servers server_processes = [] for i in range ( n_learners ): port = first_server_port + i server = GRPCServer ( mli_factory = SimpleFactory (), port = port ) server_process = Process ( target = server . run ) print ( \"starting server\" , i ) server_process . start () server_processes . append ( server_process ) The rest of the example follows the grpc_mnist.py example.","title":"Using the MLI Factory interface"},{"location":"installation/","text":"Installation \u00b6 The core package, colearn , contains only the MachineLearningInterface and a simple driver that implements the Collective Learning Protocol. To install only the core package: pip install colearn To make collective learning easier to use we have defined extra packages with helpers for model development in Keras and Pytorch. To install with Keras/Pytorch extras: pip install colearn[keras] pip install colearn[pytorch] To install both the Keras and Pytorch extras use: pip install colearn[all] To run stand-alone examples: python -m colearn_examples.ml_interface.run_demo For more examples see the Examples Page Installing From Source \u00b6 Alternatively, to install the latest code from the repo: Download the source code from github: git clone https://github.com/fetchai/colearn.git && cd colearn Create and launch a clean virtual environment with Python 3.7. (This library has currently only been tested with Python 3.7). pipenv --python 3 .7 && pipenv shell Install the package from source: pip install -e . [ all ] Run one of the examples: python colearn_examples/ml_interface/pytorch_mnist.py If you are developing the colearn library then install it in editable mode so that new changes are effective immediately: pip install -e .[all] Running the tests \u00b6 Tests can be run with: tox Documentation \u00b6 To run the documentation, first install mkdocs and plugins: pip install . [ docs ] Then run: mkdocs serve","title":"Installation"},{"location":"installation/#installation","text":"The core package, colearn , contains only the MachineLearningInterface and a simple driver that implements the Collective Learning Protocol. To install only the core package: pip install colearn To make collective learning easier to use we have defined extra packages with helpers for model development in Keras and Pytorch. To install with Keras/Pytorch extras: pip install colearn[keras] pip install colearn[pytorch] To install both the Keras and Pytorch extras use: pip install colearn[all] To run stand-alone examples: python -m colearn_examples.ml_interface.run_demo For more examples see the Examples Page","title":"Installation"},{"location":"installation/#installing-from-source","text":"Alternatively, to install the latest code from the repo: Download the source code from github: git clone https://github.com/fetchai/colearn.git && cd colearn Create and launch a clean virtual environment with Python 3.7. (This library has currently only been tested with Python 3.7). pipenv --python 3 .7 && pipenv shell Install the package from source: pip install -e . [ all ] Run one of the examples: python colearn_examples/ml_interface/pytorch_mnist.py If you are developing the colearn library then install it in editable mode so that new changes are effective immediately: pip install -e .[all]","title":"Installing From Source"},{"location":"installation/#running-the-tests","text":"Tests can be run with: tox","title":"Running the tests"},{"location":"installation/#documentation","text":"To run the documentation, first install mkdocs and plugins: pip install . [ docs ] Then run: mkdocs serve","title":"Documentation"},{"location":"intro_tutorial_keras/","text":"Using collective learning with keras \u00b6 This tutorial is a simple guide to trying out the collective learning protocol with your own machine learning code. Everything runs locally. The most flexible way to use the collective learning backends is to make a class that implements the Collective Learning MachineLearningInterface defined in ml_interface.py . For more details on how to use the MachineLearningInterface see here However, the simpler way is to use one of the helper classes that we have provided that implement most of the interface for popular ML libraries. In this tutorial we are going to walk through using the KerasLearner . First we are going to define the model architecture, then we are going to load the data and configure the model, and then we will run Collective Learning. A standard script for machine learning with Keras looks like the one below # ------------------------------------------------------------------------------ # # Copyright 2021 Fetch.AI Limited # # Licensed under the Creative Commons Attribution-NonCommercial International # License, Version 4.0 (the \"License\"); you may not use this file except in # compliance with the License. You may obtain a copy of the License at # # http://creativecommons.org/licenses/by-nc/4.0/legalcode # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # ------------------------------------------------------------------------------ import tensorflow as tf import tensorflow_datasets as tfds from colearn_keras.utils import normalize_img n_rounds = 20 width = 28 height = 28 n_classes = 10 l_rate = 0.001 batch_size = 64 # Load the data train_dataset , info = tfds . load ( 'mnist' , split = 'train' , as_supervised = True , with_info = True ) n_train = info . splits [ 'train' ] . num_examples test_dataset = tfds . load ( 'mnist' , split = 'test' , as_supervised = True ) train_dataset = train_dataset . map ( normalize_img , num_parallel_calls = tf . data . experimental . AUTOTUNE ) train_dataset = train_dataset . shuffle ( n_train ) train_dataset = train_dataset . batch ( batch_size ) test_dataset = test_dataset . map ( normalize_img , num_parallel_calls = tf . data . experimental . AUTOTUNE ) test_dataset = test_dataset . batch ( batch_size ) # Define the model input_img = tf . keras . Input ( shape = ( width , height , 1 ), name = \"Input\" ) x = tf . keras . layers . Conv2D ( 64 , ( 3 , 3 ), activation = \"relu\" , padding = \"same\" , name = \"Conv1_1\" )( input_img ) x = tf . keras . layers . BatchNormalization ( name = \"bn1\" )( x ) x = tf . keras . layers . MaxPooling2D (( 2 , 2 ), name = \"pool1\" )( x ) x = tf . keras . layers . Conv2D ( 128 , ( 3 , 3 ), activation = \"relu\" , padding = \"same\" , name = \"Conv2_1\" )( x ) x = tf . keras . layers . BatchNormalization ( name = \"bn4\" )( x ) x = tf . keras . layers . MaxPooling2D (( 2 , 2 ), name = \"pool2\" )( x ) x = tf . keras . layers . Flatten ( name = \"flatten\" )( x ) x = tf . keras . layers . Dense ( n_classes , activation = \"softmax\" , name = \"fc1\" )( x ) model = tf . keras . Model ( inputs = input_img , outputs = x ) opt = tf . keras . optimizers . Adam ( lr = l_rate ) model . compile ( loss = \"sparse_categorical_crossentropy\" , metrics = [ tf . keras . metrics . SparseCategoricalAccuracy ()], optimizer = opt ) # Train and evaluate model for round in range ( n_rounds ): model . fit ( train_dataset , steps_per_epoch = 40 ) result = model . evaluate ( x = test_dataset , return_dict = True , steps = 10 ) print ( f \"Performance at round { round } is { result } \" ) There are three steps: Load the data Define the model Train the model In this tutorial we are going to see how to modify each step to use collective learning. We'll end up with code like this: # ------------------------------------------------------------------------------ # # Copyright 2021 Fetch.AI Limited # # Licensed under the Creative Commons Attribution-NonCommercial International # License, Version 4.0 (the \"License\"); you may not use this file except in # compliance with the License. You may obtain a copy of the License at # # http://creativecommons.org/licenses/by-nc/4.0/legalcode # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # ------------------------------------------------------------------------------ import os import tensorflow as tf import tensorflow_datasets as tfds from colearn.training import initial_result , collective_learning_round , set_equal_weights from colearn.utils.plot import ColearnPlot from colearn.utils.results import Results , print_results from colearn_keras.keras_learner import KerasLearner from colearn_keras.utils import normalize_img \"\"\" MNIST training example using Keras Used dataset: - MNIST is set of 60 000 black and white hand written digits images of size 28x28x1 in 10 classes What script does: - Loads MNIST dataset from Keras - Sets up a Keras learner - Randomly splits dataset between multiple learners - Does multiple rounds of learning process and displays plot with results \"\"\" n_learners = 5 vote_threshold = 0.5 vote_batches = 2 testing_mode = bool ( os . getenv ( \"COLEARN_EXAMPLES_TEST\" , \"\" )) # for testing n_rounds = 20 if not testing_mode else 1 width = 28 height = 28 n_classes = 10 l_rate = 0.001 batch_size = 64 # Load data for each learner train_dataset , info = tfds . load ( 'mnist' , split = 'train' , as_supervised = True , with_info = True ) n_datapoints = info . splits [ 'train' ] . num_examples train_datasets = [ train_dataset . shard ( num_shards = n_learners , index = i ) for i in range ( n_learners )] test_dataset = tfds . load ( 'mnist' , split = 'test' , as_supervised = True ) vote_datasets = [ test_dataset . shard ( num_shards = 2 * n_learners , index = i ) for i in range ( n_learners )] test_datasets = [ test_dataset . shard ( num_shards = 2 * n_learners , index = i ) for i in range ( n_learners , 2 * n_learners )] for i in range ( n_learners ): train_datasets [ i ] = train_datasets [ i ] . map ( normalize_img , num_parallel_calls = tf . data . experimental . AUTOTUNE ) train_datasets [ i ] = train_datasets [ i ] . shuffle ( n_datapoints // n_learners ) train_datasets [ i ] = train_datasets [ i ] . batch ( batch_size ) vote_datasets [ i ] = vote_datasets [ i ] . map ( normalize_img , num_parallel_calls = tf . data . experimental . AUTOTUNE ) vote_datasets [ i ] = vote_datasets [ i ] . batch ( batch_size ) test_datasets [ i ] = test_datasets [ i ] . map ( normalize_img , num_parallel_calls = tf . data . experimental . AUTOTUNE ) test_datasets [ i ] = test_datasets [ i ] . batch ( batch_size ) # Define model def get_model (): input_img = tf . keras . Input ( shape = ( width , height , 1 ), name = \"Input\" ) x = tf . keras . layers . Conv2D ( 64 , ( 3 , 3 ), activation = \"relu\" , padding = \"same\" , name = \"Conv1_1\" )( input_img ) x = tf . keras . layers . BatchNormalization ( name = \"bn1\" )( x ) x = tf . keras . layers . MaxPooling2D (( 2 , 2 ), name = \"pool1\" )( x ) x = tf . keras . layers . Conv2D ( 128 , ( 3 , 3 ), activation = \"relu\" , padding = \"same\" , name = \"Conv2_1\" )( x ) x = tf . keras . layers . BatchNormalization ( name = \"bn4\" )( x ) x = tf . keras . layers . MaxPooling2D (( 2 , 2 ), name = \"pool2\" )( x ) x = tf . keras . layers . Flatten ( name = \"flatten\" )( x ) x = tf . keras . layers . Dense ( n_classes , activation = \"softmax\" , name = \"fc1\" )( x ) model = tf . keras . Model ( inputs = input_img , outputs = x ) opt = tf . keras . optimizers . Adam ( lr = l_rate ) model . compile ( loss = \"sparse_categorical_crossentropy\" , metrics = [ tf . keras . metrics . SparseCategoricalAccuracy ()], optimizer = opt ) return model all_learner_models = [] for i in range ( n_learners ): all_learner_models . append ( KerasLearner ( model = get_model (), train_loader = train_datasets [ i ], vote_loader = vote_datasets [ i ], test_loader = test_datasets [ i ], criterion = \"sparse_categorical_accuracy\" , minimise_criterion = False , model_evaluate_kwargs = { \"steps\" : vote_batches }, )) set_equal_weights ( all_learner_models ) # Train the model using Collective Learning results = Results () results . data . append ( initial_result ( all_learner_models )) plot = ColearnPlot ( score_name = all_learner_models [ 0 ] . criterion ) for round_index in range ( n_rounds ): results . data . append ( collective_learning_round ( all_learner_models , vote_threshold , round_index ) ) print_results ( results ) plot . plot_results_and_votes ( results ) plot . block () print ( \"Colearn Example Finished!\" ) The first thing is to modify the data loading code. Each learner needs to have their own training and testing set from the data. This is easy to do with keras: train_datasets = [ train_dataset . shard ( num_shards = n_learners , index = i ) for i in range ( n_learners )] The model definition is very similar too, except that each learner will need its own copy of the model, so we've moved it into a function. To use collective learning, we need to create an object that implements the MachineLearningInterface. To make it easier to use the MachineLearningInterface with keras, we've defined KerasLearner . KerasLearner implements standard training and evaluation routines as well as the MachineLearningInterface methods. # ------------------------------------------------------------------------------ # # Copyright 2021 Fetch.AI Limited # # Licensed under the Creative Commons Attribution-NonCommercial International # License, Version 4.0 (the \"License\"); you may not use this file except in # compliance with the License. You may obtain a copy of the License at # # http://creativecommons.org/licenses/by-nc/4.0/legalcode # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # ------------------------------------------------------------------------------ from inspect import signature from typing import Optional try : import tensorflow as tf except ImportError : raise Exception ( \"Tensorflow is not installed. To use the tensorflow/keras \" \"add-ons please install colearn with `pip install colearn[keras]`.\" ) from tensorflow import keras from colearn.ml_interface import MachineLearningInterface , Weights , ProposedWeights , ColearnModel , ModelFormat , convert_model_to_onnx from colearn.ml_interface import DiffPrivBudget , DiffPrivConfig , TrainingSummary , ErrorCodes from tensorflow_privacy.privacy.analysis.compute_dp_sgd_privacy import compute_dp_sgd_privacy from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import make_keras_optimizer_class class KerasLearner ( MachineLearningInterface ): \"\"\" Tensorflow Keras learner implementation of machine learning interface \"\"\" def __init__ ( self , model : keras . Model , train_loader : tf . data . Dataset , vote_loader : tf . data . Dataset , test_loader : Optional [ tf . data . Dataset ] = None , need_reset_optimizer : bool = True , minimise_criterion : bool = True , criterion : str = 'loss' , model_fit_kwargs : Optional [ dict ] = None , model_evaluate_kwargs : Optional [ dict ] = None , diff_priv_config : Optional [ DiffPrivConfig ] = None ): \"\"\" :param model: Keras model used for training :param train_loader: Training dataset :param test_loader: Optional test set. Subset of training set will be used if not specified. :param need_reset_optimizer: True to clear optimizer history before training, False to kepp history. :param minimise_criterion: Boolean - True to minimise value of criterion, False to maximise :param criterion: Function to measure model performance :param model_fit_kwargs: Arguments to be passed on model.fit function call :param model_evaluate_kwargs: Arguments to be passed on model.evaluate function call :param diff_priv_config: Contains differential privacy (dp) budget related configuration \"\"\" self . model : keras . Model = model self . train_loader : tf . data . Dataset = train_loader self . vote_loader : tf . data . Dataset = vote_loader self . test_loader : Optional [ tf . data . Dataset ] = test_loader self . need_reset_optimizer = need_reset_optimizer self . minimise_criterion : bool = minimise_criterion self . criterion = criterion self . model_fit_kwargs = model_fit_kwargs or {} self . diff_priv_config = diff_priv_config self . cumulative_epochs = 0 if self . diff_priv_config is not None : self . diff_priv_budget = DiffPrivBudget ( target_epsilon = self . diff_priv_config . target_epsilon , target_delta = self . diff_priv_config . target_delta , consumed_epsilon = 0.0 , # we will always use the highest available delta now consumed_delta = self . diff_priv_config . target_delta ) if 'epochs' in self . model_fit_kwargs . keys (): self . epochs_per_proposal = self . model_fit_kwargs [ 'epochs' ] else : self . epochs_per_proposal = signature ( self . model . fit ) . parameters [ 'epochs' ] . default if model_fit_kwargs : # check that these are valid kwargs for model fit sig = signature ( self . model . fit ) try : sig . bind_partial ( ** self . model_fit_kwargs ) except TypeError : raise Exception ( \"Invalid arguments for model.fit\" ) self . model_evaluate_kwargs = model_evaluate_kwargs or {} if model_evaluate_kwargs : # check that these are valid kwargs for model evaluate sig = signature ( self . model . evaluate ) try : sig . bind_partial ( ** self . model_evaluate_kwargs ) except TypeError : raise Exception ( \"Invalid arguments for model.evaluate\" ) self . vote_score : float = self . test ( self . vote_loader ) def reset_optimizer ( self ): \"\"\" Recompiles the Keras model. This way the optimizer history get erased, which is needed before a new training round, otherwise the outdated history is used. \"\"\" compile_args = self . model . _get_compile_args () # pylint: disable=protected-access opt_config = self . model . optimizer . get_config () if self . diff_priv_config is not None : # tensorflow_privacy optimizers get_config() miss the additional parameters # was fixed here: https://github.com/tensorflow/privacy/commit/49db04e3561638fc02795edb5774d322cdd1d7d1 # but it is not yet in the stable version, thus I need here to do the same. opt_config . update ({ 'l2_norm_clip' : self . model . optimizer . _l2_norm_clip , # pylint: disable=protected-access 'noise_multiplier' : self . model . optimizer . _noise_multiplier , # pylint: disable=protected-access 'num_microbatches' : self . model . optimizer . _num_microbatches , # pylint: disable=protected-access }) new_opt = make_keras_optimizer_class ( getattr ( keras . optimizers , opt_config [ 'name' ]) ) . from_config ( opt_config ) compile_args [ 'optimizer' ] = new_opt else : compile_args [ 'optimizer' ] = getattr ( keras . optimizers , opt_config [ 'name' ]) . from_config ( opt_config ) self . model . compile ( ** compile_args ) def mli_propose_weights ( self ) -> Weights : \"\"\" Trains model on training set and returns new weights after training - Current model is reverted to original state after training :return: Weights after training \"\"\" current_weights = self . mli_get_current_weights () if self . diff_priv_config is not None : epsilon_after_training = self . get_privacy_budget () if epsilon_after_training > self . diff_priv_budget . target_epsilon : return Weights ( weights = current_weights , training_summary = TrainingSummary ( dp_budget = self . diff_priv_budget , error_code = ErrorCodes . DP_BUDGET_EXCEEDED ) ) self . train () new_weights = self . mli_get_current_weights () self . set_weights ( current_weights ) if self . diff_priv_config is not None : self . diff_priv_budget . consumed_epsilon = epsilon_after_training self . cumulative_epochs += self . epochs_per_proposal new_weights . training_summary = TrainingSummary ( dp_budget = self . diff_priv_budget ) return new_weights def mli_test_weights ( self , weights : Weights ) -> ProposedWeights : \"\"\" Tests given weights on training and test set and returns weights with score values :param weights: Weights to be tested :return: ProposedWeights - Weights with vote and test score \"\"\" current_weights = self . mli_get_current_weights () self . set_weights ( weights ) vote_score = self . test ( self . vote_loader ) if self . test_loader : test_score = self . test ( self . test_loader ) else : test_score = 0 vote = self . vote ( vote_score ) self . set_weights ( current_weights ) return ProposedWeights ( weights = weights , vote_score = vote_score , test_score = test_score , vote = vote , ) def vote ( self , new_score ) -> bool : \"\"\" Compares current model score with proposed model score and returns vote :param new_score: Proposed score :return: bool positive or negative vote \"\"\" if self . minimise_criterion : return new_score < self . vote_score else : return new_score > self . vote_score def mli_accept_weights ( self , weights : Weights ): \"\"\" Updates the model with the proposed set of weights :param weights: The new weights \"\"\" self . set_weights ( weights ) self . vote_score = self . test ( self . vote_loader ) def get_train_batch_size ( self ) -> int : \"\"\" Calculates train batch size. \"\"\" if hasattr ( self . train_loader , '_batch_size' ): return self . train_loader . _batch_size # pylint: disable=protected-access else : return self . train_loader . _input_dataset . _batch_size # pylint: disable=protected-access def get_privacy_budget ( self ) -> float : \"\"\" Calculates, what epsilon will apply after another model training. Need to calculate it in advance to see if another training would result in privacy budget violation. \"\"\" batch_size = self . get_train_batch_size () iterations_per_epoch = tf . data . experimental . cardinality ( self . train_loader ) . numpy () n_samples = batch_size * iterations_per_epoch planned_epochs = self . cumulative_epochs + self . epochs_per_proposal epsilon , _ = compute_dp_sgd_privacy ( n = n_samples , batch_size = batch_size , noise_multiplier = self . diff_priv_config . noise_multiplier , # type: ignore epochs = planned_epochs , delta = self . diff_priv_budget . target_delta ) return epsilon def mli_get_current_weights ( self ) -> Weights : \"\"\" :return: The current weights of the model \"\"\" return Weights ( weights = self . model . get_weights ()) def mli_get_current_model ( self ) -> ColearnModel : \"\"\" :return: The current model and its format \"\"\" return ColearnModel ( model_format = ModelFormat ( ModelFormat . ONNX ), model_file = \"\" , model = convert_model_to_onnx ( self . model ), ) def set_weights ( self , weights : Weights ): \"\"\" Rewrites weight of current model :param weights: Weights to be stored \"\"\" self . model . set_weights ( weights . weights ) def train ( self ): \"\"\" Trains the model on the training dataset \"\"\" if self . need_reset_optimizer : # erase the outdated optimizer memory (momentums mostly) self . reset_optimizer () self . model . fit ( self . train_loader , ** self . model_fit_kwargs ) def test ( self , loader : tf . data . Dataset ) -> float : \"\"\" Tests performance of the model on specified dataset :param loader: Dataset for testing :return: Value of performance metric \"\"\" result = self . model . evaluate ( x = loader , return_dict = True , ** self . model_evaluate_kwargs ) return result [ self . criterion ] We create a set of KerasLearners by passing in the model and the datasets: all_learner_models = [] for i in range ( n_learners ): all_learner_models . append ( KerasLearner ( model = get_model (), train_loader = train_datasets [ i ], vote_loader = vote_datasets [ i ], test_loader = test_datasets [ i ], criterion = \"sparse_categorical_accuracy\" , minimise_criterion = False , model_evaluate_kwargs = { \"steps\" : vote_batches }, )) Then we give all the models the same weights to start off with: set_equal_weights ( all_learner_models ) And then we can move on to the final stage, which is training with Collective Learning. The function collective_learning_round performs one round of collective learning. One learner is selected to train and propose an update. The other learners vote on the update, and if the vote passes then the update is accepted. Then a new round begins. # Train the model using Collective Learning results = Results () results . data . append ( initial_result ( all_learner_models )) for round in range ( n_rounds ): results . data . append ( collective_learning_round ( all_learner_models , vote_threshold , round ) ) plot_results ( results , n_learners , block = False , score_name = all_learner_models [ 0 ] . criterion ) plot_votes ( results , block = False ) plot_results ( results , n_learners , block = False , score_name = all_learner_models [ 0 ] . criterion ) plot_votes ( results , block = True )","title":"Keras"},{"location":"intro_tutorial_keras/#using-collective-learning-with-keras","text":"This tutorial is a simple guide to trying out the collective learning protocol with your own machine learning code. Everything runs locally. The most flexible way to use the collective learning backends is to make a class that implements the Collective Learning MachineLearningInterface defined in ml_interface.py . For more details on how to use the MachineLearningInterface see here However, the simpler way is to use one of the helper classes that we have provided that implement most of the interface for popular ML libraries. In this tutorial we are going to walk through using the KerasLearner . First we are going to define the model architecture, then we are going to load the data and configure the model, and then we will run Collective Learning. A standard script for machine learning with Keras looks like the one below # ------------------------------------------------------------------------------ # # Copyright 2021 Fetch.AI Limited # # Licensed under the Creative Commons Attribution-NonCommercial International # License, Version 4.0 (the \"License\"); you may not use this file except in # compliance with the License. You may obtain a copy of the License at # # http://creativecommons.org/licenses/by-nc/4.0/legalcode # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # ------------------------------------------------------------------------------ import tensorflow as tf import tensorflow_datasets as tfds from colearn_keras.utils import normalize_img n_rounds = 20 width = 28 height = 28 n_classes = 10 l_rate = 0.001 batch_size = 64 # Load the data train_dataset , info = tfds . load ( 'mnist' , split = 'train' , as_supervised = True , with_info = True ) n_train = info . splits [ 'train' ] . num_examples test_dataset = tfds . load ( 'mnist' , split = 'test' , as_supervised = True ) train_dataset = train_dataset . map ( normalize_img , num_parallel_calls = tf . data . experimental . AUTOTUNE ) train_dataset = train_dataset . shuffle ( n_train ) train_dataset = train_dataset . batch ( batch_size ) test_dataset = test_dataset . map ( normalize_img , num_parallel_calls = tf . data . experimental . AUTOTUNE ) test_dataset = test_dataset . batch ( batch_size ) # Define the model input_img = tf . keras . Input ( shape = ( width , height , 1 ), name = \"Input\" ) x = tf . keras . layers . Conv2D ( 64 , ( 3 , 3 ), activation = \"relu\" , padding = \"same\" , name = \"Conv1_1\" )( input_img ) x = tf . keras . layers . BatchNormalization ( name = \"bn1\" )( x ) x = tf . keras . layers . MaxPooling2D (( 2 , 2 ), name = \"pool1\" )( x ) x = tf . keras . layers . Conv2D ( 128 , ( 3 , 3 ), activation = \"relu\" , padding = \"same\" , name = \"Conv2_1\" )( x ) x = tf . keras . layers . BatchNormalization ( name = \"bn4\" )( x ) x = tf . keras . layers . MaxPooling2D (( 2 , 2 ), name = \"pool2\" )( x ) x = tf . keras . layers . Flatten ( name = \"flatten\" )( x ) x = tf . keras . layers . Dense ( n_classes , activation = \"softmax\" , name = \"fc1\" )( x ) model = tf . keras . Model ( inputs = input_img , outputs = x ) opt = tf . keras . optimizers . Adam ( lr = l_rate ) model . compile ( loss = \"sparse_categorical_crossentropy\" , metrics = [ tf . keras . metrics . SparseCategoricalAccuracy ()], optimizer = opt ) # Train and evaluate model for round in range ( n_rounds ): model . fit ( train_dataset , steps_per_epoch = 40 ) result = model . evaluate ( x = test_dataset , return_dict = True , steps = 10 ) print ( f \"Performance at round { round } is { result } \" ) There are three steps: Load the data Define the model Train the model In this tutorial we are going to see how to modify each step to use collective learning. We'll end up with code like this: # ------------------------------------------------------------------------------ # # Copyright 2021 Fetch.AI Limited # # Licensed under the Creative Commons Attribution-NonCommercial International # License, Version 4.0 (the \"License\"); you may not use this file except in # compliance with the License. You may obtain a copy of the License at # # http://creativecommons.org/licenses/by-nc/4.0/legalcode # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # ------------------------------------------------------------------------------ import os import tensorflow as tf import tensorflow_datasets as tfds from colearn.training import initial_result , collective_learning_round , set_equal_weights from colearn.utils.plot import ColearnPlot from colearn.utils.results import Results , print_results from colearn_keras.keras_learner import KerasLearner from colearn_keras.utils import normalize_img \"\"\" MNIST training example using Keras Used dataset: - MNIST is set of 60 000 black and white hand written digits images of size 28x28x1 in 10 classes What script does: - Loads MNIST dataset from Keras - Sets up a Keras learner - Randomly splits dataset between multiple learners - Does multiple rounds of learning process and displays plot with results \"\"\" n_learners = 5 vote_threshold = 0.5 vote_batches = 2 testing_mode = bool ( os . getenv ( \"COLEARN_EXAMPLES_TEST\" , \"\" )) # for testing n_rounds = 20 if not testing_mode else 1 width = 28 height = 28 n_classes = 10 l_rate = 0.001 batch_size = 64 # Load data for each learner train_dataset , info = tfds . load ( 'mnist' , split = 'train' , as_supervised = True , with_info = True ) n_datapoints = info . splits [ 'train' ] . num_examples train_datasets = [ train_dataset . shard ( num_shards = n_learners , index = i ) for i in range ( n_learners )] test_dataset = tfds . load ( 'mnist' , split = 'test' , as_supervised = True ) vote_datasets = [ test_dataset . shard ( num_shards = 2 * n_learners , index = i ) for i in range ( n_learners )] test_datasets = [ test_dataset . shard ( num_shards = 2 * n_learners , index = i ) for i in range ( n_learners , 2 * n_learners )] for i in range ( n_learners ): train_datasets [ i ] = train_datasets [ i ] . map ( normalize_img , num_parallel_calls = tf . data . experimental . AUTOTUNE ) train_datasets [ i ] = train_datasets [ i ] . shuffle ( n_datapoints // n_learners ) train_datasets [ i ] = train_datasets [ i ] . batch ( batch_size ) vote_datasets [ i ] = vote_datasets [ i ] . map ( normalize_img , num_parallel_calls = tf . data . experimental . AUTOTUNE ) vote_datasets [ i ] = vote_datasets [ i ] . batch ( batch_size ) test_datasets [ i ] = test_datasets [ i ] . map ( normalize_img , num_parallel_calls = tf . data . experimental . AUTOTUNE ) test_datasets [ i ] = test_datasets [ i ] . batch ( batch_size ) # Define model def get_model (): input_img = tf . keras . Input ( shape = ( width , height , 1 ), name = \"Input\" ) x = tf . keras . layers . Conv2D ( 64 , ( 3 , 3 ), activation = \"relu\" , padding = \"same\" , name = \"Conv1_1\" )( input_img ) x = tf . keras . layers . BatchNormalization ( name = \"bn1\" )( x ) x = tf . keras . layers . MaxPooling2D (( 2 , 2 ), name = \"pool1\" )( x ) x = tf . keras . layers . Conv2D ( 128 , ( 3 , 3 ), activation = \"relu\" , padding = \"same\" , name = \"Conv2_1\" )( x ) x = tf . keras . layers . BatchNormalization ( name = \"bn4\" )( x ) x = tf . keras . layers . MaxPooling2D (( 2 , 2 ), name = \"pool2\" )( x ) x = tf . keras . layers . Flatten ( name = \"flatten\" )( x ) x = tf . keras . layers . Dense ( n_classes , activation = \"softmax\" , name = \"fc1\" )( x ) model = tf . keras . Model ( inputs = input_img , outputs = x ) opt = tf . keras . optimizers . Adam ( lr = l_rate ) model . compile ( loss = \"sparse_categorical_crossentropy\" , metrics = [ tf . keras . metrics . SparseCategoricalAccuracy ()], optimizer = opt ) return model all_learner_models = [] for i in range ( n_learners ): all_learner_models . append ( KerasLearner ( model = get_model (), train_loader = train_datasets [ i ], vote_loader = vote_datasets [ i ], test_loader = test_datasets [ i ], criterion = \"sparse_categorical_accuracy\" , minimise_criterion = False , model_evaluate_kwargs = { \"steps\" : vote_batches }, )) set_equal_weights ( all_learner_models ) # Train the model using Collective Learning results = Results () results . data . append ( initial_result ( all_learner_models )) plot = ColearnPlot ( score_name = all_learner_models [ 0 ] . criterion ) for round_index in range ( n_rounds ): results . data . append ( collective_learning_round ( all_learner_models , vote_threshold , round_index ) ) print_results ( results ) plot . plot_results_and_votes ( results ) plot . block () print ( \"Colearn Example Finished!\" ) The first thing is to modify the data loading code. Each learner needs to have their own training and testing set from the data. This is easy to do with keras: train_datasets = [ train_dataset . shard ( num_shards = n_learners , index = i ) for i in range ( n_learners )] The model definition is very similar too, except that each learner will need its own copy of the model, so we've moved it into a function. To use collective learning, we need to create an object that implements the MachineLearningInterface. To make it easier to use the MachineLearningInterface with keras, we've defined KerasLearner . KerasLearner implements standard training and evaluation routines as well as the MachineLearningInterface methods. # ------------------------------------------------------------------------------ # # Copyright 2021 Fetch.AI Limited # # Licensed under the Creative Commons Attribution-NonCommercial International # License, Version 4.0 (the \"License\"); you may not use this file except in # compliance with the License. You may obtain a copy of the License at # # http://creativecommons.org/licenses/by-nc/4.0/legalcode # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # ------------------------------------------------------------------------------ from inspect import signature from typing import Optional try : import tensorflow as tf except ImportError : raise Exception ( \"Tensorflow is not installed. To use the tensorflow/keras \" \"add-ons please install colearn with `pip install colearn[keras]`.\" ) from tensorflow import keras from colearn.ml_interface import MachineLearningInterface , Weights , ProposedWeights , ColearnModel , ModelFormat , convert_model_to_onnx from colearn.ml_interface import DiffPrivBudget , DiffPrivConfig , TrainingSummary , ErrorCodes from tensorflow_privacy.privacy.analysis.compute_dp_sgd_privacy import compute_dp_sgd_privacy from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import make_keras_optimizer_class class KerasLearner ( MachineLearningInterface ): \"\"\" Tensorflow Keras learner implementation of machine learning interface \"\"\" def __init__ ( self , model : keras . Model , train_loader : tf . data . Dataset , vote_loader : tf . data . Dataset , test_loader : Optional [ tf . data . Dataset ] = None , need_reset_optimizer : bool = True , minimise_criterion : bool = True , criterion : str = 'loss' , model_fit_kwargs : Optional [ dict ] = None , model_evaluate_kwargs : Optional [ dict ] = None , diff_priv_config : Optional [ DiffPrivConfig ] = None ): \"\"\" :param model: Keras model used for training :param train_loader: Training dataset :param test_loader: Optional test set. Subset of training set will be used if not specified. :param need_reset_optimizer: True to clear optimizer history before training, False to kepp history. :param minimise_criterion: Boolean - True to minimise value of criterion, False to maximise :param criterion: Function to measure model performance :param model_fit_kwargs: Arguments to be passed on model.fit function call :param model_evaluate_kwargs: Arguments to be passed on model.evaluate function call :param diff_priv_config: Contains differential privacy (dp) budget related configuration \"\"\" self . model : keras . Model = model self . train_loader : tf . data . Dataset = train_loader self . vote_loader : tf . data . Dataset = vote_loader self . test_loader : Optional [ tf . data . Dataset ] = test_loader self . need_reset_optimizer = need_reset_optimizer self . minimise_criterion : bool = minimise_criterion self . criterion = criterion self . model_fit_kwargs = model_fit_kwargs or {} self . diff_priv_config = diff_priv_config self . cumulative_epochs = 0 if self . diff_priv_config is not None : self . diff_priv_budget = DiffPrivBudget ( target_epsilon = self . diff_priv_config . target_epsilon , target_delta = self . diff_priv_config . target_delta , consumed_epsilon = 0.0 , # we will always use the highest available delta now consumed_delta = self . diff_priv_config . target_delta ) if 'epochs' in self . model_fit_kwargs . keys (): self . epochs_per_proposal = self . model_fit_kwargs [ 'epochs' ] else : self . epochs_per_proposal = signature ( self . model . fit ) . parameters [ 'epochs' ] . default if model_fit_kwargs : # check that these are valid kwargs for model fit sig = signature ( self . model . fit ) try : sig . bind_partial ( ** self . model_fit_kwargs ) except TypeError : raise Exception ( \"Invalid arguments for model.fit\" ) self . model_evaluate_kwargs = model_evaluate_kwargs or {} if model_evaluate_kwargs : # check that these are valid kwargs for model evaluate sig = signature ( self . model . evaluate ) try : sig . bind_partial ( ** self . model_evaluate_kwargs ) except TypeError : raise Exception ( \"Invalid arguments for model.evaluate\" ) self . vote_score : float = self . test ( self . vote_loader ) def reset_optimizer ( self ): \"\"\" Recompiles the Keras model. This way the optimizer history get erased, which is needed before a new training round, otherwise the outdated history is used. \"\"\" compile_args = self . model . _get_compile_args () # pylint: disable=protected-access opt_config = self . model . optimizer . get_config () if self . diff_priv_config is not None : # tensorflow_privacy optimizers get_config() miss the additional parameters # was fixed here: https://github.com/tensorflow/privacy/commit/49db04e3561638fc02795edb5774d322cdd1d7d1 # but it is not yet in the stable version, thus I need here to do the same. opt_config . update ({ 'l2_norm_clip' : self . model . optimizer . _l2_norm_clip , # pylint: disable=protected-access 'noise_multiplier' : self . model . optimizer . _noise_multiplier , # pylint: disable=protected-access 'num_microbatches' : self . model . optimizer . _num_microbatches , # pylint: disable=protected-access }) new_opt = make_keras_optimizer_class ( getattr ( keras . optimizers , opt_config [ 'name' ]) ) . from_config ( opt_config ) compile_args [ 'optimizer' ] = new_opt else : compile_args [ 'optimizer' ] = getattr ( keras . optimizers , opt_config [ 'name' ]) . from_config ( opt_config ) self . model . compile ( ** compile_args ) def mli_propose_weights ( self ) -> Weights : \"\"\" Trains model on training set and returns new weights after training - Current model is reverted to original state after training :return: Weights after training \"\"\" current_weights = self . mli_get_current_weights () if self . diff_priv_config is not None : epsilon_after_training = self . get_privacy_budget () if epsilon_after_training > self . diff_priv_budget . target_epsilon : return Weights ( weights = current_weights , training_summary = TrainingSummary ( dp_budget = self . diff_priv_budget , error_code = ErrorCodes . DP_BUDGET_EXCEEDED ) ) self . train () new_weights = self . mli_get_current_weights () self . set_weights ( current_weights ) if self . diff_priv_config is not None : self . diff_priv_budget . consumed_epsilon = epsilon_after_training self . cumulative_epochs += self . epochs_per_proposal new_weights . training_summary = TrainingSummary ( dp_budget = self . diff_priv_budget ) return new_weights def mli_test_weights ( self , weights : Weights ) -> ProposedWeights : \"\"\" Tests given weights on training and test set and returns weights with score values :param weights: Weights to be tested :return: ProposedWeights - Weights with vote and test score \"\"\" current_weights = self . mli_get_current_weights () self . set_weights ( weights ) vote_score = self . test ( self . vote_loader ) if self . test_loader : test_score = self . test ( self . test_loader ) else : test_score = 0 vote = self . vote ( vote_score ) self . set_weights ( current_weights ) return ProposedWeights ( weights = weights , vote_score = vote_score , test_score = test_score , vote = vote , ) def vote ( self , new_score ) -> bool : \"\"\" Compares current model score with proposed model score and returns vote :param new_score: Proposed score :return: bool positive or negative vote \"\"\" if self . minimise_criterion : return new_score < self . vote_score else : return new_score > self . vote_score def mli_accept_weights ( self , weights : Weights ): \"\"\" Updates the model with the proposed set of weights :param weights: The new weights \"\"\" self . set_weights ( weights ) self . vote_score = self . test ( self . vote_loader ) def get_train_batch_size ( self ) -> int : \"\"\" Calculates train batch size. \"\"\" if hasattr ( self . train_loader , '_batch_size' ): return self . train_loader . _batch_size # pylint: disable=protected-access else : return self . train_loader . _input_dataset . _batch_size # pylint: disable=protected-access def get_privacy_budget ( self ) -> float : \"\"\" Calculates, what epsilon will apply after another model training. Need to calculate it in advance to see if another training would result in privacy budget violation. \"\"\" batch_size = self . get_train_batch_size () iterations_per_epoch = tf . data . experimental . cardinality ( self . train_loader ) . numpy () n_samples = batch_size * iterations_per_epoch planned_epochs = self . cumulative_epochs + self . epochs_per_proposal epsilon , _ = compute_dp_sgd_privacy ( n = n_samples , batch_size = batch_size , noise_multiplier = self . diff_priv_config . noise_multiplier , # type: ignore epochs = planned_epochs , delta = self . diff_priv_budget . target_delta ) return epsilon def mli_get_current_weights ( self ) -> Weights : \"\"\" :return: The current weights of the model \"\"\" return Weights ( weights = self . model . get_weights ()) def mli_get_current_model ( self ) -> ColearnModel : \"\"\" :return: The current model and its format \"\"\" return ColearnModel ( model_format = ModelFormat ( ModelFormat . ONNX ), model_file = \"\" , model = convert_model_to_onnx ( self . model ), ) def set_weights ( self , weights : Weights ): \"\"\" Rewrites weight of current model :param weights: Weights to be stored \"\"\" self . model . set_weights ( weights . weights ) def train ( self ): \"\"\" Trains the model on the training dataset \"\"\" if self . need_reset_optimizer : # erase the outdated optimizer memory (momentums mostly) self . reset_optimizer () self . model . fit ( self . train_loader , ** self . model_fit_kwargs ) def test ( self , loader : tf . data . Dataset ) -> float : \"\"\" Tests performance of the model on specified dataset :param loader: Dataset for testing :return: Value of performance metric \"\"\" result = self . model . evaluate ( x = loader , return_dict = True , ** self . model_evaluate_kwargs ) return result [ self . criterion ] We create a set of KerasLearners by passing in the model and the datasets: all_learner_models = [] for i in range ( n_learners ): all_learner_models . append ( KerasLearner ( model = get_model (), train_loader = train_datasets [ i ], vote_loader = vote_datasets [ i ], test_loader = test_datasets [ i ], criterion = \"sparse_categorical_accuracy\" , minimise_criterion = False , model_evaluate_kwargs = { \"steps\" : vote_batches }, )) Then we give all the models the same weights to start off with: set_equal_weights ( all_learner_models ) And then we can move on to the final stage, which is training with Collective Learning. The function collective_learning_round performs one round of collective learning. One learner is selected to train and propose an update. The other learners vote on the update, and if the vote passes then the update is accepted. Then a new round begins. # Train the model using Collective Learning results = Results () results . data . append ( initial_result ( all_learner_models )) for round in range ( n_rounds ): results . data . append ( collective_learning_round ( all_learner_models , vote_threshold , round ) ) plot_results ( results , n_learners , block = False , score_name = all_learner_models [ 0 ] . criterion ) plot_votes ( results , block = False ) plot_results ( results , n_learners , block = False , score_name = all_learner_models [ 0 ] . criterion ) plot_votes ( results , block = True )","title":"Using collective learning with keras"},{"location":"intro_tutorial_mli/","text":"Using collective learning \u00b6 This tutorial is a simple guide to trying out the collective learning protocol with your own machine learning code. Everything runs locally. The most flexible way to use the collective learning backends is to make a class that implements the Collective Learning MachineLearningInterface defined in ml_interface.py . This tutorial will walk through implementing the MachineLearningInterface . If you're already using keras or pytorch you might find it easier to use the KerasLearner or Pytorchlearner classes. See the other tutorials for details of how to do that. The MachineLearningInterface \u00b6 # ------------------------------------------------------------------------------ # # Copyright 2021 Fetch.AI Limited # # Licensed under the Creative Commons Attribution-NonCommercial International # License, Version 4.0 (the \"License\"); you may not use this file except in # compliance with the License. You may obtain a copy of the License at # # http://creativecommons.org/licenses/by-nc/4.0/legalcode # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # ------------------------------------------------------------------------------ import abc from enum import Enum from typing import Any , Optional import onnx import onnxmltools import sklearn import tensorflow as tf import torch from pydantic import BaseModel from tensorflow import keras model_classes_keras = ( tf . keras . Model , keras . Model , tf . estimator . Estimator ) model_classes_scipy = ( torch . nn . Module ) model_classes_sklearn = ( sklearn . base . ClassifierMixin ) def convert_model_to_onnx ( model : Any ): \"\"\" Helper function to convert a ML model to onnx format \"\"\" if isinstance ( model , model_classes_keras ): return onnxmltools . convert_keras ( model ) if isinstance ( model , model_classes_sklearn ): return onnxmltools . convert_sklearn ( model ) if 'xgboost' in model . __repr__ (): return onnxmltools . convert_sklearn ( model ) if isinstance ( model , model_classes_scipy ): raise Exception ( \"Pytorch models not yet supported to onnx\" ) else : raise Exception ( \"Attempt to convert unsupported model to onnx: {model} \" ) class DiffPrivBudget ( BaseModel ): target_epsilon : float target_delta : float consumed_epsilon : float consumed_delta : float class ErrorCodes ( Enum ): DP_BUDGET_EXCEEDED = 1 class TrainingSummary ( BaseModel ): dp_budget : Optional [ DiffPrivBudget ] error_code : Optional [ ErrorCodes ] class Weights ( BaseModel ): weights : Any training_summary : Optional [ TrainingSummary ] class DiffPrivConfig ( BaseModel ): target_epsilon : float target_delta : float max_grad_norm : float noise_multiplier : float class ProposedWeights ( BaseModel ): weights : Weights vote_score : float test_score : float vote : Optional [ bool ] class ModelFormat ( Enum ): PICKLE_WEIGHTS_ONLY = 1 ONNX = 2 class ColearnModel ( BaseModel ): model_format : ModelFormat model_file : Optional [ str ] model : Optional [ Any ] def deser_model ( model : Any ) -> onnx . ModelProto : \"\"\" Helper function to recover a onnx model from its deserialized form \"\"\" return onnx . load_model_from_string ( model ) class MachineLearningInterface ( abc . ABC ): @abc . abstractmethod def mli_propose_weights ( self ) -> Weights : \"\"\" Trains the model. Returns new weights. Does not change the current weights of the model. \"\"\" pass @abc . abstractmethod def mli_test_weights ( self , weights : Weights ) -> ProposedWeights : \"\"\" Tests the proposed weights and fills in the rest of the fields \"\"\" @abc . abstractmethod def mli_accept_weights ( self , weights : Weights ): \"\"\" Updates the model with the proposed set of weights :param weights: The new weights \"\"\" pass @abc . abstractmethod def mli_get_current_weights ( self ) -> Weights : \"\"\" Returns the current weights of the model \"\"\" pass @abc . abstractmethod def mli_get_current_model ( self ) -> ColearnModel : \"\"\" Returns the current model \"\"\" pass There are four methods that need to be implemented: propose_weights causes the model to do some training and then return a new set of weights that are proposed to the other learners. This method shouldn't charge the current weights of the model - that only happens when accept_weights is called. test_weights - the models takes some new weights and returns a vote on whether the new weights are an improvement. As in propose_weights, this shouldn't change the current weights of the model - that only happens when accept_weights is called. accept_weights - the model accepts some weights that have been voted on and approved by the set of learners. The old weighs of the model are discarded and replaced by the new weights. current_weights should return the current weights of the model. Algorithms that work with colearn \u00b6 These conditions need to be fulfilled for algorithms to work with collective learning: Model fitting must be incremental so that the previous model is used as the starting point for training. This is easy to achieve for neural networks because neural network training is always iterative, but for other learning algorithms more care must be taken. Some examples of getting this wrong: from sklearn.linear_model import LinearRegression model = LinearRegression () model . fit ( X , y ) from sklearn.ensemble import RandomForestClassifier model = RandomForestClassifier ( n_estimators = 10 ) # it would be okay with warm_start=True model . fit ( X , y ) from xgboost import XGBRegressor model = XGBRegressor () model . fit ( X , y ) None of the training methods here use the previous result when fit is called for a second time; instead they start again from scratch. Good examples of incremental training can be seen in the examples . Many sklearn models have a warm_start parameter which can be set to True to use the previous training result. XGBoost has an xgb_model parameter for passing in the previous training results. The model mustn't overfit when propose_weights() is called. You should limit training so that a learner will not overfit their training data in one round. For example, if a learner overfits their own training data then the other learners will reject the proposed update because it is not a good fit for their data. For a neural network a good approach is to restrict the number of batches that are used each round; for random forest, restrict the trees that are added each round. Implementation for fraud detection task \u00b6 Here is the class that implements the MachineLearningInterface for the task of detecting fraud in bank transactions. class FraudSklearnLearner ( MachineLearningInterface ): def __init__ ( self , train_data , train_labels , test_data , test_labels , batch_size : int = 10000 , steps_per_round : int = 1 ): self . steps_per_round = steps_per_round self . batch_size = batch_size self . train_data = train_data self . train_labels = train_labels self . test_data = test_data self . test_labels = test_labels self . class_labels = np . unique ( train_labels ) self . train_sampler = infinite_batch_sampler ( train_data . shape [ 0 ], batch_size ) self . model = SGDClassifier ( max_iter = 1 , verbose = 0 , loss = \"modified_huber\" ) self . model . partial_fit ( self . train_data [ 0 : 1 ], self . train_labels [ 0 : 1 ], classes = self . class_labels ) # this needs to be called before predict self . vote_score = self . test ( self . train_data , self . train_labels ) def mli_propose_weights ( self ) -> Weights : current_weights = self . mli_get_current_weights () for i in range ( self . steps_per_round ): batch_indices = next ( self . train_sampler ) train_data = self . train_data [ batch_indices ] train_labels = self . train_labels [ batch_indices ] self . model . partial_fit ( train_data , train_labels , classes = self . class_labels ) new_weights = self . mli_get_current_weights () self . set_weights ( current_weights ) return new_weights def mli_test_weights ( self , weights : Weights ) -> ProposedWeights : current_weights = self . mli_get_current_weights () self . set_weights ( weights ) vote_score = self . test ( self . train_data , self . train_labels ) test_score = self . test ( self . test_data , self . test_labels ) vote = self . vote_score <= vote_score self . set_weights ( current_weights ) return ProposedWeights ( weights = weights , vote_score = vote_score , test_score = test_score , vote = vote ) def mli_accept_weights ( self , weights : Weights ): self . set_weights ( weights ) self . vote_score = self . test ( self . train_data , self . train_labels ) def mli_get_current_weights ( self ): # return Weights(weights=copy.deepcopy(self.model)) return Weights ( weights = dict ( coef_ = self . model . coef_ , intercept_ = self . model . intercept_ )) def set_weights ( self , weights : Weights ): # self.model = weights.weights self . model . coef_ = weights . weights [ 'coef_' ] self . model . intercept_ = weights . weights [ 'intercept_' ] def test ( self , data , labels ): try : return self . model . score ( data , labels ) except sklearn . exceptions . NotFittedError : return 0 Let's step through this and see how it works. The propose_weights method saves the current weights of the model. Then it performs some training of the model, and gets the new weights. It returns the new weights, and resets the model weights to be the old weights. def mli_propose_weights ( self ) -> Weights : current_weights = self . mli_get_current_weights () for i in range ( self . steps_per_round ): batch_indices = next ( self . train_sampler ) train_data = self . train_data [ batch_indices ] train_labels = self . train_labels [ batch_indices ] self . model . partial_fit ( train_data , train_labels , classes = self . class_labels ) new_weights = self . mli_get_current_weights () self . set_weights ( current_weights ) return new_weights The test_weights method takes as a parameter the proposed weights that it needs to vote on. It saves the current weights of the model, and then sets the model weights to be the proposed weights. It tests the model and votes based on whether the score that it is monitoring has improved. The vote score can be any metric that you like. You could use loss, accuracy, mean squared error or any custom metric. If the vote score is the loss then the model would only vote True if the score has decreased. Here we're using accuracy, so the vote is true if the score increases. This method then resets the weights to the old values and returns the vote along with some scores for monitoring purposes. def mli_test_weights ( self , weights : Weights ) -> ProposedWeights : current_weights = self . mli_get_current_weights () self . set_weights ( weights ) vote_score = self . test ( self . train_data , self . train_labels ) test_score = self . test ( self . test_data , self . test_labels ) vote = self . vote_score <= vote_score self . set_weights ( current_weights ) return ProposedWeights ( weights = weights , vote_score = vote_score , test_score = test_score , vote = vote ) The accept_weights method sets the weights of the model to be the new weights. It also updates the vote score to be the current performance. Note You could implement a cache here. These weights will already have been tested in test_weights, so the vote score could be retrieved from the cache instead of recomputed. def mli_accept_weights ( self , weights : Weights ): self . set_weights ( weights ) self . vote_score = self . test ( self . train_data , self . train_labels ) The final method is the simplest - get_current_weights just returns the current weights of the model. These weights are wrapped inside a Weights object. def mli_get_current_weights ( self ): return Weights ( weights = dict ( coef_ = self . model . coef_ , intercept_ = self . model . intercept_ )) The rest of the example \u00b6 The data is loaded and preprocessed and then split into equal parts for each learner. Then a list of FraudLearner instances is created, each with its own dataset. all_learner_models = [] for i in range ( n_learners ): all_learner_models . append ( FraudLearner ( train_data = learner_train_data [ i ], train_labels = learner_train_labels [ i ], test_data = learner_test_data [ i ], test_labels = learner_test_labels [ i ] )) Then we give all the models the same weights to start off with: set_equal_weights ( all_learner_models ) And then we can move on to the final stage, which is training with Collective Learning. The function collective_learning_round performs one round of collective learning. One learner is selected to train and propose an update. The other learners vote on the update, and if the vote passes then the update is accepted. Then a new round begins. # Train the model using Collective Learning results = Results () results . data . append ( initial_result ( all_learner_models )) for round in range ( n_rounds ): results . data . append ( collective_learning_round ( all_learner_models , vote_threshold , round ) ) plot_results ( results , n_learners , block = False , score_name = all_learner_models [ 0 ] . criterion ) plot_votes ( results , block = False ) plot_results ( results , n_learners , block = False , score_name = all_learner_models [ 0 ] . criterion ) plot_votes ( results , block = True )","title":"The MachineLearningInterface"},{"location":"intro_tutorial_mli/#using-collective-learning","text":"This tutorial is a simple guide to trying out the collective learning protocol with your own machine learning code. Everything runs locally. The most flexible way to use the collective learning backends is to make a class that implements the Collective Learning MachineLearningInterface defined in ml_interface.py . This tutorial will walk through implementing the MachineLearningInterface . If you're already using keras or pytorch you might find it easier to use the KerasLearner or Pytorchlearner classes. See the other tutorials for details of how to do that.","title":"Using collective learning"},{"location":"intro_tutorial_mli/#the-machinelearninginterface","text":"# ------------------------------------------------------------------------------ # # Copyright 2021 Fetch.AI Limited # # Licensed under the Creative Commons Attribution-NonCommercial International # License, Version 4.0 (the \"License\"); you may not use this file except in # compliance with the License. You may obtain a copy of the License at # # http://creativecommons.org/licenses/by-nc/4.0/legalcode # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # ------------------------------------------------------------------------------ import abc from enum import Enum from typing import Any , Optional import onnx import onnxmltools import sklearn import tensorflow as tf import torch from pydantic import BaseModel from tensorflow import keras model_classes_keras = ( tf . keras . Model , keras . Model , tf . estimator . Estimator ) model_classes_scipy = ( torch . nn . Module ) model_classes_sklearn = ( sklearn . base . ClassifierMixin ) def convert_model_to_onnx ( model : Any ): \"\"\" Helper function to convert a ML model to onnx format \"\"\" if isinstance ( model , model_classes_keras ): return onnxmltools . convert_keras ( model ) if isinstance ( model , model_classes_sklearn ): return onnxmltools . convert_sklearn ( model ) if 'xgboost' in model . __repr__ (): return onnxmltools . convert_sklearn ( model ) if isinstance ( model , model_classes_scipy ): raise Exception ( \"Pytorch models not yet supported to onnx\" ) else : raise Exception ( \"Attempt to convert unsupported model to onnx: {model} \" ) class DiffPrivBudget ( BaseModel ): target_epsilon : float target_delta : float consumed_epsilon : float consumed_delta : float class ErrorCodes ( Enum ): DP_BUDGET_EXCEEDED = 1 class TrainingSummary ( BaseModel ): dp_budget : Optional [ DiffPrivBudget ] error_code : Optional [ ErrorCodes ] class Weights ( BaseModel ): weights : Any training_summary : Optional [ TrainingSummary ] class DiffPrivConfig ( BaseModel ): target_epsilon : float target_delta : float max_grad_norm : float noise_multiplier : float class ProposedWeights ( BaseModel ): weights : Weights vote_score : float test_score : float vote : Optional [ bool ] class ModelFormat ( Enum ): PICKLE_WEIGHTS_ONLY = 1 ONNX = 2 class ColearnModel ( BaseModel ): model_format : ModelFormat model_file : Optional [ str ] model : Optional [ Any ] def deser_model ( model : Any ) -> onnx . ModelProto : \"\"\" Helper function to recover a onnx model from its deserialized form \"\"\" return onnx . load_model_from_string ( model ) class MachineLearningInterface ( abc . ABC ): @abc . abstractmethod def mli_propose_weights ( self ) -> Weights : \"\"\" Trains the model. Returns new weights. Does not change the current weights of the model. \"\"\" pass @abc . abstractmethod def mli_test_weights ( self , weights : Weights ) -> ProposedWeights : \"\"\" Tests the proposed weights and fills in the rest of the fields \"\"\" @abc . abstractmethod def mli_accept_weights ( self , weights : Weights ): \"\"\" Updates the model with the proposed set of weights :param weights: The new weights \"\"\" pass @abc . abstractmethod def mli_get_current_weights ( self ) -> Weights : \"\"\" Returns the current weights of the model \"\"\" pass @abc . abstractmethod def mli_get_current_model ( self ) -> ColearnModel : \"\"\" Returns the current model \"\"\" pass There are four methods that need to be implemented: propose_weights causes the model to do some training and then return a new set of weights that are proposed to the other learners. This method shouldn't charge the current weights of the model - that only happens when accept_weights is called. test_weights - the models takes some new weights and returns a vote on whether the new weights are an improvement. As in propose_weights, this shouldn't change the current weights of the model - that only happens when accept_weights is called. accept_weights - the model accepts some weights that have been voted on and approved by the set of learners. The old weighs of the model are discarded and replaced by the new weights. current_weights should return the current weights of the model.","title":"The MachineLearningInterface"},{"location":"intro_tutorial_mli/#algorithms-that-work-with-colearn","text":"These conditions need to be fulfilled for algorithms to work with collective learning: Model fitting must be incremental so that the previous model is used as the starting point for training. This is easy to achieve for neural networks because neural network training is always iterative, but for other learning algorithms more care must be taken. Some examples of getting this wrong: from sklearn.linear_model import LinearRegression model = LinearRegression () model . fit ( X , y ) from sklearn.ensemble import RandomForestClassifier model = RandomForestClassifier ( n_estimators = 10 ) # it would be okay with warm_start=True model . fit ( X , y ) from xgboost import XGBRegressor model = XGBRegressor () model . fit ( X , y ) None of the training methods here use the previous result when fit is called for a second time; instead they start again from scratch. Good examples of incremental training can be seen in the examples . Many sklearn models have a warm_start parameter which can be set to True to use the previous training result. XGBoost has an xgb_model parameter for passing in the previous training results. The model mustn't overfit when propose_weights() is called. You should limit training so that a learner will not overfit their training data in one round. For example, if a learner overfits their own training data then the other learners will reject the proposed update because it is not a good fit for their data. For a neural network a good approach is to restrict the number of batches that are used each round; for random forest, restrict the trees that are added each round.","title":"Algorithms that work with colearn"},{"location":"intro_tutorial_mli/#implementation-for-fraud-detection-task","text":"Here is the class that implements the MachineLearningInterface for the task of detecting fraud in bank transactions. class FraudSklearnLearner ( MachineLearningInterface ): def __init__ ( self , train_data , train_labels , test_data , test_labels , batch_size : int = 10000 , steps_per_round : int = 1 ): self . steps_per_round = steps_per_round self . batch_size = batch_size self . train_data = train_data self . train_labels = train_labels self . test_data = test_data self . test_labels = test_labels self . class_labels = np . unique ( train_labels ) self . train_sampler = infinite_batch_sampler ( train_data . shape [ 0 ], batch_size ) self . model = SGDClassifier ( max_iter = 1 , verbose = 0 , loss = \"modified_huber\" ) self . model . partial_fit ( self . train_data [ 0 : 1 ], self . train_labels [ 0 : 1 ], classes = self . class_labels ) # this needs to be called before predict self . vote_score = self . test ( self . train_data , self . train_labels ) def mli_propose_weights ( self ) -> Weights : current_weights = self . mli_get_current_weights () for i in range ( self . steps_per_round ): batch_indices = next ( self . train_sampler ) train_data = self . train_data [ batch_indices ] train_labels = self . train_labels [ batch_indices ] self . model . partial_fit ( train_data , train_labels , classes = self . class_labels ) new_weights = self . mli_get_current_weights () self . set_weights ( current_weights ) return new_weights def mli_test_weights ( self , weights : Weights ) -> ProposedWeights : current_weights = self . mli_get_current_weights () self . set_weights ( weights ) vote_score = self . test ( self . train_data , self . train_labels ) test_score = self . test ( self . test_data , self . test_labels ) vote = self . vote_score <= vote_score self . set_weights ( current_weights ) return ProposedWeights ( weights = weights , vote_score = vote_score , test_score = test_score , vote = vote ) def mli_accept_weights ( self , weights : Weights ): self . set_weights ( weights ) self . vote_score = self . test ( self . train_data , self . train_labels ) def mli_get_current_weights ( self ): # return Weights(weights=copy.deepcopy(self.model)) return Weights ( weights = dict ( coef_ = self . model . coef_ , intercept_ = self . model . intercept_ )) def set_weights ( self , weights : Weights ): # self.model = weights.weights self . model . coef_ = weights . weights [ 'coef_' ] self . model . intercept_ = weights . weights [ 'intercept_' ] def test ( self , data , labels ): try : return self . model . score ( data , labels ) except sklearn . exceptions . NotFittedError : return 0 Let's step through this and see how it works. The propose_weights method saves the current weights of the model. Then it performs some training of the model, and gets the new weights. It returns the new weights, and resets the model weights to be the old weights. def mli_propose_weights ( self ) -> Weights : current_weights = self . mli_get_current_weights () for i in range ( self . steps_per_round ): batch_indices = next ( self . train_sampler ) train_data = self . train_data [ batch_indices ] train_labels = self . train_labels [ batch_indices ] self . model . partial_fit ( train_data , train_labels , classes = self . class_labels ) new_weights = self . mli_get_current_weights () self . set_weights ( current_weights ) return new_weights The test_weights method takes as a parameter the proposed weights that it needs to vote on. It saves the current weights of the model, and then sets the model weights to be the proposed weights. It tests the model and votes based on whether the score that it is monitoring has improved. The vote score can be any metric that you like. You could use loss, accuracy, mean squared error or any custom metric. If the vote score is the loss then the model would only vote True if the score has decreased. Here we're using accuracy, so the vote is true if the score increases. This method then resets the weights to the old values and returns the vote along with some scores for monitoring purposes. def mli_test_weights ( self , weights : Weights ) -> ProposedWeights : current_weights = self . mli_get_current_weights () self . set_weights ( weights ) vote_score = self . test ( self . train_data , self . train_labels ) test_score = self . test ( self . test_data , self . test_labels ) vote = self . vote_score <= vote_score self . set_weights ( current_weights ) return ProposedWeights ( weights = weights , vote_score = vote_score , test_score = test_score , vote = vote ) The accept_weights method sets the weights of the model to be the new weights. It also updates the vote score to be the current performance. Note You could implement a cache here. These weights will already have been tested in test_weights, so the vote score could be retrieved from the cache instead of recomputed. def mli_accept_weights ( self , weights : Weights ): self . set_weights ( weights ) self . vote_score = self . test ( self . train_data , self . train_labels ) The final method is the simplest - get_current_weights just returns the current weights of the model. These weights are wrapped inside a Weights object. def mli_get_current_weights ( self ): return Weights ( weights = dict ( coef_ = self . model . coef_ , intercept_ = self . model . intercept_ ))","title":"Implementation for fraud detection task"},{"location":"intro_tutorial_mli/#the-rest-of-the-example","text":"The data is loaded and preprocessed and then split into equal parts for each learner. Then a list of FraudLearner instances is created, each with its own dataset. all_learner_models = [] for i in range ( n_learners ): all_learner_models . append ( FraudLearner ( train_data = learner_train_data [ i ], train_labels = learner_train_labels [ i ], test_data = learner_test_data [ i ], test_labels = learner_test_labels [ i ] )) Then we give all the models the same weights to start off with: set_equal_weights ( all_learner_models ) And then we can move on to the final stage, which is training with Collective Learning. The function collective_learning_round performs one round of collective learning. One learner is selected to train and propose an update. The other learners vote on the update, and if the vote passes then the update is accepted. Then a new round begins. # Train the model using Collective Learning results = Results () results . data . append ( initial_result ( all_learner_models )) for round in range ( n_rounds ): results . data . append ( collective_learning_round ( all_learner_models , vote_threshold , round ) ) plot_results ( results , n_learners , block = False , score_name = all_learner_models [ 0 ] . criterion ) plot_votes ( results , block = False ) plot_results ( results , n_learners , block = False , score_name = all_learner_models [ 0 ] . criterion ) plot_votes ( results , block = True )","title":"The rest of the example"},{"location":"intro_tutorial_pytorch/","text":"Using collective learning with pytorch \u00b6 This tutorial is a simple guide to trying out the collective learning protocol with your own machine learning code. Everything runs locally. The most flexible way to use the collective learning backends is to make a class that implements the Collective Learning MachineLearningInterface defined in ml_interface.py . For more details on how to use the MachineLearningInterface see here However, the simpler way is to use one of the helper classes that we have provided that implement most of the interface for popular ML libraries. In this tutorial we are going to walk through using the PytorchLearner . First we are going to define the model architecture, then we are going to load the data and configure the model, and then we will run Collective Learning. A standard script for machine learning with Pytorch looks like the one below # ------------------------------------------------------------------------------ # # Copyright 2021 Fetch.AI Limited # # Licensed under the Creative Commons Attribution-NonCommercial International # License, Version 4.0 (the \"License\"); you may not use this file except in # compliance with the License. You may obtain a copy of the License at # # http://creativecommons.org/licenses/by-nc/4.0/legalcode # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # ------------------------------------------------------------------------------ from torchsummary import summary from torchvision import transforms , datasets import torch.utils.data import torch.nn as nn import torch.nn.functional as nn_func # define some constants batch_size = 64 seed = 42 n_rounds = 20 train_fraction = 0.9 learning_rate = 0.001 height = 28 width = 28 n_classes = 10 num_test_batches = 10 no_cuda = False cuda = not no_cuda and torch . cuda . is_available () device = torch . device ( \"cuda\" if cuda else \"cpu\" ) kwargs = { 'num_workers' : 1 , 'pin_memory' : True } if cuda else {} # Load the data data = datasets . MNIST ( '/tmp/mnist' , transform = transforms . ToTensor (), download = True ) n_train = int ( train_fraction * len ( data )) n_test = len ( data ) - n_train train_data , test_data = torch . utils . data . random_split ( data , [ n_train , n_test ]) train_dataloader = torch . utils . data . DataLoader ( train_data , batch_size = batch_size , shuffle = True , ** kwargs ) test_dataloader = torch . utils . data . DataLoader ( test_data , batch_size = batch_size , shuffle = True , ** kwargs ) # Define the model class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv1 = nn . Conv2d ( 1 , 20 , 5 , 1 ) self . conv2 = nn . Conv2d ( 20 , 50 , 5 , 1 ) self . fc1 = nn . Linear ( 4 * 4 * 50 , 500 ) self . fc2 = nn . Linear ( 500 , n_classes ) def forward ( self , x ): x = nn_func . relu ( self . conv1 ( x . view ( - 1 , 1 , height , width ))) x = nn_func . max_pool2d ( x , 2 , 2 ) x = nn_func . relu ( self . conv2 ( x )) x = nn_func . max_pool2d ( x , 2 , 2 ) x = x . view ( - 1 , 4 * 4 * 50 ) x = nn_func . relu ( self . fc1 ( x )) x = self . fc2 ( x ) return nn_func . log_softmax ( x , dim = 1 ) model = Net () opt = torch . optim . Adam ( model . parameters (), lr = learning_rate ) criterion = torch . nn . NLLLoss () # Train and evaluate the model for round in range ( n_rounds ): # train model model . train () for batch_idx , ( data , labels ) in enumerate ( train_dataloader ): opt . zero_grad () # Data needs to be on same device as model data = data . to ( device ) labels = labels . to ( device ) output = model ( data ) loss = criterion ( output , labels ) loss . backward () opt . step () # evaluate model model . eval () total_score = 0 all_labels = [] all_outputs = [] with torch . no_grad (): for batch_idx , ( data , labels ) in enumerate ( test_dataloader ): if batch_idx == num_test_batches : break data = data . to ( device ) labels = labels . to ( device ) output = model ( data ) total_score += criterion ( output , labels ) avg_loss = float ( total_score / ( num_test_batches * batch_size )) print ( f \"Average loss at round { round } is { avg_loss } \" ) There are three steps: Load the data Define the model Train the model In this tutorial we are going to see how to modify each step to use collective learning. We'll end up with code like this: # ------------------------------------------------------------------------------ # # Copyright 2021 Fetch.AI Limited # # Licensed under the Creative Commons Attribution-NonCommercial International # License, Version 4.0 (the \"License\"); you may not use this file except in # compliance with the License. You may obtain a copy of the License at # # http://creativecommons.org/licenses/by-nc/4.0/legalcode # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # ------------------------------------------------------------------------------ import os from typing_extensions import TypedDict import torch.nn as nn import torch.nn.functional as nn_func import torch.utils.data from torchsummary import summary from torchvision import transforms , datasets from colearn.training import initial_result , collective_learning_round , set_equal_weights from colearn.utils.plot import ColearnPlot from colearn.utils.results import Results , print_results from colearn_pytorch.utils import categorical_accuracy from colearn_pytorch.pytorch_learner import PytorchLearner \"\"\" MNIST training example using PyTorch Used dataset: - MNIST is set of 60 000 black and white hand written digits images of size 28x28x1 in 10 classes What script does: - Loads MNIST dataset from torchvision.datasets - Randomly splits dataset between multiple learners - Does multiple rounds of learning process and displays plot with results \"\"\" # define some constants n_learners = 5 batch_size = 64 testing_mode = bool ( os . getenv ( \"COLEARN_EXAMPLES_TEST\" , \"\" )) # for testing n_rounds = 20 if not testing_mode else 1 vote_threshold = 0.5 train_fraction = 0.9 vote_fraction = 0.05 learning_rate = 0.001 height = 28 width = 28 n_classes = 10 vote_batches = 2 score_name = \"categorical accuracy\" no_cuda = False cuda = not no_cuda and torch . cuda . is_available () device = torch . device ( \"cuda\" if cuda else \"cpu\" ) DataloaderKwargs = TypedDict ( 'DataloaderKwargs' , { 'num_workers' : int , 'pin_memory' : bool }, total = False ) kwargs : DataloaderKwargs = { 'num_workers' : 1 , 'pin_memory' : True } if cuda else {} # Load the data and split for each learner. DATA_DIR = os . environ . get ( 'PYTORCH_DATA_DIR' , os . path . expanduser ( os . path . join ( '~' , 'pytorch_datasets' ))) data = datasets . MNIST ( DATA_DIR , transform = transforms . ToTensor (), download = True ) n_train = int ( train_fraction * len ( data )) n_vote = int ( vote_fraction * len ( data )) n_test = len ( data ) - n_train - n_vote train_data , vote_data , test_data = torch . utils . data . random_split ( data , [ n_train , n_vote , n_test ]) data_split = [ len ( train_data ) // n_learners ] * n_learners learner_train_data = torch . utils . data . random_split ( train_data , data_split ) learner_train_dataloaders = [ torch . utils . data . DataLoader ( ds , batch_size = batch_size , shuffle = True , ** kwargs ) for ds in learner_train_data ] data_split = [ len ( vote_data ) // n_learners ] * n_learners learner_vote_data = torch . utils . data . random_split ( vote_data , data_split ) learner_vote_dataloaders = [ torch . utils . data . DataLoader ( ds , batch_size = batch_size , shuffle = True , ** kwargs ) for ds in learner_vote_data ] data_split = [ len ( test_data ) // n_learners ] * n_learners learner_test_data = torch . utils . data . random_split ( test_data , data_split ) learner_test_dataloaders = [ torch . utils . data . DataLoader ( ds , batch_size = batch_size , shuffle = True , ** kwargs ) for ds in learner_test_data ] # Define the model class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv1 = nn . Conv2d ( 1 , 20 , 5 , 1 ) self . conv2 = nn . Conv2d ( 20 , 50 , 5 , 1 ) self . fc1 = nn . Linear ( 4 * 4 * 50 , 500 ) self . fc2 = nn . Linear ( 500 , n_classes ) def forward ( self , x ): x = nn_func . relu ( self . conv1 ( x . view ( - 1 , 1 , height , width ))) x = nn_func . max_pool2d ( x , 2 , 2 ) x = nn_func . relu ( self . conv2 ( x )) x = nn_func . max_pool2d ( x , 2 , 2 ) x = x . view ( - 1 , 4 * 4 * 50 ) x = nn_func . relu ( self . fc1 ( x )) x = self . fc2 ( x ) return nn_func . log_softmax ( x , dim = 1 ) # Make n instances of PytorchLearner with model and torch dataloaders all_learner_models = [] for i in range ( n_learners ): model = Net () . to ( device ) opt = torch . optim . Adam ( model . parameters (), lr = learning_rate ) learner = PytorchLearner ( model = model , train_loader = learner_train_dataloaders [ i ], vote_loader = learner_vote_dataloaders [ i ], test_loader = learner_test_dataloaders [ i ], device = device , optimizer = opt , criterion = torch . nn . NLLLoss (), num_test_batches = vote_batches , vote_criterion = categorical_accuracy , minimise_criterion = False ) all_learner_models . append ( learner ) # Ensure all learners starts with exactly same weights set_equal_weights ( all_learner_models ) summary ( all_learner_models [ 0 ] . model , input_size = ( width , height ), device = str ( device )) # Train the model using Collective Learning results = Results () results . data . append ( initial_result ( all_learner_models )) plot = ColearnPlot ( score_name = score_name ) for round_index in range ( n_rounds ): results . data . append ( collective_learning_round ( all_learner_models , vote_threshold , round_index ) ) print_results ( results ) plot . plot_results_and_votes ( results ) plot . block () print ( \"Colearn Example Finished!\" ) The first thing is to modify the data loading code. Each learner needs to have their own training and testing set from the data. This is easy to do with the pytorch random_split utility: data_split = [ len ( test_data ) // n_learners ] * n_learners learner_test_data = torch . utils . data . random_split ( test_data , data_split ) The model definition is the same as before. To use collective learning, we need to create an object that implements the MachineLearningInterface. To make it easier to use the MachineLearningInterface with pytorch, we've defined PytorchLearner . PytorchLearner implements standard training and evaluation routines as well as the MachineLearningInterface methods. # ------------------------------------------------------------------------------ # # Copyright 2021 Fetch.AI Limited # # Licensed under the Creative Commons Attribution-NonCommercial International # License, Version 4.0 (the \"License\"); you may not use this file except in # compliance with the License. You may obtain a copy of the License at # # http://creativecommons.org/licenses/by-nc/4.0/legalcode # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # ------------------------------------------------------------------------------ from typing import Optional , Callable from collections import OrderedDict , defaultdict try : import torch except ImportError : raise Exception ( \"Pytorch is not installed. To use the pytorch \" \"add-ons please install colearn with `pip install colearn[pytorch]`.\" ) import torch.nn import torch.optim import torch.utils import torch.utils.data from torch.nn.modules.loss import _Loss from colearn.ml_interface import ( MachineLearningInterface , Weights , ProposedWeights , ColearnModel , convert_model_to_onnx , ModelFormat , DiffPrivBudget , DiffPrivConfig , TrainingSummary , ErrorCodes , ) from opacus import PrivacyEngine _DEFAULT_DEVICE = torch . device ( \"cpu\" ) class PytorchLearner ( MachineLearningInterface ): \"\"\" Pytorch learner implementation of machine learning interface \"\"\" def __init__ ( self , model : torch . nn . Module , optimizer : torch . optim . Optimizer , train_loader : torch . utils . data . DataLoader , vote_loader : torch . utils . data . DataLoader , test_loader : Optional [ torch . utils . data . DataLoader ] = None , need_reset_optimizer : bool = True , device = _DEFAULT_DEVICE , criterion : Optional [ _Loss ] = None , minimise_criterion = True , vote_criterion : Optional [ Callable [[ torch . Tensor , torch . Tensor ], float ]] = None , num_train_batches : Optional [ int ] = None , num_test_batches : Optional [ int ] = None , diff_priv_config : Optional [ DiffPrivConfig ] = None , ): \"\"\" :param model: Pytorch model used for training :param optimizer: Training optimizer :param train_loader: Train dataset :param test_loader: Optional test dataset - subset of training set will be used if not specified :param need_reset_optimizer: True to clear optimizer history before training, False to kepp history. :param device: Pytorch device - CPU or GPU :param criterion: Loss function :param minimise_criterion: True to minimise value of criterion, False to maximise :param vote_criterion: Function to measure model performance for voting :param num_train_batches: Number of training batches :param num_test_batches: Number of testing batches :param diff_priv_config: Contains differential privacy (dp) budget related configuration \"\"\" # Model has to be on same device as data self . model : torch . nn . Module = model . to ( device ) self . optimizer : torch . optim . Optimizer = optimizer self . criterion = criterion self . train_loader : torch . utils . data . DataLoader = train_loader self . vote_loader : torch . utils . data . DataLoader = vote_loader self . test_loader : Optional [ torch . utils . data . DataLoader ] = test_loader self . need_reset_optimizer = need_reset_optimizer self . device = device self . num_train_batches = num_train_batches or len ( train_loader ) self . num_test_batches = num_test_batches self . minimise_criterion = minimise_criterion self . vote_criterion = vote_criterion self . dp_config = diff_priv_config self . dp_privacy_engine = PrivacyEngine () if diff_priv_config is not None : ( self . model , self . optimizer , self . train_loader , ) = self . dp_privacy_engine . make_private ( module = self . model , optimizer = self . optimizer , data_loader = self . train_loader , max_grad_norm = diff_priv_config . max_grad_norm , noise_multiplier = diff_priv_config . noise_multiplier , ) self . vote_score = self . test ( self . vote_loader ) def mli_get_current_weights ( self ) -> Weights : \"\"\" :return: The current weights of the model \"\"\" current_state_dict = OrderedDict () for key in self . model . state_dict (): current_state_dict [ key ] = self . model . state_dict ()[ key ] . clone () w = Weights ( weights = current_state_dict , training_summary = self . get_training_summary () ) return w def mli_get_current_model ( self ) -> ColearnModel : \"\"\" :return: The current model and its format \"\"\" return ColearnModel ( model_format = ModelFormat ( ModelFormat . ONNX ), model_file = \"\" , model = convert_model_to_onnx ( self . model ), ) def set_weights ( self , weights : Weights ): \"\"\" Rewrites weight of current model :param weights: Weights to be stored \"\"\" self . model . load_state_dict ( weights . weights ) def reset_optimizer ( self ): \"\"\" Clear optimizer state, such as number of iterations, momentums. This way, the outdated history can be erased. \"\"\" self . optimizer . __setstate__ ({ \"state\" : defaultdict ( dict )}) def train ( self ): \"\"\" Trains the model on the training dataset \"\"\" if self . need_reset_optimizer : # erase the outdated optimizer memory (momentums mostly) self . reset_optimizer () self . model . train () for batch_idx , ( data , labels ) in enumerate ( self . train_loader ): if batch_idx == self . num_train_batches : break self . optimizer . zero_grad () # Data needs to be on same device as model data = data . to ( self . device ) labels = labels . to ( self . device ) output = self . model ( data ) loss = self . criterion ( output , labels ) loss . backward () self . optimizer . step () def mli_propose_weights ( self ) -> Weights : \"\"\" Trains model on training set and returns new weights after training - Current model is reverted to original state after training :return: Weights after training \"\"\" current_weights = self . mli_get_current_weights () training_summary = current_weights . training_summary if ( training_summary is not None and training_summary . error_code is not None and training_summary . error_code == ErrorCodes . DP_BUDGET_EXCEEDED ): return current_weights self . train () new_weights = self . mli_get_current_weights () self . set_weights ( current_weights ) training_summary = new_weights . training_summary if ( training_summary is not None and training_summary . error_code is not None and training_summary . error_code == ErrorCodes . DP_BUDGET_EXCEEDED ): current_weights . training_summary = training_summary return current_weights return new_weights def mli_test_weights ( self , weights : Weights ) -> ProposedWeights : \"\"\" Tests given weights on training and test set and returns weights with score values :param weights: Weights to be tested :return: ProposedWeights - Weights with vote and test score \"\"\" current_weights = self . mli_get_current_weights () self . set_weights ( weights ) vote_score = self . test ( self . vote_loader ) if self . test_loader : test_score = self . test ( self . test_loader ) else : test_score = 0 vote = self . vote ( vote_score ) self . set_weights ( current_weights ) return ProposedWeights ( weights = weights , vote_score = vote_score , test_score = test_score , vote = vote ) def vote ( self , new_score ) -> bool : \"\"\" Compares current model score with proposed model score and returns vote :param new_score: Proposed score :return: bool positive or negative vote \"\"\" if self . minimise_criterion : return new_score < self . vote_score else : return new_score > self . vote_score def test ( self , loader : torch . utils . data . DataLoader ) -> float : \"\"\" Tests performance of the model on specified dataset :param loader: Dataset for testing :return: Value of performance metric \"\"\" if not self . criterion : raise Exception ( \"Criterion is unspecified so test method cannot be used\" ) self . model . eval () total_score = 0 all_labels = [] all_outputs = [] batch_idx = 0 total_samples = 0 with torch . no_grad (): for batch_idx , ( data , labels ) in enumerate ( loader ): total_samples += labels . shape [ 0 ] if self . num_test_batches and batch_idx == self . num_test_batches : break data = data . to ( self . device ) labels = labels . to ( self . device ) output = self . model ( data ) if self . vote_criterion is not None : all_labels . append ( labels ) all_outputs . append ( output ) else : total_score += self . criterion ( output , labels ) . item () if batch_idx == 0 : raise Exception ( \"No batches in loader\" ) if self . vote_criterion is None : return float ( total_score / total_samples ) else : return self . vote_criterion ( torch . cat ( all_outputs , dim = 0 ), torch . cat ( all_labels , dim = 0 ) ) def mli_accept_weights ( self , weights : Weights ): \"\"\" Updates the model with the proposed set of weights :param weights: The new weights \"\"\" self . set_weights ( weights ) self . vote_score = self . test ( self . vote_loader ) def get_training_summary ( self ) -> Optional [ TrainingSummary ]: \"\"\" Differential Privacy Budget :return: the target and consumed epsilon so far \"\"\" if self . dp_config is None : return None delta = self . dp_config . target_delta target_epsilon = self . dp_config . target_epsilon consumed_epsilon = self . dp_privacy_engine . get_epsilon ( delta ) budget = DiffPrivBudget ( target_epsilon = target_epsilon , consumed_epsilon = consumed_epsilon , target_delta = delta , consumed_delta = delta , # delta is constatnt per training ) err = ( ErrorCodes . DP_BUDGET_EXCEEDED if consumed_epsilon >= target_epsilon else None ) return TrainingSummary ( dp_budget = budget , error_code = err , ) We create a set of PytorchLearners by passing in the model and the datasets: all_learner_models = [] for i in range ( n_learners ): model = Net () opt = torch . optim . Adam ( model . parameters (), lr = learning_rate ) learner = PytorchLearner ( model = model , train_loader = learner_train_dataloaders [ i ], vote_loader = learner_vote_dataloaders [ i ], test_loader = learner_test_dataloaders [ i ], device = device , optimizer = opt , criterion = torch . nn . NLLLoss (), num_test_batches = vote_batches , vote_criterion = categorical_accuracy , minimise_criterion = False ) all_learner_models . append ( learner ) Then we give all the models the same weights to start off with: set_equal_weights ( all_learner_models ) And then we can move on to the final stage, which is training with Collective Learning. The function collective_learning_round performs one round of collective learning. One learner is selected to train and propose an update. The other learners vote on the update, and if the vote passes then the update is accepted. Then a new round begins. # Train the model using Collective Learning results = Results () results . data . append ( initial_result ( all_learner_models )) for round in range ( n_rounds ): results . data . append ( collective_learning_round ( all_learner_models , vote_threshold , round ) ) plot_results ( results , n_learners , score_name = score_name ) plot_votes ( results ) # Plot the final result with votes plot_results ( results , n_learners , score_name = score_name ) plot_votes ( results , block = True )","title":"PyTorch"},{"location":"intro_tutorial_pytorch/#using-collective-learning-with-pytorch","text":"This tutorial is a simple guide to trying out the collective learning protocol with your own machine learning code. Everything runs locally. The most flexible way to use the collective learning backends is to make a class that implements the Collective Learning MachineLearningInterface defined in ml_interface.py . For more details on how to use the MachineLearningInterface see here However, the simpler way is to use one of the helper classes that we have provided that implement most of the interface for popular ML libraries. In this tutorial we are going to walk through using the PytorchLearner . First we are going to define the model architecture, then we are going to load the data and configure the model, and then we will run Collective Learning. A standard script for machine learning with Pytorch looks like the one below # ------------------------------------------------------------------------------ # # Copyright 2021 Fetch.AI Limited # # Licensed under the Creative Commons Attribution-NonCommercial International # License, Version 4.0 (the \"License\"); you may not use this file except in # compliance with the License. You may obtain a copy of the License at # # http://creativecommons.org/licenses/by-nc/4.0/legalcode # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # ------------------------------------------------------------------------------ from torchsummary import summary from torchvision import transforms , datasets import torch.utils.data import torch.nn as nn import torch.nn.functional as nn_func # define some constants batch_size = 64 seed = 42 n_rounds = 20 train_fraction = 0.9 learning_rate = 0.001 height = 28 width = 28 n_classes = 10 num_test_batches = 10 no_cuda = False cuda = not no_cuda and torch . cuda . is_available () device = torch . device ( \"cuda\" if cuda else \"cpu\" ) kwargs = { 'num_workers' : 1 , 'pin_memory' : True } if cuda else {} # Load the data data = datasets . MNIST ( '/tmp/mnist' , transform = transforms . ToTensor (), download = True ) n_train = int ( train_fraction * len ( data )) n_test = len ( data ) - n_train train_data , test_data = torch . utils . data . random_split ( data , [ n_train , n_test ]) train_dataloader = torch . utils . data . DataLoader ( train_data , batch_size = batch_size , shuffle = True , ** kwargs ) test_dataloader = torch . utils . data . DataLoader ( test_data , batch_size = batch_size , shuffle = True , ** kwargs ) # Define the model class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv1 = nn . Conv2d ( 1 , 20 , 5 , 1 ) self . conv2 = nn . Conv2d ( 20 , 50 , 5 , 1 ) self . fc1 = nn . Linear ( 4 * 4 * 50 , 500 ) self . fc2 = nn . Linear ( 500 , n_classes ) def forward ( self , x ): x = nn_func . relu ( self . conv1 ( x . view ( - 1 , 1 , height , width ))) x = nn_func . max_pool2d ( x , 2 , 2 ) x = nn_func . relu ( self . conv2 ( x )) x = nn_func . max_pool2d ( x , 2 , 2 ) x = x . view ( - 1 , 4 * 4 * 50 ) x = nn_func . relu ( self . fc1 ( x )) x = self . fc2 ( x ) return nn_func . log_softmax ( x , dim = 1 ) model = Net () opt = torch . optim . Adam ( model . parameters (), lr = learning_rate ) criterion = torch . nn . NLLLoss () # Train and evaluate the model for round in range ( n_rounds ): # train model model . train () for batch_idx , ( data , labels ) in enumerate ( train_dataloader ): opt . zero_grad () # Data needs to be on same device as model data = data . to ( device ) labels = labels . to ( device ) output = model ( data ) loss = criterion ( output , labels ) loss . backward () opt . step () # evaluate model model . eval () total_score = 0 all_labels = [] all_outputs = [] with torch . no_grad (): for batch_idx , ( data , labels ) in enumerate ( test_dataloader ): if batch_idx == num_test_batches : break data = data . to ( device ) labels = labels . to ( device ) output = model ( data ) total_score += criterion ( output , labels ) avg_loss = float ( total_score / ( num_test_batches * batch_size )) print ( f \"Average loss at round { round } is { avg_loss } \" ) There are three steps: Load the data Define the model Train the model In this tutorial we are going to see how to modify each step to use collective learning. We'll end up with code like this: # ------------------------------------------------------------------------------ # # Copyright 2021 Fetch.AI Limited # # Licensed under the Creative Commons Attribution-NonCommercial International # License, Version 4.0 (the \"License\"); you may not use this file except in # compliance with the License. You may obtain a copy of the License at # # http://creativecommons.org/licenses/by-nc/4.0/legalcode # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # ------------------------------------------------------------------------------ import os from typing_extensions import TypedDict import torch.nn as nn import torch.nn.functional as nn_func import torch.utils.data from torchsummary import summary from torchvision import transforms , datasets from colearn.training import initial_result , collective_learning_round , set_equal_weights from colearn.utils.plot import ColearnPlot from colearn.utils.results import Results , print_results from colearn_pytorch.utils import categorical_accuracy from colearn_pytorch.pytorch_learner import PytorchLearner \"\"\" MNIST training example using PyTorch Used dataset: - MNIST is set of 60 000 black and white hand written digits images of size 28x28x1 in 10 classes What script does: - Loads MNIST dataset from torchvision.datasets - Randomly splits dataset between multiple learners - Does multiple rounds of learning process and displays plot with results \"\"\" # define some constants n_learners = 5 batch_size = 64 testing_mode = bool ( os . getenv ( \"COLEARN_EXAMPLES_TEST\" , \"\" )) # for testing n_rounds = 20 if not testing_mode else 1 vote_threshold = 0.5 train_fraction = 0.9 vote_fraction = 0.05 learning_rate = 0.001 height = 28 width = 28 n_classes = 10 vote_batches = 2 score_name = \"categorical accuracy\" no_cuda = False cuda = not no_cuda and torch . cuda . is_available () device = torch . device ( \"cuda\" if cuda else \"cpu\" ) DataloaderKwargs = TypedDict ( 'DataloaderKwargs' , { 'num_workers' : int , 'pin_memory' : bool }, total = False ) kwargs : DataloaderKwargs = { 'num_workers' : 1 , 'pin_memory' : True } if cuda else {} # Load the data and split for each learner. DATA_DIR = os . environ . get ( 'PYTORCH_DATA_DIR' , os . path . expanduser ( os . path . join ( '~' , 'pytorch_datasets' ))) data = datasets . MNIST ( DATA_DIR , transform = transforms . ToTensor (), download = True ) n_train = int ( train_fraction * len ( data )) n_vote = int ( vote_fraction * len ( data )) n_test = len ( data ) - n_train - n_vote train_data , vote_data , test_data = torch . utils . data . random_split ( data , [ n_train , n_vote , n_test ]) data_split = [ len ( train_data ) // n_learners ] * n_learners learner_train_data = torch . utils . data . random_split ( train_data , data_split ) learner_train_dataloaders = [ torch . utils . data . DataLoader ( ds , batch_size = batch_size , shuffle = True , ** kwargs ) for ds in learner_train_data ] data_split = [ len ( vote_data ) // n_learners ] * n_learners learner_vote_data = torch . utils . data . random_split ( vote_data , data_split ) learner_vote_dataloaders = [ torch . utils . data . DataLoader ( ds , batch_size = batch_size , shuffle = True , ** kwargs ) for ds in learner_vote_data ] data_split = [ len ( test_data ) // n_learners ] * n_learners learner_test_data = torch . utils . data . random_split ( test_data , data_split ) learner_test_dataloaders = [ torch . utils . data . DataLoader ( ds , batch_size = batch_size , shuffle = True , ** kwargs ) for ds in learner_test_data ] # Define the model class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv1 = nn . Conv2d ( 1 , 20 , 5 , 1 ) self . conv2 = nn . Conv2d ( 20 , 50 , 5 , 1 ) self . fc1 = nn . Linear ( 4 * 4 * 50 , 500 ) self . fc2 = nn . Linear ( 500 , n_classes ) def forward ( self , x ): x = nn_func . relu ( self . conv1 ( x . view ( - 1 , 1 , height , width ))) x = nn_func . max_pool2d ( x , 2 , 2 ) x = nn_func . relu ( self . conv2 ( x )) x = nn_func . max_pool2d ( x , 2 , 2 ) x = x . view ( - 1 , 4 * 4 * 50 ) x = nn_func . relu ( self . fc1 ( x )) x = self . fc2 ( x ) return nn_func . log_softmax ( x , dim = 1 ) # Make n instances of PytorchLearner with model and torch dataloaders all_learner_models = [] for i in range ( n_learners ): model = Net () . to ( device ) opt = torch . optim . Adam ( model . parameters (), lr = learning_rate ) learner = PytorchLearner ( model = model , train_loader = learner_train_dataloaders [ i ], vote_loader = learner_vote_dataloaders [ i ], test_loader = learner_test_dataloaders [ i ], device = device , optimizer = opt , criterion = torch . nn . NLLLoss (), num_test_batches = vote_batches , vote_criterion = categorical_accuracy , minimise_criterion = False ) all_learner_models . append ( learner ) # Ensure all learners starts with exactly same weights set_equal_weights ( all_learner_models ) summary ( all_learner_models [ 0 ] . model , input_size = ( width , height ), device = str ( device )) # Train the model using Collective Learning results = Results () results . data . append ( initial_result ( all_learner_models )) plot = ColearnPlot ( score_name = score_name ) for round_index in range ( n_rounds ): results . data . append ( collective_learning_round ( all_learner_models , vote_threshold , round_index ) ) print_results ( results ) plot . plot_results_and_votes ( results ) plot . block () print ( \"Colearn Example Finished!\" ) The first thing is to modify the data loading code. Each learner needs to have their own training and testing set from the data. This is easy to do with the pytorch random_split utility: data_split = [ len ( test_data ) // n_learners ] * n_learners learner_test_data = torch . utils . data . random_split ( test_data , data_split ) The model definition is the same as before. To use collective learning, we need to create an object that implements the MachineLearningInterface. To make it easier to use the MachineLearningInterface with pytorch, we've defined PytorchLearner . PytorchLearner implements standard training and evaluation routines as well as the MachineLearningInterface methods. # ------------------------------------------------------------------------------ # # Copyright 2021 Fetch.AI Limited # # Licensed under the Creative Commons Attribution-NonCommercial International # License, Version 4.0 (the \"License\"); you may not use this file except in # compliance with the License. You may obtain a copy of the License at # # http://creativecommons.org/licenses/by-nc/4.0/legalcode # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # ------------------------------------------------------------------------------ from typing import Optional , Callable from collections import OrderedDict , defaultdict try : import torch except ImportError : raise Exception ( \"Pytorch is not installed. To use the pytorch \" \"add-ons please install colearn with `pip install colearn[pytorch]`.\" ) import torch.nn import torch.optim import torch.utils import torch.utils.data from torch.nn.modules.loss import _Loss from colearn.ml_interface import ( MachineLearningInterface , Weights , ProposedWeights , ColearnModel , convert_model_to_onnx , ModelFormat , DiffPrivBudget , DiffPrivConfig , TrainingSummary , ErrorCodes , ) from opacus import PrivacyEngine _DEFAULT_DEVICE = torch . device ( \"cpu\" ) class PytorchLearner ( MachineLearningInterface ): \"\"\" Pytorch learner implementation of machine learning interface \"\"\" def __init__ ( self , model : torch . nn . Module , optimizer : torch . optim . Optimizer , train_loader : torch . utils . data . DataLoader , vote_loader : torch . utils . data . DataLoader , test_loader : Optional [ torch . utils . data . DataLoader ] = None , need_reset_optimizer : bool = True , device = _DEFAULT_DEVICE , criterion : Optional [ _Loss ] = None , minimise_criterion = True , vote_criterion : Optional [ Callable [[ torch . Tensor , torch . Tensor ], float ]] = None , num_train_batches : Optional [ int ] = None , num_test_batches : Optional [ int ] = None , diff_priv_config : Optional [ DiffPrivConfig ] = None , ): \"\"\" :param model: Pytorch model used for training :param optimizer: Training optimizer :param train_loader: Train dataset :param test_loader: Optional test dataset - subset of training set will be used if not specified :param need_reset_optimizer: True to clear optimizer history before training, False to kepp history. :param device: Pytorch device - CPU or GPU :param criterion: Loss function :param minimise_criterion: True to minimise value of criterion, False to maximise :param vote_criterion: Function to measure model performance for voting :param num_train_batches: Number of training batches :param num_test_batches: Number of testing batches :param diff_priv_config: Contains differential privacy (dp) budget related configuration \"\"\" # Model has to be on same device as data self . model : torch . nn . Module = model . to ( device ) self . optimizer : torch . optim . Optimizer = optimizer self . criterion = criterion self . train_loader : torch . utils . data . DataLoader = train_loader self . vote_loader : torch . utils . data . DataLoader = vote_loader self . test_loader : Optional [ torch . utils . data . DataLoader ] = test_loader self . need_reset_optimizer = need_reset_optimizer self . device = device self . num_train_batches = num_train_batches or len ( train_loader ) self . num_test_batches = num_test_batches self . minimise_criterion = minimise_criterion self . vote_criterion = vote_criterion self . dp_config = diff_priv_config self . dp_privacy_engine = PrivacyEngine () if diff_priv_config is not None : ( self . model , self . optimizer , self . train_loader , ) = self . dp_privacy_engine . make_private ( module = self . model , optimizer = self . optimizer , data_loader = self . train_loader , max_grad_norm = diff_priv_config . max_grad_norm , noise_multiplier = diff_priv_config . noise_multiplier , ) self . vote_score = self . test ( self . vote_loader ) def mli_get_current_weights ( self ) -> Weights : \"\"\" :return: The current weights of the model \"\"\" current_state_dict = OrderedDict () for key in self . model . state_dict (): current_state_dict [ key ] = self . model . state_dict ()[ key ] . clone () w = Weights ( weights = current_state_dict , training_summary = self . get_training_summary () ) return w def mli_get_current_model ( self ) -> ColearnModel : \"\"\" :return: The current model and its format \"\"\" return ColearnModel ( model_format = ModelFormat ( ModelFormat . ONNX ), model_file = \"\" , model = convert_model_to_onnx ( self . model ), ) def set_weights ( self , weights : Weights ): \"\"\" Rewrites weight of current model :param weights: Weights to be stored \"\"\" self . model . load_state_dict ( weights . weights ) def reset_optimizer ( self ): \"\"\" Clear optimizer state, such as number of iterations, momentums. This way, the outdated history can be erased. \"\"\" self . optimizer . __setstate__ ({ \"state\" : defaultdict ( dict )}) def train ( self ): \"\"\" Trains the model on the training dataset \"\"\" if self . need_reset_optimizer : # erase the outdated optimizer memory (momentums mostly) self . reset_optimizer () self . model . train () for batch_idx , ( data , labels ) in enumerate ( self . train_loader ): if batch_idx == self . num_train_batches : break self . optimizer . zero_grad () # Data needs to be on same device as model data = data . to ( self . device ) labels = labels . to ( self . device ) output = self . model ( data ) loss = self . criterion ( output , labels ) loss . backward () self . optimizer . step () def mli_propose_weights ( self ) -> Weights : \"\"\" Trains model on training set and returns new weights after training - Current model is reverted to original state after training :return: Weights after training \"\"\" current_weights = self . mli_get_current_weights () training_summary = current_weights . training_summary if ( training_summary is not None and training_summary . error_code is not None and training_summary . error_code == ErrorCodes . DP_BUDGET_EXCEEDED ): return current_weights self . train () new_weights = self . mli_get_current_weights () self . set_weights ( current_weights ) training_summary = new_weights . training_summary if ( training_summary is not None and training_summary . error_code is not None and training_summary . error_code == ErrorCodes . DP_BUDGET_EXCEEDED ): current_weights . training_summary = training_summary return current_weights return new_weights def mli_test_weights ( self , weights : Weights ) -> ProposedWeights : \"\"\" Tests given weights on training and test set and returns weights with score values :param weights: Weights to be tested :return: ProposedWeights - Weights with vote and test score \"\"\" current_weights = self . mli_get_current_weights () self . set_weights ( weights ) vote_score = self . test ( self . vote_loader ) if self . test_loader : test_score = self . test ( self . test_loader ) else : test_score = 0 vote = self . vote ( vote_score ) self . set_weights ( current_weights ) return ProposedWeights ( weights = weights , vote_score = vote_score , test_score = test_score , vote = vote ) def vote ( self , new_score ) -> bool : \"\"\" Compares current model score with proposed model score and returns vote :param new_score: Proposed score :return: bool positive or negative vote \"\"\" if self . minimise_criterion : return new_score < self . vote_score else : return new_score > self . vote_score def test ( self , loader : torch . utils . data . DataLoader ) -> float : \"\"\" Tests performance of the model on specified dataset :param loader: Dataset for testing :return: Value of performance metric \"\"\" if not self . criterion : raise Exception ( \"Criterion is unspecified so test method cannot be used\" ) self . model . eval () total_score = 0 all_labels = [] all_outputs = [] batch_idx = 0 total_samples = 0 with torch . no_grad (): for batch_idx , ( data , labels ) in enumerate ( loader ): total_samples += labels . shape [ 0 ] if self . num_test_batches and batch_idx == self . num_test_batches : break data = data . to ( self . device ) labels = labels . to ( self . device ) output = self . model ( data ) if self . vote_criterion is not None : all_labels . append ( labels ) all_outputs . append ( output ) else : total_score += self . criterion ( output , labels ) . item () if batch_idx == 0 : raise Exception ( \"No batches in loader\" ) if self . vote_criterion is None : return float ( total_score / total_samples ) else : return self . vote_criterion ( torch . cat ( all_outputs , dim = 0 ), torch . cat ( all_labels , dim = 0 ) ) def mli_accept_weights ( self , weights : Weights ): \"\"\" Updates the model with the proposed set of weights :param weights: The new weights \"\"\" self . set_weights ( weights ) self . vote_score = self . test ( self . vote_loader ) def get_training_summary ( self ) -> Optional [ TrainingSummary ]: \"\"\" Differential Privacy Budget :return: the target and consumed epsilon so far \"\"\" if self . dp_config is None : return None delta = self . dp_config . target_delta target_epsilon = self . dp_config . target_epsilon consumed_epsilon = self . dp_privacy_engine . get_epsilon ( delta ) budget = DiffPrivBudget ( target_epsilon = target_epsilon , consumed_epsilon = consumed_epsilon , target_delta = delta , consumed_delta = delta , # delta is constatnt per training ) err = ( ErrorCodes . DP_BUDGET_EXCEEDED if consumed_epsilon >= target_epsilon else None ) return TrainingSummary ( dp_budget = budget , error_code = err , ) We create a set of PytorchLearners by passing in the model and the datasets: all_learner_models = [] for i in range ( n_learners ): model = Net () opt = torch . optim . Adam ( model . parameters (), lr = learning_rate ) learner = PytorchLearner ( model = model , train_loader = learner_train_dataloaders [ i ], vote_loader = learner_vote_dataloaders [ i ], test_loader = learner_test_dataloaders [ i ], device = device , optimizer = opt , criterion = torch . nn . NLLLoss (), num_test_batches = vote_batches , vote_criterion = categorical_accuracy , minimise_criterion = False ) all_learner_models . append ( learner ) Then we give all the models the same weights to start off with: set_equal_weights ( all_learner_models ) And then we can move on to the final stage, which is training with Collective Learning. The function collective_learning_round performs one round of collective learning. One learner is selected to train and propose an update. The other learners vote on the update, and if the vote passes then the update is accepted. Then a new round begins. # Train the model using Collective Learning results = Results () results . data . append ( initial_result ( all_learner_models )) for round in range ( n_rounds ): results . data . append ( collective_learning_round ( all_learner_models , vote_threshold , round ) ) plot_results ( results , n_learners , score_name = score_name ) plot_votes ( results ) # Plot the final result with votes plot_results ( results , n_learners , score_name = score_name ) plot_votes ( results , block = True )","title":"Using collective learning with pytorch"},{"location":"mli_factory/","text":"MLI Factory \u00b6 The machine learning interface factory are the minimum methods a client needs to implement to work with the GRPC Server (and become a Learner). There are two main types of functions: Supported Systems (get_models, get_dataloaders, get_compatibilities) Get a MachineLearningInterface (get_mli) When the GRPC server is connected to the Orchestrator, it will query the supported system functions to know what the MLI Factory can serve. Later when the Orchestrator wants to run something on this Learner it will call get_mli with a model_arch_name, a dataloader_name and more parameters for both. The object returned is then used to run the experiment through the MLI. Supported Systems \u00b6 The supported systems functions get_models and get_dataloaders should return a set of which will be stored (not currently implemented) in the api database. The idea being that the user can change these values on the UI while preparing to start/join an experiment. ExampleMliFactory \u00b6 An example MLIFactory that will implement all the tasks in run_demo. This is the one used by contract_learn.","title":"MLI Factory"},{"location":"mli_factory/#mli-factory","text":"The machine learning interface factory are the minimum methods a client needs to implement to work with the GRPC Server (and become a Learner). There are two main types of functions: Supported Systems (get_models, get_dataloaders, get_compatibilities) Get a MachineLearningInterface (get_mli) When the GRPC server is connected to the Orchestrator, it will query the supported system functions to know what the MLI Factory can serve. Later when the Orchestrator wants to run something on this Learner it will call get_mli with a model_arch_name, a dataloader_name and more parameters for both. The object returned is then used to run the experiment through the MLI.","title":"MLI Factory"},{"location":"mli_factory/#supported-systems","text":"The supported systems functions get_models and get_dataloaders should return a set of which will be stored (not currently implemented) in the api database. The idea being that the user can change these values on the UI while preparing to start/join an experiment.","title":"Supported Systems"},{"location":"mli_factory/#examplemlifactory","text":"An example MLIFactory that will implement all the tasks in run_demo. This is the one used by contract_learn.","title":"ExampleMliFactory"},{"location":"tasks/","text":"1. CIFAR10 dataset \u00b6 1.1. Information and installation \u00b6 1.1.1. Information about the dataset \u00b6 The CIFAR-10 dataset consists of 60000 32x32x3 colour images in 10 classes, with 6000 images per class. The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks Input for NN are raw 32x32 3 channels GRB images NN output is distribution of probabilities for each class i.e. 10 values that sums up to 1 Code folder: here Invoke parameter: -t CIFAR10 1.1.2. Requirements \u00b6 Cifar dataset is loaded from tensorflow.keras.datasets.cifar10 and no stored data are required 1.2. Models \u00b6 1.2.1. CIFAR10Conv Keras model \u00b6 _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) (32, 32, 3) 0 _________________________________________________________________ Conv1_1 (Conv2D) (32, 32, 64) 1792 bn1_1 (BatchNormalization) (32, 32, 64) 256 Conv1_2 (Conv2D) (32, 32, 64) 36928 bn1_2 (BatchNormalization) (32, 32, 64) 256 pool1 (MaxPooling2D) (16, 16, 64) 0 _________________________________________________________________ Conv2_1 (Conv2D) (16, 16, 128 73856 bn2_1 (BatchNormalization) (16, 16, 128 512 Conv2_2 (Conv2D) (16, 16, 128 147584 bn2_2 (BatchNormalization) (16, 16, 128 512 pool2 (MaxPooling2D) (8, 8, 128) 0 _________________________________________________________________ Conv3_1 (Conv2D) (8, 8, 256) 295168 bn3_1 (BatchNormalization) (8, 8, 256) 1024 Conv3_2 (Conv2D) (8, 8, 256) 590080 bn3_2 (BatchNormalization) (8, 8, 256) 1024 Conv3_3 (Conv2D) (8, 8, 256) 590080 bn3_3 (BatchNormalization) (8, 8, 256) 1024 _________________________________________________________________ flatten (Flatten) (16384) 0 fc1 (Dense) (100) 1638500 fc2 (Dense) (10) 1010 ================================================================= Total params: 3,379,606 Trainable params: 3,377,302 Non-trainable params: 2,304 _________________________________________________________________ 1.2.2. CIFAR10Conv2 Keras model \u00b6 _________________________________________________________ Layer (type) Output Shape Param # ========================================================= Input (InputLayer) (32, 32, 3) 0 _________________________________________________________ Conv1_1 (Conv2D) (32, 32, 32) 896 Conv1_2 (Conv2D) (32, 32, 32) 9248 pool1 (MaxPooling2D) (16, 16, 32) 0 _________________________________________________________ Conv2_1 (Conv2D) (16, 16, 64) 18496 Conv2_2 (Conv2D) (16, 16, 64) 36928 pool2 (MaxPooling2D) (8, 8, 64) 0 _________________________________________________________ Conv3_1 (Conv2D) (8, 8, 128) 73856 Conv3_2 (Conv2D) (8, 8, 128) 147584 pool3 (MaxPooling2D) (4, 4, 128) 0 _________________________________________________________ flatten (Flatten) (2048) 0 fc1 (Dense) (128) 262272 fc2 (Dense) (10) 1290 ========================================================= Total params: 550,570 Trainable params: 550,570 Non-trainable params: 0 _________________________________________________________ 1.2.3. CIFAR10Resnet50 Keras model \u00b6 ________________________________________________________ Layer (type) Output Shape Param # ======================================================== Input (InputLayer) (32, 32, 3)] 0 ________________________________________________________ resnet50 (Model) (1, 1, 2048) 23587712 ________________________________________________________ Global_average_pooling2d (2048) 0 flatten (Flatten) (2048) 0 fc1 (Dense) (10) 20490 ======================================================== Total params: 23,608,202 Trainable params: 23,555,082 Non-trainable params: 53,120 ________________________________________________________ 2. Covid X-RAY dataset \u00b6 2.1. Information and installation \u00b6 2.1.1. Information about the dataset \u00b6 The Covid X-Ray dataset consists of grayscale images, there are 478 covid images and 203 normal images. To increase the number of images normal/pneumonia dataset is added Final dataset, which is a combination of two previously mentioned datasets, contains 1434 images, 478 images for each class. Images are cropped and resized to 512x512 pixel and spatial domain (Texture, GLDM, GLCM) and frequency domain (FFT and Wavelet) features are used to create 256 dimensional vector representation of each image. PCA is applied after to reduce dimensionality to 64 values which represents the first 64 highest eigenvalues of the covariance matrix. Input for NN are 64 values for each image NN output is distribution of probabilities for each class i.e. 3 values Code folder: here Invoke parameter: -t COVID 2.1.2 Requirements \u00b6 Download Covid dataset: here Download pneumonia dataset: here 2.2. Models \u00b6 2.2.1. Covid XRAY Keras model \u00b6 _________________________________________________________ Layer (type) Output Shape Param # ========================================================= input_1 (InputLayer) (64) 0 _________________________________________________________ dense (Dense) (128) 8320 dropout (Dropout) (128) 0 _________________________________________________________ dense_1 (Dense) (16) 2064 dropout_1 (Dropout) (16) 0 _________________________________________________________ dense_2 (Dense) (3) 51 ========================================================= Total params: 10,435 Trainable params: 10,435 Non-trainable params: 0 _________________________________________________________ 3. FRAUD dataset \u00b6 3.1. Information and installation \u00b6 3.1.1. Information about the dataset \u00b6 EEE-CIS Fraud Detection, contains multiple files with credit card transactions Raw dataset files are automatically merged and pre-processed and input files for neural network are created X.csv with data - has 431 values for each transaction Y.csv with labels - v has 1 value for each transaction 0 = not a fraud 1 = fraud Code folder: here Invoke parameter: -t FRAUD 3.1.2. Requirements \u00b6 Download dataset: here 3.2. Models \u00b6 3.2.1. FraudDense1 Keras model \u00b6 _________________________________________________________ Layer (type) Output Shape Param # ========================================================= Input (InputLayer) (431) 0 _________________________________________________________ dense (Dense) (512) 221184 Batch_normalization (512) 2048 _________________________________________________________ dense_1 (Dense) (512) 262656 Batch_normalization_1 (512) 2048 _________________________________________________________ dense_2 (Dense) (512) 262656 Batch_normalization_2 (512) 2048 _________________________________________________________ fc1 (Dense) (1) 513 ========================================================= Total params: 753,153 Trainable params: 750,081 Non-trainable params: 3,072 _________________________________________________________ 3.2.2. FraudSVM Scikit-learn model \u00b6 Model is defined as SGDClassifier(max_iter=1, verbose=0, loss=\"modified_huber\") Which is support vector machine linear classifier 4. MNIST \u00b6 4.1. Information and installation \u00b6 4.1.1. Information about the dataset \u00b6 This is a dataset of 70,000 28x28x1 grayscale images of the 10 digits Input for NN are raw 28x28 1 channel images NN output is distribution of probabilities for each class i.e. 10 values that sums up to 1 Code folder: here Invoke parameter: -t MNIST 4.1.2 Requirements \u00b6 MNIST dataset is loaded from tensorflow.keras.datasets.cifar10 and no stored data are required 4.2. Models \u00b6 4.2.1. MNISTConv Keras model \u00b6 _________________________________________________________ Layer (type) Output Shape Param # ========================================================= Input (InputLayer) (28, 28, 1) 0 _________________________________________________________ Conv1_1 (Conv2D) (28, 28, 64) 640 bn1 (BatchNormalization) (28, 28, 64) 256 pool1 (MaxPooling2D) (14, 14, 64) 0 _________________________________________________________ Conv2_1 (Conv2D) (14, 14, 128) 73856 bn4 (BatchNormalization) (14, 14, 128) 512 pool2 (MaxPooling2D) (7, 7, 128) 0 _________________________________________________________ flatten (Flatten) (6272) 0 fc1 (Dense) (10) 62730 ========================================================= Total params: 137,994 Trainable params: 137,610 Non-trainable params: 384 _________________________________________________________ 4.2.2. MNIST Pytorch model \u00b6 --------------------------------------------------------- Layer (type) Output Shape Param # ========================================================= Input [28,28,1] 0 Conv2d-1 [20, 24, 24] 520 Conv2d-2 [50, 8, 8] 25,050 Linear-3 [500] 400,500 Linear-4 [10] 5,010 ========================================================= Total params: 431,080 Trainable params: 431,080 Non-trainable params: 0 --------------------------------------------------------- 4.2.3. MNISTSupermini Keras model \u00b6 ________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ======================================================================================== input_1 (InputLayer) (28, 28, 1) 0 ________________________________________________________________________________________ conv2d (Conv2D) (26, 26, 8) 80 input_1[0][0] Batch_normalization (26, 26, 8) 32 conv2d[0][0] Max_pooling2d (13, 13, 8) 0 batch_normalization[0][0] dropout (Dropout) (13, 13, 8) 0 max_pooling2d[0][0] ________________________________________________________________________________________ Separable_conv2d (11, 11, 26) 306 dropout[0][0] batch_normalization_1 (11, 11, 26) 104 separable_conv2d[0][0] dropout_1 (Dropout) (11, 11, 26) 0 batch_normalization_1[0][0] ________________________________________________________________________________________ Separable_conv2d_1 (11, 11, 26) 936 dropout_1[0][0] dropout_2[0][0] dropout_3[0][0] ________________________________________________________________________________________ Batch_normalization_2 (11, 11, 26) 104 separable_conv2d_1[0][0] dropout_2 (Dropout) (11, 11, 26) 0 batch_normalization_2[0][0] ________________________________________________________________________________________ Batch_normalization_3 (11, 11, 26) 104 separable_conv2d_1[1][0] dropout_3 (Dropout) (11, 11, 26) 0 batch_normalization_3[0][0] ________________________________________________________________________________________ Batch_normalization_4 (11, 11, 26) 104 separable_conv2d_1[2][0] dropout_4 (Dropout) (11, 11, 26) 0 batch_normalization_4[0][0] ________________________________________________________________________________________ Global_average_pooling2d (26) 0 dropout_4[0][0] dense (Dense) (16) 432 global_average_pooling2d[0][0] Batch_normalization_5 (16) 64 dense[0][0] dropout_5 (Dropout) (16) 0 batch_normalization_5[0][0] dense_1 (Dense) (10) 170 dropout_5[0][0] ======================================================================================== Total params: 2,436 Trainable params: 2,180 Non-trainable params: 256 ________________________________________________________________________________________ 5. Pneumonia XRAY \u00b6 5.1. Information and installation \u00b6 5.1.1. Information about the dataset \u00b6 The Chest X-Ray Images (Pneumonia) dataset consists of 5856 grayscale images of various sizes in 2 classes (normal/pneumonia). Labels are determined by folder name - NORMAL or PNEUMONIA Input for NN are raw resized 128x128 1 channel images NN output is distribution of probabilities for each class i.e. 2 values Code folder: here Invoke parameter: -t XRAY 5.1.2 Requirements \u00b6 Download dataset: here 5.2. Models \u00b6 5.2.1. XraySupermini Keras model \u00b6 _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) [(128, 128, 1)] 0 _________________________________________________________________ Conv1_1 (Conv2D) (128, 128, 32) 320 _________________________________________________________________ bn1 (BatchNormalization) (128, 128, 32) 128 _________________________________________________________________ pool1 (MaxPooling2D) (32, 32, 32) 0 _________________________________________________________________ Conv2_1 (Conv2D) (32, 32, 64) 18496 _________________________________________________________________ bn2 (BatchNormalization) (32, 32, 64) 256 _________________________________________________________________ Global_max_pooling2d (64) 0 _________________________________________________________________ fc1 (Dense) (1) 65 ================================================================= Total params: 19,265 Trainable params: 19,073 Non-trainable params: 192 _________________________________________________________________ 5.2.2. XrayResnet50 Keras model \u00b6 _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) [(128, 128, 1)] 0 _________________________________________________________________ resnet50 (Model) (4, 4, 2048) 23581440 _________________________________________________________________ global_average_pooling2d (2048) 0 _________________________________________________________________ flatten (Flatten) (2048) 0 _________________________________________________________________ fc1 (Dense) (1) 2049 ================================================================= Total params: 23,583,489 Trainable params: 23,530,369 Non-trainable params: 53,120 _________________________________________________________________ 5.2.3. XrayPretrainedResnet50 Keras model \u00b6 _____________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ===================================================================================== Input (InputLayer) (128, 128, 1) 0 _____________________________________________________________________________________ concatenate (Concatenate) (128, 128, 3) 0 Input[0][0] Input[0][0] Input[0][0] _____________________________________________________________________________________ tf_op_layer_mul (128, 128, 3) 0 concatenate[0][0] tf_op_layer_strided_slice (128, 128, 3) 0 tf_op_layer_mul[0][0] tf_op_layer_BiasAdd (128, 128, 3) 0 tf_op_layer_strided_slice[0][0] _____________________________________________________________________________________ resnet50 (Model) (4, 4, 2048) 23587712 tf_op_layer_BiasAdd[0][0] _____________________________________________________________________________________ global_average_pooling2d (2048) 0 resnet50[1][0] flatten (Flatten) (2048) 0 global_average_pooling2d[0][0] _____________________________________________________________________________________ fc1 (Dense) (1) 2049 flatten[0][0] ===================================================================================== Total params: 23,589,761 Trainable params: 23,536,641 Non-trainable params: 53,120 _____________________________________________________________________________________ 5.2.4. XrayDropout Keras model \u00b6 _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) [(128, 128, 1)] 0 _________________________________________________________________ Conv1_1 (Conv2D) (128, 128, 128) 1280 bn1 (BatchNormalization) (128, 128, 128) 512 pool1 (MaxPooling2D) (32, 32, 128) 0 _________________________________________________________________ Conv2_1 (Conv2D) (32, 32, 256) 295168 bn2 (BatchNormalization) (32, 32, 256) 1024 pool2 (MaxPooling2D) (8, 8, 256) 0 _________________________________________________________________ flatten (Flatten) (16384) 0 fc1 (Dense) (128) 2097280 bn3 (BatchNormalization) (128) 512 dropout (Dropout) (128) 0 _________________________________________________________________ fc2 (Dense) (64) 8256 bn4 (BatchNormalization) (64) 256 dropout_1 (Dropout) (64) 0 _________________________________________________________________ fc3 (Dense) (1) 65 ================================================================= Total params: 2,404,353 Trainable params: 2,403,201 Non-trainable params: 1,152 _________________________________________________________________ 5.2.5. XrayDropout2 Keras model \u00b6 _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) (128, 128, 1) 0 _________________________________________________________________ Conv1_1 (Conv2D) (128, 128, 64) 640 bn1 (BatchNormalization) (128, 128, 64) 256 pool1 (MaxPooling2D) (64, 64, 64) 0 _________________________________________________________________ Conv2_1 (Conv2D) (64, 64, 128) 73856 bn2 (BatchNormalization) (64, 64, 128) 512 pool2 (MaxPooling2D) (32, 32, 128) 0 _________________________________________________________________ Conv3_1 (Conv2D) (32, 32, 256) 295168 bn3 (BatchNormalization) (32, 32, 256) 1024 pool3 (MaxPooling2D) (16, 16, 256) 0 _________________________________________________________________ Conv4_1 (Conv2D) (16, 16, 512) 1180160 bn4 (BatchNormalization) (16, 16, 512) 2048 pool4 (MaxPooling2D) (8, 8, 512) 0 _________________________________________________________________ Conv5_1 (Conv2D) (8, 8, 512) 2359808 bn5 (BatchNormalization) (8, 8, 512) 2048 pool5 (MaxPooling2D) (4, 4, 512) 0 _________________________________________________________________ flatten (Flatten) (8192) 0 fc1 (Dense) (256) 2097408 bn6 (BatchNormalization) (256) 1024 dropout (Dropout) (256) 0 _________________________________________________________________ fc2 (Dense) (128) 32896 bn7 (BatchNormalization) (128) 512 dropout_1 (Dropout) (128) 0 _________________________________________________________________ fc3 (Dense) (64) 8256 bn8 (BatchNormalization) (64) 256 dropout_2 (Dropout) (64) 0 _________________________________________________________________ fc4 (Dense) (1) 65 ================================================================= Total params: 6,055,937 Trainable params: 6,052,097 Non-trainable params: 3,840 _________________________________________________________________ 5.2.6. XrayVGG16 Keras model \u00b6 _____________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ===================================================================================== Input (InputLayer) (128, 128, 1) 0 _____________________________________________________________________________________ concatenate (Concatenate) (128, 128, 3) 0 Input[0][0] Input[0][0] Input[0][0] _____________________________________________________________________________________ tf_op_layer_mul (128, 128, 3) 0 concatenate[0][0] Tf_op_layer_strided_slice (28, 128, 3) 0 tf_op_layer_mul[0][0] tf_op_layer_BiasAdd (128, 128, 3) 0 tf_op_layer_strided_slice[0][0] _____________________________________________________________________________________ vgg16 (Model) (4, 4, 512) 14714688 tf_op_layer_BiasAdd[0][0] _____________________________________________________________________________________ flatten (Flatten) (8192) 0 vgg16[1][0] fc1 (Dense) (1) 8193 flatten[0][0] ===================================================================================== Total params: 14,722,881 Trainable params: 14,722,881 Non-trainable params: 0 _____________________________________________________________________________________ 5.2.7. XrayMini Keras model \u00b6 _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) [(128, 128, 1)] 0 _________________________________________________________________ Conv1_1 (Conv2D) (128, 128, 128) 1280 bn1 (BatchNormalization) (128, 128, 128) 512 pool1 (MaxPooling2D) (32, 32, 128) 0 _________________________________________________________________ Conv2_1 (Conv2D) (32, 32, 256) 295168 bn2 (BatchNormalization) (32, 32, 256) 1024 pool2 (MaxPooling2D) (8, 8, 256) 0 _________________________________________________________________ flatten (Flatten) (16384) 0 fc1 (Dense) (1) 16385 ================================================================= Total params: 314,369 Trainable params: 313,601 Non-trainable params: 768 _________________________________________________________________ 5.2.7. XrayOneMB Keras model \u00b6 _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) (128, 128, 1) 0 _________________________________________________________________ Conv1_1 (Conv2D) (128, 128, 64) 640 bn1_1 (BatchNormalization) (128, 128, 64) 256 Conv1_2 (Conv2D) (128, 128, 64) 36928 bn1_2 (BatchNormalization) (128, 128, 64) 256 pool1 (MaxPooling2D) (64, 64, 64) 0 _________________________________________________________________ Conv2_1 (Conv2D) (64, 64, 64) 36928 bn2_1 (BatchNormalization) (64, 64, 64) 256 Conv2_2 (Conv2D) (64, 64, 64) 36928 bn2_2 (BatchNormalization) (64, 64, 64) 256 pool2 (MaxPooling2D) (32, 32, 64) 0 _________________________________________________________________ Conv3_1 (Conv2D) (32, 32, 128) 73856 bn3_1 (BatchNormalization) (32, 32, 128) 512 Conv3_2 (SeparableConv2D) (32, 32, 128) 17664 bn3_2 (BatchNormalization) (32, 32, 128) 512 pool3 (MaxPooling2D) (16, 16, 128) 0 _________________________________________________________________ Conv4_1 (SeparableConv2D) (16, 16, 128) 17664 bn4_1 (BatchNormalization) (16, 16, 128) 512 _________________________________________________________________ Conv4_2 (SeparableConv2D) (16, 16, 128) 17664 bn4_2 (BatchNormalization) (16, 16, 128) 512 _________________________________________________________________ pool4 (AveragePooling2D) (4, 4, 128) 0 flatten (Flatten) (2048) 0 _________________________________________________________________ fc1 (Dense) (1) 2049 ================================================================= Total params: 243,393 Trainable params: 241,857 Non-trainable params: 1,536 _________________________________________________________________","title":"1. CIFAR10 dataset"},{"location":"tasks/#1-cifar10-dataset","text":"","title":"1. CIFAR10 dataset"},{"location":"tasks/#11-information-and-installation","text":"","title":"1.1. Information and installation"},{"location":"tasks/#111-information-about-the-dataset","text":"The CIFAR-10 dataset consists of 60000 32x32x3 colour images in 10 classes, with 6000 images per class. The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks Input for NN are raw 32x32 3 channels GRB images NN output is distribution of probabilities for each class i.e. 10 values that sums up to 1 Code folder: here Invoke parameter: -t CIFAR10","title":"1.1.1. Information about the dataset"},{"location":"tasks/#112-requirements","text":"Cifar dataset is loaded from tensorflow.keras.datasets.cifar10 and no stored data are required","title":"1.1.2. Requirements"},{"location":"tasks/#12-models","text":"","title":"1.2. Models"},{"location":"tasks/#121-cifar10conv-keras-model","text":"_________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) (32, 32, 3) 0 _________________________________________________________________ Conv1_1 (Conv2D) (32, 32, 64) 1792 bn1_1 (BatchNormalization) (32, 32, 64) 256 Conv1_2 (Conv2D) (32, 32, 64) 36928 bn1_2 (BatchNormalization) (32, 32, 64) 256 pool1 (MaxPooling2D) (16, 16, 64) 0 _________________________________________________________________ Conv2_1 (Conv2D) (16, 16, 128 73856 bn2_1 (BatchNormalization) (16, 16, 128 512 Conv2_2 (Conv2D) (16, 16, 128 147584 bn2_2 (BatchNormalization) (16, 16, 128 512 pool2 (MaxPooling2D) (8, 8, 128) 0 _________________________________________________________________ Conv3_1 (Conv2D) (8, 8, 256) 295168 bn3_1 (BatchNormalization) (8, 8, 256) 1024 Conv3_2 (Conv2D) (8, 8, 256) 590080 bn3_2 (BatchNormalization) (8, 8, 256) 1024 Conv3_3 (Conv2D) (8, 8, 256) 590080 bn3_3 (BatchNormalization) (8, 8, 256) 1024 _________________________________________________________________ flatten (Flatten) (16384) 0 fc1 (Dense) (100) 1638500 fc2 (Dense) (10) 1010 ================================================================= Total params: 3,379,606 Trainable params: 3,377,302 Non-trainable params: 2,304 _________________________________________________________________","title":"1.2.1. CIFAR10Conv Keras model"},{"location":"tasks/#122-cifar10conv2-keras-model","text":"_________________________________________________________ Layer (type) Output Shape Param # ========================================================= Input (InputLayer) (32, 32, 3) 0 _________________________________________________________ Conv1_1 (Conv2D) (32, 32, 32) 896 Conv1_2 (Conv2D) (32, 32, 32) 9248 pool1 (MaxPooling2D) (16, 16, 32) 0 _________________________________________________________ Conv2_1 (Conv2D) (16, 16, 64) 18496 Conv2_2 (Conv2D) (16, 16, 64) 36928 pool2 (MaxPooling2D) (8, 8, 64) 0 _________________________________________________________ Conv3_1 (Conv2D) (8, 8, 128) 73856 Conv3_2 (Conv2D) (8, 8, 128) 147584 pool3 (MaxPooling2D) (4, 4, 128) 0 _________________________________________________________ flatten (Flatten) (2048) 0 fc1 (Dense) (128) 262272 fc2 (Dense) (10) 1290 ========================================================= Total params: 550,570 Trainable params: 550,570 Non-trainable params: 0 _________________________________________________________","title":"1.2.2. CIFAR10Conv2 Keras model"},{"location":"tasks/#123-cifar10resnet50-keras-model","text":"________________________________________________________ Layer (type) Output Shape Param # ======================================================== Input (InputLayer) (32, 32, 3)] 0 ________________________________________________________ resnet50 (Model) (1, 1, 2048) 23587712 ________________________________________________________ Global_average_pooling2d (2048) 0 flatten (Flatten) (2048) 0 fc1 (Dense) (10) 20490 ======================================================== Total params: 23,608,202 Trainable params: 23,555,082 Non-trainable params: 53,120 ________________________________________________________","title":"1.2.3. CIFAR10Resnet50 Keras model"},{"location":"tasks/#2-covid-x-ray-dataset","text":"","title":"2. Covid X-RAY dataset"},{"location":"tasks/#21-information-and-installation","text":"","title":"2.1. Information and installation"},{"location":"tasks/#211-information-about-the-dataset","text":"The Covid X-Ray dataset consists of grayscale images, there are 478 covid images and 203 normal images. To increase the number of images normal/pneumonia dataset is added Final dataset, which is a combination of two previously mentioned datasets, contains 1434 images, 478 images for each class. Images are cropped and resized to 512x512 pixel and spatial domain (Texture, GLDM, GLCM) and frequency domain (FFT and Wavelet) features are used to create 256 dimensional vector representation of each image. PCA is applied after to reduce dimensionality to 64 values which represents the first 64 highest eigenvalues of the covariance matrix. Input for NN are 64 values for each image NN output is distribution of probabilities for each class i.e. 3 values Code folder: here Invoke parameter: -t COVID","title":"2.1.1. Information about the dataset"},{"location":"tasks/#212-requirements","text":"Download Covid dataset: here Download pneumonia dataset: here","title":"2.1.2 Requirements"},{"location":"tasks/#22-models","text":"","title":"2.2. Models"},{"location":"tasks/#221-covid-xray-keras-model","text":"_________________________________________________________ Layer (type) Output Shape Param # ========================================================= input_1 (InputLayer) (64) 0 _________________________________________________________ dense (Dense) (128) 8320 dropout (Dropout) (128) 0 _________________________________________________________ dense_1 (Dense) (16) 2064 dropout_1 (Dropout) (16) 0 _________________________________________________________ dense_2 (Dense) (3) 51 ========================================================= Total params: 10,435 Trainable params: 10,435 Non-trainable params: 0 _________________________________________________________","title":"2.2.1. Covid XRAY Keras model"},{"location":"tasks/#3-fraud-dataset","text":"","title":"3. FRAUD dataset"},{"location":"tasks/#31-information-and-installation","text":"","title":"3.1. Information and installation"},{"location":"tasks/#311-information-about-the-dataset","text":"EEE-CIS Fraud Detection, contains multiple files with credit card transactions Raw dataset files are automatically merged and pre-processed and input files for neural network are created X.csv with data - has 431 values for each transaction Y.csv with labels - v has 1 value for each transaction 0 = not a fraud 1 = fraud Code folder: here Invoke parameter: -t FRAUD","title":"3.1.1. Information about the dataset"},{"location":"tasks/#312-requirements","text":"Download dataset: here","title":"3.1.2. Requirements"},{"location":"tasks/#32-models","text":"","title":"3.2. Models"},{"location":"tasks/#321-frauddense1-keras-model","text":"_________________________________________________________ Layer (type) Output Shape Param # ========================================================= Input (InputLayer) (431) 0 _________________________________________________________ dense (Dense) (512) 221184 Batch_normalization (512) 2048 _________________________________________________________ dense_1 (Dense) (512) 262656 Batch_normalization_1 (512) 2048 _________________________________________________________ dense_2 (Dense) (512) 262656 Batch_normalization_2 (512) 2048 _________________________________________________________ fc1 (Dense) (1) 513 ========================================================= Total params: 753,153 Trainable params: 750,081 Non-trainable params: 3,072 _________________________________________________________","title":"3.2.1. FraudDense1 Keras model"},{"location":"tasks/#322-fraudsvm-scikit-learn-model","text":"Model is defined as SGDClassifier(max_iter=1, verbose=0, loss=\"modified_huber\") Which is support vector machine linear classifier","title":"3.2.2. FraudSVM Scikit-learn model"},{"location":"tasks/#4-mnist","text":"","title":"4. MNIST"},{"location":"tasks/#41-information-and-installation","text":"","title":"4.1. Information and installation"},{"location":"tasks/#411-information-about-the-dataset","text":"This is a dataset of 70,000 28x28x1 grayscale images of the 10 digits Input for NN are raw 28x28 1 channel images NN output is distribution of probabilities for each class i.e. 10 values that sums up to 1 Code folder: here Invoke parameter: -t MNIST","title":"4.1.1. Information about the dataset"},{"location":"tasks/#412-requirements","text":"MNIST dataset is loaded from tensorflow.keras.datasets.cifar10 and no stored data are required","title":"4.1.2 Requirements"},{"location":"tasks/#42-models","text":"","title":"4.2. Models"},{"location":"tasks/#421-mnistconv-keras-model","text":"_________________________________________________________ Layer (type) Output Shape Param # ========================================================= Input (InputLayer) (28, 28, 1) 0 _________________________________________________________ Conv1_1 (Conv2D) (28, 28, 64) 640 bn1 (BatchNormalization) (28, 28, 64) 256 pool1 (MaxPooling2D) (14, 14, 64) 0 _________________________________________________________ Conv2_1 (Conv2D) (14, 14, 128) 73856 bn4 (BatchNormalization) (14, 14, 128) 512 pool2 (MaxPooling2D) (7, 7, 128) 0 _________________________________________________________ flatten (Flatten) (6272) 0 fc1 (Dense) (10) 62730 ========================================================= Total params: 137,994 Trainable params: 137,610 Non-trainable params: 384 _________________________________________________________","title":"4.2.1. MNISTConv Keras model"},{"location":"tasks/#422-mnist-pytorch-model","text":"--------------------------------------------------------- Layer (type) Output Shape Param # ========================================================= Input [28,28,1] 0 Conv2d-1 [20, 24, 24] 520 Conv2d-2 [50, 8, 8] 25,050 Linear-3 [500] 400,500 Linear-4 [10] 5,010 ========================================================= Total params: 431,080 Trainable params: 431,080 Non-trainable params: 0 ---------------------------------------------------------","title":"4.2.2. MNIST Pytorch model"},{"location":"tasks/#423-mnistsupermini-keras-model","text":"________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ======================================================================================== input_1 (InputLayer) (28, 28, 1) 0 ________________________________________________________________________________________ conv2d (Conv2D) (26, 26, 8) 80 input_1[0][0] Batch_normalization (26, 26, 8) 32 conv2d[0][0] Max_pooling2d (13, 13, 8) 0 batch_normalization[0][0] dropout (Dropout) (13, 13, 8) 0 max_pooling2d[0][0] ________________________________________________________________________________________ Separable_conv2d (11, 11, 26) 306 dropout[0][0] batch_normalization_1 (11, 11, 26) 104 separable_conv2d[0][0] dropout_1 (Dropout) (11, 11, 26) 0 batch_normalization_1[0][0] ________________________________________________________________________________________ Separable_conv2d_1 (11, 11, 26) 936 dropout_1[0][0] dropout_2[0][0] dropout_3[0][0] ________________________________________________________________________________________ Batch_normalization_2 (11, 11, 26) 104 separable_conv2d_1[0][0] dropout_2 (Dropout) (11, 11, 26) 0 batch_normalization_2[0][0] ________________________________________________________________________________________ Batch_normalization_3 (11, 11, 26) 104 separable_conv2d_1[1][0] dropout_3 (Dropout) (11, 11, 26) 0 batch_normalization_3[0][0] ________________________________________________________________________________________ Batch_normalization_4 (11, 11, 26) 104 separable_conv2d_1[2][0] dropout_4 (Dropout) (11, 11, 26) 0 batch_normalization_4[0][0] ________________________________________________________________________________________ Global_average_pooling2d (26) 0 dropout_4[0][0] dense (Dense) (16) 432 global_average_pooling2d[0][0] Batch_normalization_5 (16) 64 dense[0][0] dropout_5 (Dropout) (16) 0 batch_normalization_5[0][0] dense_1 (Dense) (10) 170 dropout_5[0][0] ======================================================================================== Total params: 2,436 Trainable params: 2,180 Non-trainable params: 256 ________________________________________________________________________________________","title":"4.2.3. MNISTSupermini Keras model"},{"location":"tasks/#5-pneumonia-xray","text":"","title":"5. Pneumonia XRAY"},{"location":"tasks/#51-information-and-installation","text":"","title":"5.1. Information and installation"},{"location":"tasks/#511-information-about-the-dataset","text":"The Chest X-Ray Images (Pneumonia) dataset consists of 5856 grayscale images of various sizes in 2 classes (normal/pneumonia). Labels are determined by folder name - NORMAL or PNEUMONIA Input for NN are raw resized 128x128 1 channel images NN output is distribution of probabilities for each class i.e. 2 values Code folder: here Invoke parameter: -t XRAY","title":"5.1.1. Information about the dataset"},{"location":"tasks/#512-requirements","text":"Download dataset: here","title":"5.1.2 Requirements"},{"location":"tasks/#52-models","text":"","title":"5.2. Models"},{"location":"tasks/#521-xraysupermini-keras-model","text":"_________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) [(128, 128, 1)] 0 _________________________________________________________________ Conv1_1 (Conv2D) (128, 128, 32) 320 _________________________________________________________________ bn1 (BatchNormalization) (128, 128, 32) 128 _________________________________________________________________ pool1 (MaxPooling2D) (32, 32, 32) 0 _________________________________________________________________ Conv2_1 (Conv2D) (32, 32, 64) 18496 _________________________________________________________________ bn2 (BatchNormalization) (32, 32, 64) 256 _________________________________________________________________ Global_max_pooling2d (64) 0 _________________________________________________________________ fc1 (Dense) (1) 65 ================================================================= Total params: 19,265 Trainable params: 19,073 Non-trainable params: 192 _________________________________________________________________","title":"5.2.1. XraySupermini Keras model"},{"location":"tasks/#522-xrayresnet50-keras-model","text":"_________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) [(128, 128, 1)] 0 _________________________________________________________________ resnet50 (Model) (4, 4, 2048) 23581440 _________________________________________________________________ global_average_pooling2d (2048) 0 _________________________________________________________________ flatten (Flatten) (2048) 0 _________________________________________________________________ fc1 (Dense) (1) 2049 ================================================================= Total params: 23,583,489 Trainable params: 23,530,369 Non-trainable params: 53,120 _________________________________________________________________","title":"5.2.2. XrayResnet50 Keras model"},{"location":"tasks/#523-xraypretrainedresnet50-keras-model","text":"_____________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ===================================================================================== Input (InputLayer) (128, 128, 1) 0 _____________________________________________________________________________________ concatenate (Concatenate) (128, 128, 3) 0 Input[0][0] Input[0][0] Input[0][0] _____________________________________________________________________________________ tf_op_layer_mul (128, 128, 3) 0 concatenate[0][0] tf_op_layer_strided_slice (128, 128, 3) 0 tf_op_layer_mul[0][0] tf_op_layer_BiasAdd (128, 128, 3) 0 tf_op_layer_strided_slice[0][0] _____________________________________________________________________________________ resnet50 (Model) (4, 4, 2048) 23587712 tf_op_layer_BiasAdd[0][0] _____________________________________________________________________________________ global_average_pooling2d (2048) 0 resnet50[1][0] flatten (Flatten) (2048) 0 global_average_pooling2d[0][0] _____________________________________________________________________________________ fc1 (Dense) (1) 2049 flatten[0][0] ===================================================================================== Total params: 23,589,761 Trainable params: 23,536,641 Non-trainable params: 53,120 _____________________________________________________________________________________","title":"5.2.3. XrayPretrainedResnet50 Keras model"},{"location":"tasks/#524-xraydropout-keras-model","text":"_________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) [(128, 128, 1)] 0 _________________________________________________________________ Conv1_1 (Conv2D) (128, 128, 128) 1280 bn1 (BatchNormalization) (128, 128, 128) 512 pool1 (MaxPooling2D) (32, 32, 128) 0 _________________________________________________________________ Conv2_1 (Conv2D) (32, 32, 256) 295168 bn2 (BatchNormalization) (32, 32, 256) 1024 pool2 (MaxPooling2D) (8, 8, 256) 0 _________________________________________________________________ flatten (Flatten) (16384) 0 fc1 (Dense) (128) 2097280 bn3 (BatchNormalization) (128) 512 dropout (Dropout) (128) 0 _________________________________________________________________ fc2 (Dense) (64) 8256 bn4 (BatchNormalization) (64) 256 dropout_1 (Dropout) (64) 0 _________________________________________________________________ fc3 (Dense) (1) 65 ================================================================= Total params: 2,404,353 Trainable params: 2,403,201 Non-trainable params: 1,152 _________________________________________________________________","title":"5.2.4. XrayDropout Keras model"},{"location":"tasks/#525-xraydropout2-keras-model","text":"_________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) (128, 128, 1) 0 _________________________________________________________________ Conv1_1 (Conv2D) (128, 128, 64) 640 bn1 (BatchNormalization) (128, 128, 64) 256 pool1 (MaxPooling2D) (64, 64, 64) 0 _________________________________________________________________ Conv2_1 (Conv2D) (64, 64, 128) 73856 bn2 (BatchNormalization) (64, 64, 128) 512 pool2 (MaxPooling2D) (32, 32, 128) 0 _________________________________________________________________ Conv3_1 (Conv2D) (32, 32, 256) 295168 bn3 (BatchNormalization) (32, 32, 256) 1024 pool3 (MaxPooling2D) (16, 16, 256) 0 _________________________________________________________________ Conv4_1 (Conv2D) (16, 16, 512) 1180160 bn4 (BatchNormalization) (16, 16, 512) 2048 pool4 (MaxPooling2D) (8, 8, 512) 0 _________________________________________________________________ Conv5_1 (Conv2D) (8, 8, 512) 2359808 bn5 (BatchNormalization) (8, 8, 512) 2048 pool5 (MaxPooling2D) (4, 4, 512) 0 _________________________________________________________________ flatten (Flatten) (8192) 0 fc1 (Dense) (256) 2097408 bn6 (BatchNormalization) (256) 1024 dropout (Dropout) (256) 0 _________________________________________________________________ fc2 (Dense) (128) 32896 bn7 (BatchNormalization) (128) 512 dropout_1 (Dropout) (128) 0 _________________________________________________________________ fc3 (Dense) (64) 8256 bn8 (BatchNormalization) (64) 256 dropout_2 (Dropout) (64) 0 _________________________________________________________________ fc4 (Dense) (1) 65 ================================================================= Total params: 6,055,937 Trainable params: 6,052,097 Non-trainable params: 3,840 _________________________________________________________________","title":"5.2.5. XrayDropout2 Keras model"},{"location":"tasks/#526-xrayvgg16-keras-model","text":"_____________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ===================================================================================== Input (InputLayer) (128, 128, 1) 0 _____________________________________________________________________________________ concatenate (Concatenate) (128, 128, 3) 0 Input[0][0] Input[0][0] Input[0][0] _____________________________________________________________________________________ tf_op_layer_mul (128, 128, 3) 0 concatenate[0][0] Tf_op_layer_strided_slice (28, 128, 3) 0 tf_op_layer_mul[0][0] tf_op_layer_BiasAdd (128, 128, 3) 0 tf_op_layer_strided_slice[0][0] _____________________________________________________________________________________ vgg16 (Model) (4, 4, 512) 14714688 tf_op_layer_BiasAdd[0][0] _____________________________________________________________________________________ flatten (Flatten) (8192) 0 vgg16[1][0] fc1 (Dense) (1) 8193 flatten[0][0] ===================================================================================== Total params: 14,722,881 Trainable params: 14,722,881 Non-trainable params: 0 _____________________________________________________________________________________","title":"5.2.6. XrayVGG16 Keras model"},{"location":"tasks/#527-xraymini-keras-model","text":"_________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) [(128, 128, 1)] 0 _________________________________________________________________ Conv1_1 (Conv2D) (128, 128, 128) 1280 bn1 (BatchNormalization) (128, 128, 128) 512 pool1 (MaxPooling2D) (32, 32, 128) 0 _________________________________________________________________ Conv2_1 (Conv2D) (32, 32, 256) 295168 bn2 (BatchNormalization) (32, 32, 256) 1024 pool2 (MaxPooling2D) (8, 8, 256) 0 _________________________________________________________________ flatten (Flatten) (16384) 0 fc1 (Dense) (1) 16385 ================================================================= Total params: 314,369 Trainable params: 313,601 Non-trainable params: 768 _________________________________________________________________","title":"5.2.7. XrayMini Keras model"},{"location":"tasks/#527-xrayonemb-keras-model","text":"_________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) (128, 128, 1) 0 _________________________________________________________________ Conv1_1 (Conv2D) (128, 128, 64) 640 bn1_1 (BatchNormalization) (128, 128, 64) 256 Conv1_2 (Conv2D) (128, 128, 64) 36928 bn1_2 (BatchNormalization) (128, 128, 64) 256 pool1 (MaxPooling2D) (64, 64, 64) 0 _________________________________________________________________ Conv2_1 (Conv2D) (64, 64, 64) 36928 bn2_1 (BatchNormalization) (64, 64, 64) 256 Conv2_2 (Conv2D) (64, 64, 64) 36928 bn2_2 (BatchNormalization) (64, 64, 64) 256 pool2 (MaxPooling2D) (32, 32, 64) 0 _________________________________________________________________ Conv3_1 (Conv2D) (32, 32, 128) 73856 bn3_1 (BatchNormalization) (32, 32, 128) 512 Conv3_2 (SeparableConv2D) (32, 32, 128) 17664 bn3_2 (BatchNormalization) (32, 32, 128) 512 pool3 (MaxPooling2D) (16, 16, 128) 0 _________________________________________________________________ Conv4_1 (SeparableConv2D) (16, 16, 128) 17664 bn4_1 (BatchNormalization) (16, 16, 128) 512 _________________________________________________________________ Conv4_2 (SeparableConv2D) (16, 16, 128) 17664 bn4_2 (BatchNormalization) (16, 16, 128) 512 _________________________________________________________________ pool4 (AveragePooling2D) (4, 4, 128) 0 flatten (Flatten) (2048) 0 _________________________________________________________________ fc1 (Dense) (1) 2049 ================================================================= Total params: 243,393 Trainable params: 241,857 Non-trainable params: 1,536 _________________________________________________________________","title":"5.2.7. XrayOneMB Keras model"}]}