{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the Fetch.ai Collective Learning Library","text":"<p>Colearn is a library that enables privacy-preserving decentralized machine learning tasks on the FET network.</p> <p>This blockchain-mediated collective learning system enables multiple stakeholders to build a shared machine learning model without needing to rely on a central authority, and without revealing their dataset to the other stakeholders. This library is currently in development.</p>"},{"location":"#how-collective-learning-works","title":"How collective learning works","text":"<p>A group of learners comes together, each of whom have their own datasets and want to collaborate on training a machine learning model over a set number of rounds. We refer to this as an 'experiment'. In each round of collective learning:</p> <ol> <li>One learner is selected to train the model and propose a new set of model weights.</li> <li>The other learners vote on whether the weights are an improvement.</li> <li>If the majority vote that the new weights are better than the old ones then the new weights are accepted by all the learners.     Otherwise the new weights are discarded.</li> <li>The next round begins. For more information on the Collective Learning Protocol see here.</li> </ol>"},{"location":"#current-version","title":"Current Version","text":"<p>We have released v.0.2.8 of the Colearn Machine Learning Interface, the first version of an interface that allows developers to define their own model architectures that can then be used in collective learning. Together with the interface we provide a simple backend for local experiments. This is a prototype backend with upcoming blockchain ledger based backends to follow. Future releases will use similar interfaces so that learners built with the current system will work on a different backend that integrates a distributed ledger and provides other improvements. The current framework will then be used mainly for model development and debugging. We invite all users to experiment with the framework, develop their own models, and provide feedback!</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>To use the latest stable release we recommend installing the package from PyPi</p> <p>To install with support for Keras and Pytorch:</p> <pre><code>pip install colearn[all]\n</code></pre> <p>To install with just support for Keras or Pytorch:</p> <pre><code>pip install colearn[keras]\npip install colearn[pytorch]\n</code></pre> <p>For more installation options or get the latest (development) version see Installation</p> <p>Then run the standalone demo:</p> <pre><code>python -m colearn_examples.ml_interface.run_demo\n</code></pre> <p>For plenty of other examples see the Examples.</p>"},{"location":"#writing-your-own-models","title":"Writing your own models","text":"<p>We encourage users to try out the system by writing their own models. Models need to implement the collective learning interface, which provides functions for training and voting on updates. More instructions can be found in the Getting Started section.</p>"},{"location":"about/","title":"How collective learning works","text":"<p>A Colearn experiment begins when a group of entities, referred to as  learners, decide on a model architecture and begin learning. Together they will train a single global model. The goal is to train a model that performs better than any of the learners can produce by training on their private data set.</p>"},{"location":"about/#how-training-works","title":"How Training Works","text":"<p>Training occurs in rounds; during each round the learners attempt to improve the performance of the global shared model. To do so each round an update of the global model (for example new set of weights in a neural network) is proposed. The learners then validate the update and decide if the new model is better than the current global model. If enough learners approve the update then the global model is updated. After an update is approved or rejected a new round begins.</p> <p>The detailed steps of a round updating a global model M are as follows:</p> <ol> <li>One of the learners is selected and proposes a new updated model M'</li> <li>The rest of the learners validate M'</li> <li>If M' has better performance than M against their private data set then the learner votes to approve</li> <li>If not, the learner votes to reject</li> <li>The total votes are tallied</li> <li>If more than some threshold (typically 50%) of learners approve then M' becomes the new global model. If not,      M continues to be the global model</li> <li>A new round begins.</li> </ol> <p>By using a decentralized ledger (a blockchain) this learning process can be run in a completely decentralized, secure and auditable way. Further security can be provided by using differential privacy to avoid exposing your private data set when generating an update.</p>"},{"location":"about/#learning-algorithms-that-work-for-collective-learning","title":"Learning algorithms that work for collective learning","text":"<p>Collective learning is not just for neural networks; any learning algorithm that can be trained on subsets of the data and which can use the results of previous training rounds as the basis for subsequent rounds can be used. Neural networks fit both these constraints: training can be done on mini-batches of data and each training step uses the weights of the previous training step as its starting point. More generally, any model that is trained using mini-batch stochastic gradient descent is fine. Other algorithms can be made to work with collective learning as well. For example, a random forest can be trained iteratively by having each learner add new trees (see example in mli_random_forest_iris.py). For more discussion, see here.</p>"},{"location":"about/#the-driver","title":"The driver","text":"<p>The driver implements the voting protocol, so it handles selecting a learner to train, sending the update out for voting, calculating the vote and accepting or declining the update. Here we have a very minimal driver that doesn't use networking or a blockchain. Eventually the driver will be a smart contract. This is the code that implements one round of voting:</p> <pre><code>def run_one_round(round_index: int, learners: Sequence[MachineLearningInterface],\n                  vote_threshold=0.5):\n    proposer = round_index % len(learners)\n    new_weights = learners[proposer].mli_propose_weights()\n\n    prop_weights_list = [ln.mli_test_weights(new_weights) for ln in learners]\n    approves = sum(1 if v.vote else 0 for v in prop_weights_list)\n\n    vote = False\n    if approves &gt;= len(learners) * vote_threshold:\n        vote = True\n        for j, learner in enumerate(learners):\n            learner.mli_accept_weights(prop_weights_list[j])\n\n    return prop_weights_list, vote\n</code></pre> <p>The driver has a list of learners, and each round it selects one learner to be the proposer. The proposer does some training and proposes an updated set of weights. The driver then sends the proposed weights to each of the learners, and they each vote on whether this is an improvement. If the number of approving votes is greater than the vote threshold the proposed weights are accepted, and if not they're rejected.</p>"},{"location":"about/#the-machine-learning-interface","title":"The Machine Learning Interface","text":"<pre><code># ------------------------------------------------------------------------------\n#\n#   Copyright 2021 Fetch.AI Limited\n#\n#   Licensed under the Creative Commons Attribution-NonCommercial International\n#   License, Version 4.0 (the \"License\"); you may not use this file except in\n#   compliance with the License. You may obtain a copy of the License at\n#\n#       http://creativecommons.org/licenses/by-nc/4.0/legalcode\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\n#\n# ------------------------------------------------------------------------------\nimport abc\nfrom enum import Enum\nfrom typing import Any, Optional\n\nimport onnx\nimport onnxmltools\nimport sklearn\nimport tensorflow as tf\nimport torch\nfrom pydantic import BaseModel\nfrom tensorflow import keras\n\nmodel_classes_keras = (tf.keras.Model, keras.Model, tf.estimator.Estimator)\nmodel_classes_scipy = (torch.nn.Module)\nmodel_classes_sklearn = (sklearn.base.ClassifierMixin)\n\n\ndef convert_model_to_onnx(model: Any):\n\"\"\"\n    Helper function to convert a ML model to onnx format\n    \"\"\"\n    if isinstance(model, model_classes_keras):\n        return onnxmltools.convert_keras(model)\n    if isinstance(model, model_classes_sklearn):\n        return onnxmltools.convert_sklearn(model)\n    if 'xgboost' in model.__repr__():\n        return onnxmltools.convert_sklearn(model)\n    if isinstance(model, model_classes_scipy):\n        raise Exception(\"Pytorch models not yet supported to onnx\")\n    else:\n        raise Exception(\"Attempt to convert unsupported model to onnx: {model}\")\n\n\nclass DiffPrivBudget(BaseModel):\n    target_epsilon: float\n    target_delta: float\n    consumed_epsilon: float\n    consumed_delta: float\n\n\nclass ErrorCodes(Enum):\n    DP_BUDGET_EXCEEDED = 1\n\n\nclass TrainingSummary(BaseModel):\n    dp_budget: Optional[DiffPrivBudget]\n    error_code: Optional[ErrorCodes]\n\n\nclass Weights(BaseModel):\n    weights: Any\n    training_summary: Optional[TrainingSummary]\n\n\nclass DiffPrivConfig(BaseModel):\n    target_epsilon: float\n    target_delta: float\n    max_grad_norm: float\n    noise_multiplier: float\n\n\nclass ProposedWeights(BaseModel):\n    weights: Weights\n    vote_score: float\n    test_score: float\n    vote: Optional[bool]\n\n\nclass ModelFormat(Enum):\n    PICKLE_WEIGHTS_ONLY = 1\n    ONNX = 2\n\n\nclass ColearnModel(BaseModel):\n    model_format: ModelFormat\n    model_file: Optional[str]\n    model: Optional[Any]\n\n\ndef deser_model(model: Any) -&gt; onnx.ModelProto:\n\"\"\"\n    Helper function to recover a onnx model from its deserialized form\n    \"\"\"\n    return onnx.load_model_from_string(model)\n\n\nclass MachineLearningInterface(abc.ABC):\n    @abc.abstractmethod\n    def mli_propose_weights(self) -&gt; Weights:\n\"\"\"\n        Trains the model. Returns new weights. Does not change the current weights of the model.\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def mli_test_weights(self, weights: Weights) -&gt; ProposedWeights:\n\"\"\"\n        Tests the proposed weights and fills in the rest of the fields\n        \"\"\"\n\n    @abc.abstractmethod\n    def mli_accept_weights(self, weights: Weights):\n\"\"\"\n        Updates the model with the proposed set of weights\n        :param weights: The new weights\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def mli_get_current_weights(self) -&gt; Weights:\n\"\"\"\n        Returns the current weights of the model\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def mli_get_current_model(self) -&gt; ColearnModel:\n\"\"\"\n        Returns the current model\n        \"\"\"\n        pass \n</code></pre> <p>There are four methods that need to be implemented:</p> <ol> <li><code>propose_weights</code> causes the model to do some training and then return a    new set of weights that are proposed to the other learners.    This method shouldn't change the current weights of the model - that    only happens when <code>accept_weights</code> is called.</li> <li><code>test_weights</code> - the models takes some new weights and returns a vote on whether the new weights are an improvement.    As with propose_weights, this shouldn't change the current weights of the model -    that only happens when <code>accept_weights</code> is called.</li> <li><code>accept_weights</code> - the models accepts some weights that have been voted on and approved by the set of learners.     The old weights of the model are discarded and replaced by the new weights.</li> <li><code>current_weights</code> should return the current weights of the model.</li> </ol> <p>For more details about directly implementing the machine learning interface see the tutorial here</p>"},{"location":"demo/","title":"How to run the demo","text":"<p>You can try collective learning for yourself using the simple demo in run_demo. This demo creates n learners for one of six learning tasks and co-ordinates the collective learning between them.</p> <p>There are six potential models for the demo</p> <ul> <li>KERAS_MNIST is the Tensorflow implementation of a small model for the standard handwritten digits recognition dataset</li> <li>KERAS_MNIST_RESNET is the Tensorflow implementation of a Resnet model for the standard handwritten digits recognition dataset</li> <li>KERAS_CIFAR10 is the Tensorflow implementation of the classical image recognition dataset</li> <li>PYTORCH_XRAY is Pytorch implementation of a binary classification task that requires predicting pneumonia from images of chest X-rays.   The data need to be downloaded from Kaggle</li> <li>PYTORCH_COVID_XRAY is Pytorch implementation of a 3 class classification task that requires predicting no finding, covid or pneumonia from images of chest X-rays.   This dataset is not currently publicly available.</li> <li>FRAUD The fraud dataset consists of information about credit card transactions, and the task is to predict whether   transactions are fraudulent or not.   The data need to be downloaded from Kaggle</li> </ul> <p>Use the -h flag to see the options:</p> <pre><code>python -m colearn_examples.ml_interface.run_demo -h\n</code></pre> <p>Arguments to run the demo:</p> <pre><code>--data_dir:       Directory containing training data, not required for MNIST and CIFAR10\n--test_dir:       Optional directory containing test data. A fraction of the training set will be used as a test set when not specified\n--model:          Model to train, options are KERAS_MNIST KERAS_MNIST_RESNET KERAS_CIFAR10 PYTORCH_XRAY PYTORCH_COVID_XRAY FRAUD\n--n_learners:     Number of individual learners\n--n_rounds:       Number of training rounds\n--vote_threshold: Minimum fraction of positive votes to accept the new model\n--train_ratio:    Fraction of training dataset to be used as test-set when no test-set is specified\n--seed:           Seed for initialising model and shuffling datasets\n--learning_rate:  Learning rate for optimiser\n--batch_size:     Size of training batch\n</code></pre>"},{"location":"demo/#running-mnist","title":"Running MNIST","text":"<p>The simplest task to run is MNIST because the data are downloaded automatically from <code>tensorflow_datasets</code>. The command below runs the MNIST task with five learners for 15 rounds.</p> <pre><code>python -m colearn_examples.ml_interface.run_demo --model KERAS_MNIST --n_learners 5 --n_rounds 15\n</code></pre> <p>You should see a graph of the vote score and the test score (the score used here is categorical accuracy). The new model is accepted if the fraction of positive votes (green colour) is higher than 0.5. The new model is rejected if the fraction of negative votes (red color) is lower than 0.5.</p> <p></p> <p>As you can see, there are five learners, and initially they perform poorly. In round one, learner 0 is selected to propose a new set of weights.</p>"},{"location":"demo/#other-datasets","title":"Other datasets","text":"<p>To run the CIFAR10 dataset:</p> <pre><code>python -m colearn_examples.ml_interface.run_demo --model KERAS_CIFAR10 --n_learners 5 --n_rounds 15\n</code></pre> <p>The Fraud and X-ray datasets need to be downloaded from kaggle (this requires a kaggle account). To run the fraud dataset:</p> <pre><code>python -m colearn_examples.ml_interface.run_demo --model FRAUD --n_learners 5 --n_rounds 15 --data_dir ./data/fraud\n</code></pre> <p>To run the X-ray dataset:</p> <pre><code>python -m colearn_examples.ml_interface.run_demo --model PYTORCH_XRAY --n_learners 5 --n_rounds 15 --data_dir ./data/xray\n</code></pre>"},{"location":"dev_notes/","title":"Developer Notes","text":"<p>These are some notes for developers working on the colearn code repo</p>"},{"location":"dev_notes/#google-cloud-storage","title":"Google Cloud Storage","text":"<p>To have access to the google cloud storage you need to set up your google authentication and have the $GOOGLE_APPLICATION_CREDENTIALS set up correctly. For more details ask or see the contract-learn documentation</p>"},{"location":"dev_notes/#build-image","title":"Build image","text":"<p>To build ML server image and push to google cloud use the following command:</p> <pre><code>cd docker\npython3 ./build.py --publish --allow_dirty\n# Check this worked correctly\ndocker images\n</code></pre>"},{"location":"differential_privacy/","title":"What is differential privacy?","text":"<p>To make a machine learning system that protects privacy we first need to have a definition of what privacy is. Differential privacy (DP) is one such definition. First we need to have three concepts: the database is a collection of data about individuals (for example, their medical records), and we want to make a query about that data (for example \"How much does smoking increase someone's risk of cancer?\"). DP says that privacy is preserved if the result of the query cannot be used to determine if any particular individual is present in the database.</p> <p>So if person A has their medical data in a database, and the query that we want to make on that database is \"How much does smoking increase someone's risk of cancer\" then the result of that query shouldn't disclose whether or not person A's details are in the database.</p> <p>From this comes the idea of sensitivity of a query. The sensitivity of a query determines how much the result of the query depends on an individual's data. For example, the query \"How much does smoking increase the risk of cancer for adults in the UK?\" is less sensitive than the query \"How much does smoking increase the risk of cancer for men aged 50-55 in Cambridge?\" because the second query uses a smaller set of individuals.</p>"},{"location":"differential_privacy/#epsilon-differential-privacy","title":"Epsilon-differential privacy","text":"<p>EDP is a scheme for preserving differential privacy. In EDP all queries have random noise added to them, so they are no longer deterministic. So if the query was \"What fraction of people in the database are male\", and the true result is 0.5 then the results of calling this query three times might be 0.53, 0.49 and 0.51. This makes it harder to tell if an individual's data is in the database, because the effect of adding a person can't be distinguished from the effect of the random noise. Intuitively this is a bit like blurring an image: adding noise obscures personal information. The amount of personal information that is revealed isn't zero, but it is guaranteed to be below a certain threshold.</p> <p>The level of privacy that is provided is controlled by the parameter epsilon; the greater epsilon is the more noise is added and the more privacy is preserved. Queries that are more sensitive have more noise added, because they reveal more information about individuals. It is important to add as little noise as possible, because adding more noise obscures the patterns that you want to extract from the data.</p>"},{"location":"differential_privacy/#differential-privacy-when-training-neural-networks","title":"Differential privacy when training neural networks","text":"<p>Each training step for a neural network can be though of as a complicated query on a database of training data. Differential privacy mechanisms tell you how much noise you need to add to guarantee a certain level of privacy. The <code>opacus</code> and <code>tensorflow-privacy</code> libraries implement epsilon-differential privacy for training neural networks for pytorch and keras respectively.</p>"},{"location":"differential_privacy/#how-to-use-differential-privacy-with-colearn","title":"How to use differential privacy with colearn","text":"<p>By using <code>opacus</code> and <code>tensorflow-privacy</code> we can make collective learning use differential privacy. The learner that is proposing weights does so using a DP-enabled optimiser.</p> <p>To see an example of using this see dp_pytorch and dp_keras.</p>"},{"location":"examples/","title":"Examples that use Collective Learning","text":"<p>This is a list of examples that we've implemented to show you how to use Collective Learning locally. See and example of the gRPC server for the next step towards decentralized Colearn.</p>"},{"location":"examples/#mnist","title":"Mnist","text":"<p>Uses the standard Mnist database of handwritten images</p> <ul> <li>mnist_keras.   Uses the <code>KerasLearner</code> helper class.   Discussed in more detail here.</li> <li>mnist_pytorch.   Uses the <code>PytorchLearner</code> helper class.   Discussed in more detail here.</li> </ul>"},{"location":"examples/#fraud","title":"Fraud","text":"<p>The fraud dataset consists of information about credit card transactions.   The task is to predict whether transactions are fraudulent or not.   The data needs to be downloaded from Kaggle,   and the data directory passed in with the flag <code>--data_dir</code>.</p> <ul> <li>fraud_mli.   Uses the <code>MachineLearningInterface</code> directly and detects fraud in bank transactions.</li> <li>fraud_keras.   Loads data from numpy arrays and uses <code>KerasLearner</code>.</li> </ul>"},{"location":"examples/#cifar10","title":"Cifar10","text":"<p>Uses the standard Cifar10 database of images</p> <ul> <li>cifar_keras.   Uses the <code>KerasLearner</code> helper class.</li> <li>cifar_pytorch.   Uses the <code>PytorchLearner</code> helper class.</li> </ul>"},{"location":"examples/#xray","title":"Xray","text":"<p>A binary classification task that requires predicting pneumonia from images of chest X-rays.   The data need to be downloaded from Kaggle,   and the data directory passed in with the flag <code>--data_dir</code></p> <ul> <li>xray_keras.   Uses the <code>KerasLearner</code> helper class.</li> <li>xray_pytorch.   Uses the <code>PytorchLearner</code> helper class.</li> </ul>"},{"location":"examples/#iris","title":"Iris","text":"<p>Uses the standard Iris dataset. The aim of this task is to classify examples into one of three iris species based on measurements of the flower.</p> <ul> <li>iris_random_forest.   Uses the <code>MachineLearningInterface</code> directly and a random forest for classification.</li> </ul>"},{"location":"grpc_examples/","title":"Mnist gRPC Example","text":"<p>To run the Keras Mnist gRPC example run:</p> <pre><code>python -m colearn_examples.grpc.run_grpc_demo --n_learners 5 --dataloader_tag KERAS_MNIST --model_tag KERAS_MNIST \\\n--data_locations /tmp/mnist/0,/tmp/mnist/1,/tmp/mnist/2,/tmp/mnist/3,/tmp/mnist/4\n</code></pre> <p>Note</p> <p>This requires <code>colearn[keras]</code></p> <p>You can verify that the example is working correctly by running the probe:</p> <pre><code>python -m colearn_grpc.scripts.probe_grpc_server --port 9995\n</code></pre> <p>For more about the gRPC components of Colearn see the gRPC Tutorial</p>"},{"location":"grpc_tutorial/","title":"gRPC tutorial","text":"<p>This tutorial explains how to set up the gRPC learner server. It assumes that you can already run colearn locally, and that you have already defined your own models and dataloaders (if you're going to do so). If you haven't done this then see the tutorials in the Getting Started section.</p>"},{"location":"grpc_tutorial/#architecture-of-colearn","title":"Architecture of colearn","text":"<p>There are two main parts to a collective learning system: the learner and the backend. The backend controls the learner, and manages the smart contracts and IPFS, and acts as a control hub for all the associated learners. The learner is the part that executes machine learning code. This consists of proposing, evaluating and accepting new weights as detailed in the Machine Learning Interface. The learner and the backend communicate via gRPC; the learner runs a gRPC server, and the backend runs a gRPC client that makes requests of the learner. This separation means that the learner can run on specialised hardware (e.g. a compute server) and does not need to be co-located with the backend.</p>"},{"location":"grpc_tutorial/#architecture-of-grpc-server","title":"Architecture of gRPC server","text":"<p>The gRPC interface is defined in colearn_grpc/proto/interface.proto. This defines the functions that the gRPC server exposes and the format for messages between the server and the client.</p> <p>As we covered in the earlier tutorials, the machine learning part of colearn is contained inside the <code>MachineLearningInterface</code> (MLI). To recap: the MLI provides methods for proposing, evaluating and accepting weights. If you want to use your own models with colearn then you need to write an object that implements the MLI (for example, an instance of a python class that inherits from <code>MachineLearningInterface</code>). For more about the MLI see the MLI tutorial.</p> <p>The gRPC server has an MLI factory, and it uses its MLI factory to make objects that implement the <code>MachineLearningInterface</code>. The MLI factory needs to implement the MLI factory interface. You could write your own MLI factory, but it's easier to use the one we provide. Below we will discuss the MLI factory interface and then talk about how to use the example factory.</p>"},{"location":"grpc_tutorial/#mli-factory-interface","title":"MLI Factory interface","text":"<p>The MLI Factory (as the name suggests) is a factory class for creating objects that implement the machine learning interface:</p> <pre><code># ------------------------------------------------------------------------------\n#\n#   Copyright 2021 Fetch.AI Limited\n#\n#   Licensed under the Creative Commons Attribution-NonCommercial International\n#   License, Version 4.0 (the \"License\"); you may not use this file except in\n#   compliance with the License. You may obtain a copy of the License at\n#\n#       http://creativecommons.org/licenses/by-nc/4.0/legalcode\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\n#\n# ------------------------------------------------------------------------------\nimport abc\nfrom typing import Dict, Set, Any\nimport os.path\nfrom pkg_resources import get_distribution, DistributionNotFound\n\nfrom colearn.ml_interface import MachineLearningInterface\n\n\nclass MliFactory(abc.ABC):\n\"\"\"\n    Interface a class must implement to be used as a factory by the GRPC Server\n    \"\"\"\n    _version = \"0.0.0\"\n\n    # https://stackoverflow.com/questions/17583443\n    try:\n        _dist = get_distribution('colearn')\n        # Normalize case for Windows systems\n        dist_loc = os.path.normcase(_dist.location)\n        here = os.path.normcase(__file__)\n        if not here.startswith(os.path.join(dist_loc, 'colearn')):\n            # not installed, but there is another version that *is*\n            raise DistributionNotFound\n    except DistributionNotFound:\n        pass\n    else:\n        _version = _dist.version\n\n    def get_version(self) -&gt; str:\n\"\"\"\n        Returns the version of this library....\n        \"\"\"\n        return self._version\n\n    @abc.abstractmethod\n    def get_models(self) -&gt; Dict[str, Dict[str, Any]]:\n\"\"\"\n        Returns the models this factory produces.\n        The key is the name of the model and the values are their default parameters\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def get_dataloaders(self) -&gt; Dict[str, Dict[str, Any]]:\n\"\"\"\n        Returns the dataloaders this factory produces.\n        The key is the name of the dataloader and the values are their default parameters\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def get_compatibilities(self) -&gt; Dict[str, Set[str]]:\n\"\"\"\n        A model is compatible with a dataloader if they can be used together to\n        construct a MachineLearningInterface with the get_MLI function.\n\n        Returns a dictionary that defines which model is compatible\n        with which dataloader.\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def get_mli(self,\n                model_name: str, model_params: str,\n                dataloader_name: str, dataset_params: str) -&gt; MachineLearningInterface:\n\"\"\"\n        @param model_name: name of a model, must be in the set return by get_models\n        @param model_params: user defined parameters for the model\n        @param dataloader_name: name of a dataloader to be used:\n            - must be in the set returned by get_dataloaders\n            - must be compatible with model_name as defined by get_compatibilities\n        @param dataset_params: user defined parameters for the dataset\n        @return: Instance of MachineLearningInterface\n        Constructs an object that implements MachineLearningInterface whose\n        underlying model is model_name and dataset is loaded by dataloader_name.\n        \"\"\"\n        pass \n</code></pre> <p>The MLI Factory stores the constructors for dataloaders and models and also a list of the dataloaders that are compatible with each model. Each constructor is stored under a specific name. For example, \"KERAS_MNIST_MODEL\" is the model for keras mnist. The gRPC server uses the MLI factory to construct MLI objects. The MLI Factory needs to implement four methods:</p> <ul> <li>get_models - returns the names of the models that are registered with the factory and their parameters.</li> <li>get_dataloaders - returns the names of the dataloaders that are registered with the factory and their parameters.</li> <li>get_compatibilities - returns a list of dataloaders for each model that can be used with that model.</li> <li>get_mli - takes the name and parameters for the model and dataloader and constructs the MLI object.   Returns the MLI object.</li> </ul>"},{"location":"grpc_tutorial/#using-the-example-mli-factory","title":"Using the example MLI Factory","text":"<p>The example MLI factory is defined in colearn_grpc/example_mli_factory.py. It stores the models and dataloaders that it knows about in factoryRegistry.py To add a new model and dataloader to the factory you need to do the following things:</p> <ol> <li>Define a function that loads the dataset given the location of the dataset.</li> <li>Define a function that takes in the dataset and loads the MLI model.</li> <li>Register both these functions with the factory registry.</li> </ol> <p>Registering a dataloader looks like this:</p> <pre><code>@FactoryRegistry.register_dataloader(dataloader_tag)\ndef prepare_data_loaders(location: str,\n                         train_ratio: float = 0.9,\n                         batch_size: int = 32) -&gt; Tuple[PrefetchDataset, PrefetchDataset]:\n</code></pre> <p>Registering a model is similar, but you additionally have to specify the dataloaders that this model is compatible with.</p> <pre><code>@FactoryRegistry.register_model_architecture(model_tag, [dataloader_tag])\ndef prepare_learner(data_loaders: Tuple[PrefetchDataset, PrefetchDataset],\n                    steps_per_epoch: int = 100,\n                    vote_batches: int = 10,\n                    learning_rate: float = 0.001\n                    ) -&gt; KerasLearner:\n</code></pre> <p>You can see an example of how to do this in colearn_examples/grpc/mnist_grpc.py. The FactoryRegistry decorators get evaluated when the functions are imported, so ensure that the functions are imported before constructing the gRPC server (more on that later).</p> <p>Constraints on the dataloader function:</p> <ol> <li>The first parameter should be a mandatory parameter called \"location\" which stores the location of the dataset.</li> <li>The subsequent parameters should have default arguments.</li> <li>The return type should be specified with a type annotation, and this should be the same type that is expected by the    model functions that use this dataloader.</li> <li>The arguments that you pass to the dataloader function must be    JSON-encodable.    Native python types are fine (e.g. str, dict, list, float).</li> </ol> <p>Constraints on the model function:</p> <ol> <li>The first parameter should be a mandatory parameter called \"data_loaders\".    This must have the same type as the return type of the compatible dataloaders.</li> <li>The subsequent parameters should have default arguments.</li> <li>The return type of model_function should be <code>MachineLearningInterface</code> or a subclass of it (e.g. <code>KerasLearner</code>).</li> <li>The dataloaders listed as being compatible with the model should already be registered with FactoryRegistry before    the model is registered.</li> <li>The arguments that you pass to the model function must be    JSON-encodable.    Native python types are fine (e.g. str, dict, list, float).</li> </ol>"},{"location":"grpc_tutorial/#making-it-all-work-together","title":"Making it all work together","text":"<p>It can be challenging to ensure that all the parts talk to each other, so we have provided some examples and helper scripts. It is recommended to first make an all-in-one script following the example of colearn_examples/grpc/mnist_grpc.py. Once this is working you can run colearn_grpc/scripts/run_n_servers.py or colearn_grpc/scripts/run_grpc_server.py to run the server(s). The script colearn_grpc/scripts/probe_grpc_server.py will connect to a gRPC server and print the dataloaders and models that are registered on it (pass in the address as a parameter). The client side of the gRPC communication can then be run using colearn_examples/grpc/run_grpc_demo.py. More details are given below.</p> <p>A note about running tensorflow in multiple processes: on a system with a GPU, tensorflow will try to get all the GPU memory when it starts up. This means that running tensorflow in multiple processes on the same machine will fail. To prevent this happening, tensorflow should be told to use only the CPU by setting the environment variable <code>CUDA_VISIBLE_DEVIES</code> to <code>-1</code>. This can be done in a python script (before importing tensorflow) by using:</p> <pre><code>import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n</code></pre>"},{"location":"grpc_tutorial/#testing-locally-with-an-all-in-one-script","title":"Testing locally with an all-in-one script","text":"<p>You can test this locally by following the example in colearn_examples/grpc/mnist_grpc.py. Define your dataloader and model functions as specified above, and register them with the factory. Then create n_learners gRPC servers:</p> <pre><code>n_learners = 5\nfirst_server_port = 9995\n# make n servers\nfor i in range(n_learners):\n    port = first_server_port + i\n    server = GRPCServer(mli_factory=ExampleMliFactory(),\n                        port=port)\n    server_process = Process(target=server.run)\n    server_process.start()\n</code></pre> <p>And then create n_learners gRPC clients:</p> <pre><code>all_learner_models = []\nfor i in range(n_learners):\n   port = first_server_port + i\n   ml_system = ExampleGRPCLearnerClient(f\"client {i}\", f\"127.0.0.1:{port}\")\n   ml_system.start()\n   dataloader_params = {\"location\": data_folders[i]}\n   ml_system.setup_ml(dataset_loader_name=dataloader_tag,\n                      dataset_loader_parameters=json.dumps(dataloader_params),\n                      model_arch_name=model_tag,\n                      model_parameters=json.dumps({}))\n   all_learner_models.append(ml_system)\n</code></pre> <p><code>ExampleGRPCLearnerClient</code> inherits from the <code>MachineLearningInterface</code> so you can use it with the training functions as before:</p> <pre><code>for round_index in range(n_rounds):\n    results.data.append(\n        collective_learning_round(all_learner_models,\n                                  vote_threshold, round_index)\n    )\n</code></pre>"},{"location":"grpc_tutorial/#testing-remotely","title":"Testing remotely","text":"<p>We expect that the gRPC learner part will often be on a compute cluster and be separate from the gRPC client side. To test the gRPC in a setup like this you can start the servers on the computer side and the client part separately. For one gRPC server:</p> <pre><code>python3 ./colearn_grpc/scripts/run_grpc_server.py --port 9995 --metrics_port 9091\n</code></pre> <p>For multiple gRPC servers:</p> <pre><code>python3 ./colearn_grpc/scrips/run_n_grpc_servers.py --n_learners 5 --port 9995 --metrics_port 9091\n</code></pre> <p>The servers by default will start on port 9995 and use subsequent ports from there, so if three servers are required they will run on ports 9995, 9996 and 9997.</p> <p>If you have written your own dataloaders and models then you need to make sure that those functions are defined or imported before the server is created. These are the imports of the default dataloaders and models in <code>colearn_grpc/scripts/run_grpc_server.py</code>:</p> <pre><code># These are imported so that they are registered in the FactoryRegistry\nimport colearn_keras.keras_mnist\nimport colearn_keras.keras_cifar10\nimport colearn_pytorch.pytorch_xray\nimport colearn_pytorch.pytorch_covid_xray\nimport colearn_other.fraud_dataset\n</code></pre> <p>Once the gRPC server(s) are running, set up whatever networking and port forwarding is required. You can check that the gRPC server is accessible by using the probe script:</p> <pre><code>python3 ./colearn_grpc/scripts/probe_grpc_server.py --port 9995\n</code></pre> <p>If the connection is successful this will print a list of the models and datasets registered on the server. These are the defaults that are registered:</p> <pre><code>info: Attempt number 0 to connect to 127.0.0.1:9995\ninfo: Successfully connected to 127.0.0.1:9995!\n{'compatibilities': {'FRAUD': ['FRAUD'],\n                     'KERAS_CIFAR10': ['KERAS_CIFAR10'],\n                     'KERAS_MNIST': ['KERAS_MNIST'],\n                     'KERAS_MNIST_RESNET': ['KERAS_MNIST'],\n                     'PYTORCH_COVID_XRAY': ['PYTORCH_COVID_XRAY'],\n                     'PYTORCH_XRAY': ['PYTORCH_XRAY']},\n 'data_loaders': {'FRAUD': '{\"train_ratio\": 0.8}',\n                  'KERAS_CIFAR10': '{\"train_ratio\": 0.9, \"batch_size\": 32}',\n                  'KERAS_MNIST': '{\"train_ratio\": 0.9, \"batch_size\": 32}',\n                  'PYTORCH_COVID_XRAY': '{\"train_ratio\": 0.8, \"batch_size\": 8, '\n                                        '\"no_cuda\": false}',\n                  'PYTORCH_XRAY': '{\"test_location\": null, \"train_ratio\": 0.96, '\n                                  '\"batch_size\": 8, \"no_cuda\": false}'},\n 'model_architectures': {'FRAUD': '{}',\n                         'KERAS_CIFAR10': '{\"steps_per_epoch\": 100, '\n                                          '\"vote_batches\": 10, '\n                                          '\"learning_rate\": 0.001}',\n                         'KERAS_MNIST': '{\"steps_per_epoch\": 100, '\n                                        '\"vote_batches\": 10, \"learning_rate\": '\n                                        '0.001}',\n                         'KERAS_MNIST_RESNET': '{\"steps_per_epoch\": 100, '\n                                               '\"vote_batches\": 10, '\n                                               '\"learning_rate\": 0.001}',\n                         'PYTORCH_COVID_XRAY': '{\"learning_rate\": 0.001, '\n                                               '\"steps_per_epoch\": 40, '\n                                               '\"vote_batches\": 10, \"no_cuda\": '\n                                               'false, \"vote_on_accuracy\": '\n                                               'true}',\n                         'PYTORCH_XRAY': '{\"learning_rate\": 0.001, '\n                                         '\"steps_per_epoch\": 40, '\n                                         '\"vote_batches\": 10, \"no_cuda\": '\n                                         'false, \"vote_on_accuracy\": true}'}}\n</code></pre> <p>Then run <code>python -m colearn_examples.grpc.run_grpc_demo</code> on the other side to run the usual demo. The script takes as arguments the model name and dataset name that should be run, along with the number of learners and the data location for each learner.</p> <pre><code>python -m colearn_examples.grpc.run_grpc_demo --n_learners 5 --dataloader_tag KERAS_MNIST --model_tag KERAS_MNIST \\\n--data_locations /tmp/mnist/0,/tmp/mnist/1,/tmp/mnist/2,/tmp/mnist/3,/tmp/mnist/4\n</code></pre>"},{"location":"grpc_tutorial/#using-the-mli-factory-interface","title":"Using the MLI Factory interface","text":"<p>An alternative method of using your own dataloaders and models with the gRPC server is to use the MLI Factory interface. This is defined in <code>colearn_grpc/mli_factory_interface.py</code>. An example is given in <code>colearn_examples/grpc/mlifactory_grpc_mnist.py</code>. The MLI Factory is implemented as shown:</p> <pre><code>dataloader_tag = \"KERAS_MNIST_EXAMPLE_DATALOADER\"\nmodel_tag = \"KERAS_MNIST_EXAMPLE_MODEL\"\n\nclass SimpleFactory(MliFactory):\n    def get_dataloaders(self) -&gt; Dict[str, Dict[str, Any]]:\n        return {dataloader_tag: dict(train_ratio=0.9,\n                                     batch_size=32)}\n\n    def get_models(self) -&gt; Dict[str, Dict[str, Any]]:\n        return {model_tag: dict(steps_per_epoch=100,\n                                vote_batches=10,\n                                learning_rate=0.001)}\n\n    def get_compatibilities(self) -&gt; Dict[str, Set[str]]:\n        return {model_tag: {dataloader_tag}}\n\n    def get_mli(self, model_name: str, model_params: str, dataloader_name: str,\n                dataset_params: str) -&gt; MachineLearningInterface:\n        dataloader_params = json.loads(dataset_params)\n        data_loaders = prepare_data_loaders(**dataloader_params)\n\n        model_params = json.loads(model_params)\n        mli_model = prepare_learner(data_loaders=data_loaders, **model_params)\n        return mli_model\n</code></pre> <p>An instance of the <code>SimpleFactory</code> class needs to be passed to the gRPC server on creation:</p> <pre><code>n_learners = 5\nfirst_server_port = 9995\n# make n servers\nserver_processes = []\nfor i in range(n_learners):\n    port = first_server_port + i\n    server = GRPCServer(mli_factory=SimpleFactory(),\n                        port=port)\n    server_process = Process(target=server.run)\n    print(\"starting server\", i)\n    server_process.start()\n    server_processes.append(server_process)\n</code></pre> <p>The rest of the example follows the <code>grpc_mnist.py</code> example.</p>"},{"location":"installation/","title":"Installation","text":"<p>The core package, <code>colearn</code>, contains only the MachineLearningInterface and a simple driver that implements the Collective Learning Protocol. To install only the core package:</p> <pre><code>pip install colearn\n</code></pre> <p>To make collective learning easier to use we have defined extra packages with helpers for model development in Keras and Pytorch.</p> <p>To install with Keras/Pytorch extras:</p> <pre><code>pip install colearn[keras]\npip install colearn[pytorch]\n</code></pre> <p>To install both the Keras and Pytorch extras use:</p> <pre><code>pip install colearn[all]\n</code></pre> <p>To run stand-alone examples:</p> <pre><code> python -m colearn_examples.ml_interface.run_demo\n</code></pre> <p>For more examples see the Examples Page</p>"},{"location":"installation/#installing-from-source","title":"Installing From Source","text":"<p>Alternatively, to install the latest code from the repo:</p> <ol> <li>Download the source code from github:</li> </ol> <pre><code>git clone https://github.com/fetchai/colearn.git &amp;&amp; cd colearn\n</code></pre> <ol> <li>Create and launch a clean virtual environment with Python 3.7.    (This library has currently only been tested with Python 3.7).</li> </ol> <pre><code>pipenv --python 3.7 &amp;&amp; pipenv shell\n</code></pre> <ol> <li> <p>Install the package from source:</p> <pre><code>pip install -e .[all]\n</code></pre> </li> <li> <p>Run one of the examples:</p> <pre><code>python colearn_examples/ml_interface/pytorch_mnist.py\n</code></pre> </li> </ol> <p>If you are developing the colearn library then install it in editable mode so that new changes are effective immediately:</p> <pre><code>pip install -e .[all]\n</code></pre>"},{"location":"installation/#running-the-tests","title":"Running the tests","text":"<p>Tests can be run with:</p> <pre><code>tox\n</code></pre>"},{"location":"installation/#documentation","title":"Documentation","text":"<p>To run the documentation, first install mkdocs and plugins:</p> <pre><code>pip install .[docs] </code></pre> <p>Then run:</p> <pre><code>mkdocs serve\n</code></pre>"},{"location":"intro_tutorial_keras/","title":"Using collective learning with keras","text":"<p>This tutorial is a simple guide to trying out the collective learning protocol with your own machine learning code. Everything runs locally.</p> <p>The most flexible way to use the collective learning backends is to make a class that implements the Collective Learning <code>MachineLearningInterface</code> defined in ml_interface.py. For more details on how to use the <code>MachineLearningInterface</code> see here</p> <p>However, the simpler way is to use one of the helper classes that we have provided that implement most of the interface for popular ML libraries. In this tutorial we are going to walk through using the <code>KerasLearner</code>. First we are going to define the model architecture, then we are going to load the data and configure the model, and then we will run Collective Learning.</p> <p>A standard script for machine learning with Keras looks like the one below</p> <pre><code># ------------------------------------------------------------------------------\n#\n#   Copyright 2021 Fetch.AI Limited\n#\n#   Licensed under the Creative Commons Attribution-NonCommercial International\n#   License, Version 4.0 (the \"License\"); you may not use this file except in\n#   compliance with the License. You may obtain a copy of the License at\n#\n#       http://creativecommons.org/licenses/by-nc/4.0/legalcode\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\n#\n# ------------------------------------------------------------------------------\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\nfrom colearn_keras.utils import normalize_img\n\nn_rounds = 20\nwidth = 28\nheight = 28\nn_classes = 10\nl_rate = 0.001\nbatch_size = 64\n\n# Load the data\ntrain_dataset, info = tfds.load('mnist', split='train', as_supervised=True, with_info=True)\nn_train = info.splits['train'].num_examples\ntest_dataset = tfds.load('mnist', split='test', as_supervised=True)\n\ntrain_dataset = train_dataset.map(normalize_img,\n                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\ntrain_dataset = train_dataset.shuffle(n_train)\ntrain_dataset = train_dataset.batch(batch_size)\n\ntest_dataset = test_dataset.map(normalize_img,\n                                num_parallel_calls=tf.data.experimental.AUTOTUNE)\ntest_dataset = test_dataset.batch(batch_size)\n\n# Define the model\ninput_img = tf.keras.Input(shape=(width, height, 1), name=\"Input\")\nx = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", name=\"Conv1_1\")(input_img)\nx = tf.keras.layers.BatchNormalization(name=\"bn1\")(x)\nx = tf.keras.layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\nx = tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", name=\"Conv2_1\")(x)\nx = tf.keras.layers.BatchNormalization(name=\"bn4\")(x)\nx = tf.keras.layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\nx = tf.keras.layers.Flatten(name=\"flatten\")(x)\nx = tf.keras.layers.Dense(n_classes, activation=\"softmax\", name=\"fc1\")(x)\nmodel = tf.keras.Model(inputs=input_img, outputs=x)\n\nopt = tf.keras.optimizers.Adam(lr=l_rate)\nmodel.compile(\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n    optimizer=opt)\n\n# Train and evaluate model\nfor round in range(n_rounds):\n    model.fit(train_dataset, steps_per_epoch=40)\n    result = model.evaluate(x=test_dataset, return_dict=True, steps=10)\n    print(f\"Performance at round {round} is {result}\")\n</code></pre> <p>There are three steps:</p> <ol> <li>Load the data</li> <li>Define the model</li> <li>Train the model</li> </ol> <p>In this tutorial we are going to see how to modify each step to use collective learning. We'll end up with code like this:</p> <pre><code># ------------------------------------------------------------------------------\n#\n#   Copyright 2021 Fetch.AI Limited\n#\n#   Licensed under the Creative Commons Attribution-NonCommercial International\n#   License, Version 4.0 (the \"License\"); you may not use this file except in\n#   compliance with the License. You may obtain a copy of the License at\n#\n#       http://creativecommons.org/licenses/by-nc/4.0/legalcode\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\n#\n# ------------------------------------------------------------------------------\nimport os\n\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\nfrom colearn.training import initial_result, collective_learning_round, set_equal_weights\nfrom colearn.utils.plot import ColearnPlot\nfrom colearn.utils.results import Results, print_results\nfrom colearn_keras.keras_learner import KerasLearner\nfrom colearn_keras.utils import normalize_img\n\n\"\"\"\nMNIST training example using Keras\n\nUsed dataset:\n- MNIST is set of 60 000 black and white hand written digits images of size 28x28x1 in 10 classes\n\nWhat script does:\n- Loads MNIST dataset from Keras\n- Sets up a Keras learner\n- Randomly splits dataset between multiple learners\n- Does multiple rounds of learning process and displays plot with results\n\"\"\"\n\nn_learners = 5\nvote_threshold = 0.5\nvote_batches = 2\n\ntesting_mode = bool(os.getenv(\"COLEARN_EXAMPLES_TEST\", \"\"))  # for testing\nn_rounds = 20 if not testing_mode else 1\nwidth = 28\nheight = 28\nn_classes = 10\nl_rate = 0.001\nbatch_size = 64\n\n# Load data for each learner\ntrain_dataset, info = tfds.load('mnist', split='train', as_supervised=True, with_info=True)\nn_datapoints = info.splits['train'].num_examples\n\ntrain_datasets = [train_dataset.shard(num_shards=n_learners, index=i) for i in range(n_learners)]\n\ntest_dataset = tfds.load('mnist', split='test', as_supervised=True)\nvote_datasets = [test_dataset.shard(num_shards=2 * n_learners, index=i) for i in range(n_learners)]\ntest_datasets = [test_dataset.shard(num_shards=2 * n_learners, index=i) for i in range(n_learners, 2 * n_learners)]\n\n\nfor i in range(n_learners):\n    train_datasets[i] = train_datasets[i].map(\n        normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    train_datasets[i] = train_datasets[i].shuffle(n_datapoints // n_learners)\n    train_datasets[i] = train_datasets[i].batch(batch_size)\n\n    vote_datasets[i] = vote_datasets[i].map(\n        normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    vote_datasets[i] = vote_datasets[i].batch(batch_size)\n\n    test_datasets[i] = test_datasets[i].map(\n        normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    test_datasets[i] = test_datasets[i].batch(batch_size)\n\n\n# Define model\ndef get_model():\n    input_img = tf.keras.Input(\n        shape=(width, height, 1), name=\"Input\"\n    )\n    x = tf.keras.layers.Conv2D(\n        64, (3, 3), activation=\"relu\", padding=\"same\", name=\"Conv1_1\"\n    )(input_img)\n    x = tf.keras.layers.BatchNormalization(name=\"bn1\")(x)\n    x = tf.keras.layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n    x = tf.keras.layers.Conv2D(\n        128, (3, 3), activation=\"relu\", padding=\"same\", name=\"Conv2_1\"\n    )(x)\n    x = tf.keras.layers.BatchNormalization(name=\"bn4\")(x)\n    x = tf.keras.layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n    x = tf.keras.layers.Flatten(name=\"flatten\")(x)\n    x = tf.keras.layers.Dense(\n        n_classes, activation=\"softmax\", name=\"fc1\"\n    )(x)\n    model = tf.keras.Model(inputs=input_img, outputs=x)\n\n    opt = tf.keras.optimizers.Adam(lr=l_rate)\n    model.compile(\n        loss=\"sparse_categorical_crossentropy\",\n        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n        optimizer=opt)\n    return model\n\n\nall_learner_models = []\nfor i in range(n_learners):\n    all_learner_models.append(KerasLearner(\n        model=get_model(),\n        train_loader=train_datasets[i],\n        vote_loader=vote_datasets[i],\n        test_loader=test_datasets[i],\n        criterion=\"sparse_categorical_accuracy\",\n        minimise_criterion=False,\n        model_evaluate_kwargs={\"steps\": vote_batches},\n    ))\n\nset_equal_weights(all_learner_models)\n\n# Train the model using Collective Learning\nresults = Results()\nresults.data.append(initial_result(all_learner_models))\n\nplot = ColearnPlot(score_name=all_learner_models[0].criterion)\n\nfor round_index in range(n_rounds):\n    results.data.append(\n        collective_learning_round(all_learner_models,\n                                  vote_threshold, round_index)\n    )\n\n    print_results(results)\n    plot.plot_results_and_votes(results)\n\nplot.block()\n\nprint(\"Colearn Example Finished!\")\n</code></pre> <p>The first thing is to modify the data loading code. Each learner needs to have their own training and testing set from the data. This is easy to do with keras:</p> <pre><code>train_datasets = [train_dataset.shard(num_shards=n_learners, index=i) for i in range(n_learners)]\n</code></pre> <p>The model definition is very similar too, except that each learner will need its own copy of the model, so we've moved it into a function.</p> <p>To use collective learning, we need to create an object that implements the MachineLearningInterface. To make it easier to use the <code>MachineLearningInterface</code> with keras, we've defined <code>KerasLearner</code>. <code>KerasLearner</code> implements standard training and evaluation routines as well as the MachineLearningInterface methods.</p> <pre><code># ------------------------------------------------------------------------------\n#\n#   Copyright 2021 Fetch.AI Limited\n#\n#   Licensed under the Creative Commons Attribution-NonCommercial International\n#   License, Version 4.0 (the \"License\"); you may not use this file except in\n#   compliance with the License. You may obtain a copy of the License at\n#\n#       http://creativecommons.org/licenses/by-nc/4.0/legalcode\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\n#\n# ------------------------------------------------------------------------------\nfrom inspect import signature\nfrom typing import Optional\n\ntry:\n    import tensorflow as tf\nexcept ImportError:\n    raise Exception(\"Tensorflow is not installed. To use the tensorflow/keras \"\n                    \"add-ons please install colearn with `pip install colearn[keras]`.\")\nfrom tensorflow import keras\n\nfrom colearn.ml_interface import MachineLearningInterface, Weights, ProposedWeights, ColearnModel, ModelFormat, convert_model_to_onnx\nfrom colearn.ml_interface import DiffPrivBudget, DiffPrivConfig, TrainingSummary, ErrorCodes\nfrom tensorflow_privacy.privacy.analysis.compute_dp_sgd_privacy import compute_dp_sgd_privacy\nfrom tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import make_keras_optimizer_class\n\n\nclass KerasLearner(MachineLearningInterface):\n\"\"\"\n    Tensorflow Keras learner implementation of machine learning interface\n    \"\"\"\n\n    def __init__(self, model: keras.Model,\n                 train_loader: tf.data.Dataset,\n                 vote_loader: tf.data.Dataset,\n                 test_loader: Optional[tf.data.Dataset] = None,\n                 need_reset_optimizer: bool = True,\n                 minimise_criterion: bool = True,\n                 criterion: str = 'loss',\n                 model_fit_kwargs: Optional[dict] = None,\n                 model_evaluate_kwargs: Optional[dict] = None,\n                 diff_priv_config: Optional[DiffPrivConfig] = None):\n\"\"\"\n        :param model: Keras model used for training\n        :param train_loader: Training dataset\n        :param test_loader: Optional test set. Subset of training set will be used if not specified.\n        :param need_reset_optimizer: True to clear optimizer history before training, False to kepp history.\n        :param minimise_criterion: Boolean - True to minimise value of criterion, False to maximise\n        :param criterion: Function to measure model performance\n        :param model_fit_kwargs: Arguments to be passed on model.fit function call\n        :param model_evaluate_kwargs: Arguments to be passed on model.evaluate function call\n        :param diff_priv_config: Contains differential privacy (dp) budget related configuration\n        \"\"\"\n        self.model: keras.Model = model\n        self.train_loader: tf.data.Dataset = train_loader\n        self.vote_loader: tf.data.Dataset = vote_loader\n        self.test_loader: Optional[tf.data.Dataset] = test_loader\n        self.need_reset_optimizer = need_reset_optimizer\n        self.minimise_criterion: bool = minimise_criterion\n        self.criterion = criterion\n        self.model_fit_kwargs = model_fit_kwargs or {}\n        self.diff_priv_config = diff_priv_config\n        self.cumulative_epochs = 0\n\n        if self.diff_priv_config is not None:\n            self.diff_priv_budget = DiffPrivBudget(\n                target_epsilon=self.diff_priv_config.target_epsilon,\n                target_delta=self.diff_priv_config.target_delta,\n                consumed_epsilon=0.0,\n                # we will always use the highest available delta now\n                consumed_delta=self.diff_priv_config.target_delta\n            )\n            if 'epochs' in self.model_fit_kwargs.keys():\n                self.epochs_per_proposal = self.model_fit_kwargs['epochs']\n            else:\n                self.epochs_per_proposal = signature(self.model.fit).parameters['epochs'].default\n\n        if model_fit_kwargs:\n            # check that these are valid kwargs for model fit\n            sig = signature(self.model.fit)\n            try:\n                sig.bind_partial(**self.model_fit_kwargs)\n            except TypeError:\n                raise Exception(\"Invalid arguments for model.fit\")\n\n        self.model_evaluate_kwargs = model_evaluate_kwargs or {}\n\n        if model_evaluate_kwargs:\n            # check that these are valid kwargs for model evaluate\n            sig = signature(self.model.evaluate)\n            try:\n                sig.bind_partial(**self.model_evaluate_kwargs)\n            except TypeError:\n                raise Exception(\"Invalid arguments for model.evaluate\")\n\n        self.vote_score: float = self.test(self.vote_loader)\n\n    def reset_optimizer(self):\n\"\"\"\n        Recompiles the Keras model. This way the optimizer history get erased,\n        which is needed before a new training round, otherwise the outdated history is used.\n        \"\"\"\n        compile_args = self.model._get_compile_args()  # pylint: disable=protected-access\n        opt_config = self.model.optimizer.get_config()\n\n        if self.diff_priv_config is not None:\n            # tensorflow_privacy optimizers get_config() miss the additional parameters\n            # was fixed here: https://github.com/tensorflow/privacy/commit/49db04e3561638fc02795edb5774d322cdd1d7d1\n            # but it is not yet in the stable version, thus I need here to do the same.\n            opt_config.update({\n                'l2_norm_clip': self.model.optimizer._l2_norm_clip,  # pylint: disable=protected-access\n                'noise_multiplier': self.model.optimizer._noise_multiplier,  # pylint: disable=protected-access\n                'num_microbatches': self.model.optimizer._num_microbatches,  # pylint: disable=protected-access\n            })\n            new_opt = make_keras_optimizer_class(\n                getattr(keras.optimizers, opt_config['name'])\n            ).from_config(opt_config)\n            compile_args['optimizer'] = new_opt\n        else:\n            compile_args['optimizer'] = getattr(keras.optimizers,\n                                                opt_config['name']).from_config(opt_config)\n\n        self.model.compile(**compile_args)\n\n    def mli_propose_weights(self) -&gt; Weights:\n\"\"\"\n        Trains model on training set and returns new weights after training\n        - Current model is reverted to original state after training\n        :return: Weights after training\n        \"\"\"\n        current_weights = self.mli_get_current_weights()\n\n        if self.diff_priv_config is not None:\n            epsilon_after_training = self.get_privacy_budget()\n            if epsilon_after_training &gt; self.diff_priv_budget.target_epsilon:\n                return Weights(\n                    weights=current_weights,\n                    training_summary=TrainingSummary(\n                        dp_budget=self.diff_priv_budget,\n                        error_code=ErrorCodes.DP_BUDGET_EXCEEDED\n                    )\n                )\n\n        self.train()\n        new_weights = self.mli_get_current_weights()\n        self.set_weights(current_weights)\n\n        if self.diff_priv_config is not None:\n            self.diff_priv_budget.consumed_epsilon = epsilon_after_training\n            self.cumulative_epochs += self.epochs_per_proposal\n            new_weights.training_summary = TrainingSummary(dp_budget=self.diff_priv_budget)\n\n        return new_weights\n\n    def mli_test_weights(self, weights: Weights) -&gt; ProposedWeights:\n\"\"\"\n        Tests given weights on training and test set and returns weights with score values\n        :param weights: Weights to be tested\n        :return: ProposedWeights - Weights with vote and test score\n        \"\"\"\n        current_weights = self.mli_get_current_weights()\n        self.set_weights(weights)\n\n        vote_score = self.test(self.vote_loader)\n\n        if self.test_loader:\n            test_score = self.test(self.test_loader)\n        else:\n            test_score = 0\n        vote = self.vote(vote_score)\n\n        self.set_weights(current_weights)\n\n        return ProposedWeights(weights=weights,\n                               vote_score=vote_score,\n                               test_score=test_score,\n                               vote=vote,\n                               )\n\n    def vote(self, new_score) -&gt; bool:\n\"\"\"\n        Compares current model score with proposed model score and returns vote\n        :param new_score: Proposed score\n        :return: bool positive or negative vote\n        \"\"\"\n\n        if self.minimise_criterion:\n            return new_score &lt; self.vote_score\n        else:\n            return new_score &gt; self.vote_score\n\n    def mli_accept_weights(self, weights: Weights):\n\"\"\"\n        Updates the model with the proposed set of weights\n        :param weights: The new weights\n        \"\"\"\n        self.set_weights(weights)\n        self.vote_score = self.test(self.vote_loader)\n\n    def get_train_batch_size(self) -&gt; int:\n\"\"\"\n        Calculates train batch size.\n        \"\"\"\n        if hasattr(self.train_loader, '_batch_size'):\n            return self.train_loader._batch_size  # pylint: disable=protected-access\n        else:\n            return self.train_loader._input_dataset._batch_size  # pylint: disable=protected-access\n\n    def get_privacy_budget(self) -&gt; float:\n\"\"\"\n        Calculates, what epsilon will apply after another model training.\n        Need to calculate it in advance to see if another training would result in privacy budget violation.\n        \"\"\"\n        batch_size = self.get_train_batch_size()\n        iterations_per_epoch = tf.data.experimental.cardinality(self.train_loader).numpy()\n        n_samples = batch_size * iterations_per_epoch\n        planned_epochs = self.cumulative_epochs + self.epochs_per_proposal\n\n        epsilon, _ = compute_dp_sgd_privacy(\n            n=n_samples,\n            batch_size=batch_size,\n            noise_multiplier=self.diff_priv_config.noise_multiplier,  # type: ignore\n            epochs=planned_epochs,\n            delta=self.diff_priv_budget.target_delta\n        )\n        return epsilon\n\n    def mli_get_current_weights(self) -&gt; Weights:\n\"\"\"\n        :return: The current weights of the model\n        \"\"\"\n        return Weights(weights=self.model.get_weights())\n\n    def mli_get_current_model(self) -&gt; ColearnModel:\n\"\"\"\n        :return: The current model and its format\n        \"\"\"\n\n        return ColearnModel(\n            model_format=ModelFormat(ModelFormat.ONNX),\n            model_file=\"\",\n            model=convert_model_to_onnx(self.model),\n        )\n\n    def set_weights(self, weights: Weights):\n\"\"\"\n        Rewrites weight of current model\n        :param weights: Weights to be stored\n        \"\"\"\n        self.model.set_weights(weights.weights)\n\n    def train(self):\n\"\"\"\n        Trains the model on the training dataset\n        \"\"\"\n\n        if self.need_reset_optimizer:\n            # erase the outdated optimizer memory (momentums mostly)\n            self.reset_optimizer()\n\n        self.model.fit(self.train_loader, **self.model_fit_kwargs)\n\n    def test(self, loader: tf.data.Dataset) -&gt; float:\n\"\"\"\n        Tests performance of the model on specified dataset\n        :param loader: Dataset for testing\n        :return: Value of performance metric\n        \"\"\"\n        result = self.model.evaluate(x=loader, return_dict=True,\n                                     **self.model_evaluate_kwargs)\n        return result[self.criterion]\n</code></pre> <p>We create a set of KerasLearners by passing in the model and the datasets:</p> <pre><code>all_learner_models = []\nfor i in range(n_learners):\n    all_learner_models.append(KerasLearner(\n        model=get_model(),\n        train_loader=train_datasets[i],\n        vote_loader=vote_datasets[i],\n        test_loader=test_datasets[i],\n        criterion=\"sparse_categorical_accuracy\",\n        minimise_criterion=False,\n        model_evaluate_kwargs={\"steps\": vote_batches},\n    ))\n</code></pre> <p>Then we give all the models the same weights to start off with:</p> <pre><code>set_equal_weights(all_learner_models)\n</code></pre> <p>And then we can move on to the final stage, which is training with Collective Learning. The function <code>collective_learning_round</code> performs one round of collective learning. One learner is selected to train and propose an update. The other learners vote on the update, and if the vote passes then the update is accepted. Then a new round begins.</p> <pre><code># Train the model using Collective Learning\nresults = Results()\nresults.data.append(initial_result(all_learner_models))\n\nfor round in range(n_rounds):\n    results.data.append(\n        collective_learning_round(all_learner_models,\n                                  vote_threshold, round)\n    )\n\n    plot_results(results, n_learners, block=False,\n                 score_name=all_learner_models[0].criterion)\n    plot_votes(results, block=False)\n\nplot_results(results, n_learners, block=False,\n             score_name=all_learner_models[0].criterion)\nplot_votes(results, block=True)\n</code></pre>"},{"location":"intro_tutorial_mli/","title":"Using collective learning","text":"<p>This tutorial is a simple guide to trying out the collective learning protocol with your own machine learning code. Everything runs locally.</p> <p>The most flexible way to use the collective learning backends is to make a class that implements the Collective Learning <code>MachineLearningInterface</code> defined in ml_interface.py. This tutorial will walk through implementing the <code>MachineLearningInterface</code>. If you're already using keras or pytorch you might find it easier to use the <code>KerasLearner</code> or <code>Pytorchlearner</code> classes. See the other tutorials for details of how to do that.</p>"},{"location":"intro_tutorial_mli/#the-machinelearninginterface","title":"The MachineLearningInterface","text":"<pre><code># ------------------------------------------------------------------------------\n#\n#   Copyright 2021 Fetch.AI Limited\n#\n#   Licensed under the Creative Commons Attribution-NonCommercial International\n#   License, Version 4.0 (the \"License\"); you may not use this file except in\n#   compliance with the License. You may obtain a copy of the License at\n#\n#       http://creativecommons.org/licenses/by-nc/4.0/legalcode\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\n#\n# ------------------------------------------------------------------------------\nimport abc\nfrom enum import Enum\nfrom typing import Any, Optional\n\nimport onnx\nimport onnxmltools\nimport sklearn\nimport tensorflow as tf\nimport torch\nfrom pydantic import BaseModel\nfrom tensorflow import keras\n\nmodel_classes_keras = (tf.keras.Model, keras.Model, tf.estimator.Estimator)\nmodel_classes_scipy = (torch.nn.Module)\nmodel_classes_sklearn = (sklearn.base.ClassifierMixin)\n\n\ndef convert_model_to_onnx(model: Any):\n\"\"\"\n    Helper function to convert a ML model to onnx format\n    \"\"\"\n    if isinstance(model, model_classes_keras):\n        return onnxmltools.convert_keras(model)\n    if isinstance(model, model_classes_sklearn):\n        return onnxmltools.convert_sklearn(model)\n    if 'xgboost' in model.__repr__():\n        return onnxmltools.convert_sklearn(model)\n    if isinstance(model, model_classes_scipy):\n        raise Exception(\"Pytorch models not yet supported to onnx\")\n    else:\n        raise Exception(\"Attempt to convert unsupported model to onnx: {model}\")\n\n\nclass DiffPrivBudget(BaseModel):\n    target_epsilon: float\n    target_delta: float\n    consumed_epsilon: float\n    consumed_delta: float\n\n\nclass ErrorCodes(Enum):\n    DP_BUDGET_EXCEEDED = 1\n\n\nclass TrainingSummary(BaseModel):\n    dp_budget: Optional[DiffPrivBudget]\n    error_code: Optional[ErrorCodes]\n\n\nclass Weights(BaseModel):\n    weights: Any\n    training_summary: Optional[TrainingSummary]\n\n\nclass DiffPrivConfig(BaseModel):\n    target_epsilon: float\n    target_delta: float\n    max_grad_norm: float\n    noise_multiplier: float\n\n\nclass ProposedWeights(BaseModel):\n    weights: Weights\n    vote_score: float\n    test_score: float\n    vote: Optional[bool]\n\n\nclass ModelFormat(Enum):\n    PICKLE_WEIGHTS_ONLY = 1\n    ONNX = 2\n\n\nclass ColearnModel(BaseModel):\n    model_format: ModelFormat\n    model_file: Optional[str]\n    model: Optional[Any]\n\n\ndef deser_model(model: Any) -&gt; onnx.ModelProto:\n\"\"\"\n    Helper function to recover a onnx model from its deserialized form\n    \"\"\"\n    return onnx.load_model_from_string(model)\n\n\nclass MachineLearningInterface(abc.ABC):\n    @abc.abstractmethod\n    def mli_propose_weights(self) -&gt; Weights:\n\"\"\"\n        Trains the model. Returns new weights. Does not change the current weights of the model.\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def mli_test_weights(self, weights: Weights) -&gt; ProposedWeights:\n\"\"\"\n        Tests the proposed weights and fills in the rest of the fields\n        \"\"\"\n\n    @abc.abstractmethod\n    def mli_accept_weights(self, weights: Weights):\n\"\"\"\n        Updates the model with the proposed set of weights\n        :param weights: The new weights\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def mli_get_current_weights(self) -&gt; Weights:\n\"\"\"\n        Returns the current weights of the model\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def mli_get_current_model(self) -&gt; ColearnModel:\n\"\"\"\n        Returns the current model\n        \"\"\"\n        pass \n</code></pre> <p>There are four methods that need to be implemented:</p> <ol> <li><code>propose_weights</code> causes the model to do some training and then return a    new set of weights that are proposed to the other learners.    This method shouldn't charge the current weights of the model - that    only happens when <code>accept_weights</code> is called.</li> <li><code>test_weights</code> - the models takes some new weights and returns a vote on whether the new weights are an improvement.    As in propose_weights, this shouldn't change the current weights of the model -    that only happens when <code>accept_weights</code> is called.</li> <li><code>accept_weights</code> - the model accepts some weights that have been voted on and approved by the set of learners.     The old weighs of the model are discarded and replaced by the new weights.</li> <li><code>current_weights</code> should return the current weights of the model.</li> </ol>"},{"location":"intro_tutorial_mli/#algorithms-that-work-with-colearn","title":"Algorithms that work with colearn","text":"<p>These conditions need to be fulfilled for algorithms to work with collective learning:</p> <ul> <li>Model fitting must be incremental so that the previous model is used as the starting point for training.   This is easy to achieve for neural networks because neural network training is always iterative, but for other   learning algorithms more care must be taken. Some examples of getting this wrong:</li> </ul> <pre><code>from sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(X, y)\n</code></pre> <pre><code>from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators=10)  # it would be okay with warm_start=True\nmodel.fit(X, y)\n</code></pre> <pre><code>from xgboost import XGBRegressor\nmodel = XGBRegressor()\nmodel.fit(X, y)\n</code></pre> <p>None of the training methods here use the previous result when fit is called for a second time;   instead they start again from scratch.   Good examples of incremental training can be seen in the examples.   Many sklearn models have a <code>warm_start</code> parameter which can be set to <code>True</code> to use the previous training result.   XGBoost has an <code>xgb_model</code> parameter for passing in the previous training results.</p> <ul> <li>The model mustn't overfit when propose_weights() is called.   You should limit training so that a learner will not overfit their training data in one round.   For example, if a learner overfits their own training data then the other learners will reject the   proposed update because it is not a good fit for their data.   For a neural network a good approach is to restrict the number of batches that are used each round;   for  random forest, restrict the trees that are added each round.</li> </ul>"},{"location":"intro_tutorial_mli/#implementation-for-fraud-detection-task","title":"Implementation for fraud detection task","text":"<p>Here is the class that implements the <code>MachineLearningInterface</code> for the task of detecting fraud in bank transactions.</p> <pre><code>class FraudSklearnLearner(MachineLearningInterface):\n    def __init__(self, train_data, train_labels, test_data, test_labels,\n                 batch_size: int = 10000,\n                 steps_per_round: int = 1):\n        self.steps_per_round = steps_per_round\n        self.batch_size = batch_size\n        self.train_data = train_data\n        self.train_labels = train_labels\n        self.test_data = test_data\n        self.test_labels = test_labels\n\n        self.class_labels = np.unique(train_labels)\n        self.train_sampler = infinite_batch_sampler(train_data.shape[0], batch_size)\n\n        self.model = SGDClassifier(max_iter=1, verbose=0, loss=\"modified_huber\")\n        self.model.partial_fit(self.train_data[0:1], self.train_labels[0:1],\n                               classes=self.class_labels)  # this needs to be called before predict\n        self.vote_score = self.test(self.train_data, self.train_labels)\n\n    def mli_propose_weights(self) -&gt; Weights:\n        current_weights = self.mli_get_current_weights()\n\n        for i in range(self.steps_per_round):\n            batch_indices = next(self.train_sampler)\n            train_data = self.train_data[batch_indices]\n            train_labels = self.train_labels[batch_indices]\n            self.model.partial_fit(train_data, train_labels, classes=self.class_labels)\n\n        new_weights = self.mli_get_current_weights()\n        self.set_weights(current_weights)\n        return new_weights\n\n    def mli_test_weights(self, weights: Weights) -&gt; ProposedWeights:\n        current_weights = self.mli_get_current_weights()\n        self.set_weights(weights)\n\n        vote_score = self.test(self.train_data, self.train_labels)\n\n        test_score = self.test(self.test_data, self.test_labels)\n\n        vote = self.vote_score &lt;= vote_score\n\n        self.set_weights(current_weights)\n        return ProposedWeights(weights=weights,\n                               vote_score=vote_score,\n                               test_score=test_score,\n                               vote=vote\n                               )\n\n    def mli_accept_weights(self, weights: Weights):\n        self.set_weights(weights)\n        self.vote_score = self.test(self.train_data, self.train_labels)\n\n    def mli_get_current_weights(self):\n        # return Weights(weights=copy.deepcopy(self.model))\n        return Weights(weights=dict(coef_=self.model.coef_,\n                                    intercept_=self.model.intercept_))\n\n    def set_weights(self, weights: Weights):\n        # self.model = weights.weights\n        self.model.coef_ = weights.weights['coef_']\n        self.model.intercept_ = weights.weights['intercept_']\n\n    def test(self, data, labels):\n        try:\n            return self.model.score(data, labels)\n        except sklearn.exceptions.NotFittedError:\n            return 0\n</code></pre> <p>Let's step through this and see how it works. The propose_weights method saves the current weights of the model. Then it performs some training of the model, and gets the new weights. It returns the new weights, and resets the model weights to be the old weights.</p> <pre><code>    def mli_propose_weights(self) -&gt; Weights:\n        current_weights = self.mli_get_current_weights()\n\n        for i in range(self.steps_per_round):\n            batch_indices = next(self.train_sampler)\n            train_data = self.train_data[batch_indices]\n            train_labels = self.train_labels[batch_indices]\n            self.model.partial_fit(train_data, train_labels, classes=self.class_labels)\n\n        new_weights = self.mli_get_current_weights()\n        self.set_weights(current_weights)\n        return new_weights\n</code></pre> <p>The test_weights method takes as a parameter the proposed weights that it needs to vote on. It saves the current weights of the model, and then sets the model weights to be the proposed weights. It tests the model and votes based on whether the score that it is monitoring has improved. The vote score can be any metric that you like. You could use loss, accuracy, mean squared error or any custom metric. If the vote score is the loss then the model would only vote True if the score has decreased. Here we're using accuracy, so the vote is true if the score increases. This method then resets the weights to the old values and returns the vote along with some scores for monitoring purposes.</p> <pre><code>    def mli_test_weights(self, weights: Weights) -&gt; ProposedWeights:\n        current_weights = self.mli_get_current_weights()\n        self.set_weights(weights)\n\n        vote_score = self.test(self.train_data, self.train_labels)\n\n        test_score = self.test(self.test_data, self.test_labels)\n\n        vote = self.vote_score &lt;= vote_score\n\n        self.set_weights(current_weights)\n        return ProposedWeights(weights=weights,\n                               vote_score=vote_score,\n                               test_score=test_score,\n                               vote=vote\n                               )\n</code></pre> <p>The accept_weights method sets the weights of the model to be the new weights. It also updates the vote score to be the current performance.</p> <p>Note</p> <p>You could implement a cache here. These weights will already have been tested in test_weights, so the vote score could be retrieved from the cache instead of recomputed.</p> <pre><code>    def mli_accept_weights(self, weights: Weights):\n        self.set_weights(weights)\n        self.vote_score = self.test(self.train_data, self.train_labels)\n</code></pre> <p>The final method is the simplest - get_current_weights just returns the current weights of the model. These weights are wrapped inside a <code>Weights</code> object.</p> <pre><code>    def mli_get_current_weights(self):\n        return Weights(weights=dict(coef_=self.model.coef_,\n                                    intercept_=self.model.intercept_))\n</code></pre>"},{"location":"intro_tutorial_mli/#the-rest-of-the-example","title":"The rest of the example","text":"<p>The data is loaded and preprocessed and then split into equal parts for each learner. Then a list of FraudLearner instances is created, each with its own dataset.  </p> <pre><code>    all_learner_models = []\n    for i in range(n_learners):\n        all_learner_models.append(\n            FraudLearner(\n                train_data=learner_train_data[i],\n                train_labels=learner_train_labels[i],\n                test_data=learner_test_data[i],\n                test_labels=learner_test_labels[i]\n            ))\n</code></pre> <p>Then we give all the models the same weights to start off with:</p> <pre><code>set_equal_weights(all_learner_models)\n</code></pre> <p>And then we can move on to the final stage, which is training with Collective Learning. The function <code>collective_learning_round</code> performs one round of collective learning. One learner is selected to train and propose an update. The other learners vote on the update, and if the vote passes then the update is accepted. Then a new round begins.</p> <pre><code># Train the model using Collective Learning\nresults = Results()\nresults.data.append(initial_result(all_learner_models))\n\nfor round in range(n_rounds):\n    results.data.append(\n        collective_learning_round(all_learner_models,\n                                  vote_threshold, round)\n    )\n\n    plot_results(results, n_learners, block=False,\n                 score_name=all_learner_models[0].criterion)\n    plot_votes(results, block=False)\n\nplot_results(results, n_learners, block=False,\n             score_name=all_learner_models[0].criterion)\nplot_votes(results, block=True)\n</code></pre>"},{"location":"intro_tutorial_pytorch/","title":"Using collective learning with pytorch","text":"<p>This tutorial is a simple guide to trying out the collective learning protocol with your own machine learning code. Everything runs locally.</p> <p>The most flexible way to use the collective learning backends is to make a class that implements the Collective Learning <code>MachineLearningInterface</code> defined in ml_interface.py. For more details on how to use the <code>MachineLearningInterface</code> see here</p> <p>However, the simpler way is to use one of the helper classes that we have provided that implement most of the interface for popular ML libraries. In this tutorial we are going to walk through using the <code>PytorchLearner</code>. First we are going to define the model architecture, then we are going to load the data and configure the model, and then we will run Collective Learning.</p> <p>A standard script for machine learning with Pytorch looks like the one below</p> <pre><code># ------------------------------------------------------------------------------\n#\n#   Copyright 2021 Fetch.AI Limited\n#\n#   Licensed under the Creative Commons Attribution-NonCommercial International\n#   License, Version 4.0 (the \"License\"); you may not use this file except in\n#   compliance with the License. You may obtain a copy of the License at\n#\n#       http://creativecommons.org/licenses/by-nc/4.0/legalcode\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\n#\n# ------------------------------------------------------------------------------\nfrom torchsummary import summary\nfrom torchvision import transforms, datasets\nimport torch.utils.data\n\nimport torch.nn as nn\nimport torch.nn.functional as nn_func\n\n# define some constants\nbatch_size = 64\nseed = 42\nn_rounds = 20\ntrain_fraction = 0.9\nlearning_rate = 0.001\nheight = 28\nwidth = 28\nn_classes = 10\nnum_test_batches = 10\n\nno_cuda = False\ncuda = not no_cuda and torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if cuda else \"cpu\")\nkwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n\n# Load the data\ndata = datasets.MNIST('/tmp/mnist', transform=transforms.ToTensor(), download=True)\nn_train = int(train_fraction * len(data))\nn_test = len(data) - n_train\ntrain_data, test_data = torch.utils.data.random_split(data, [n_train, n_test])\n\ntrain_dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, **kwargs)\ntest_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True, **kwargs)\n\n\n# Define the model\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n        self.fc1 = nn.Linear(4 * 4 * 50, 500)\n        self.fc2 = nn.Linear(500, n_classes)\n\n    def forward(self, x):\n        x = nn_func.relu(self.conv1(x.view(-1, 1, height, width)))\n        x = nn_func.max_pool2d(x, 2, 2)\n        x = nn_func.relu(self.conv2(x))\n        x = nn_func.max_pool2d(x, 2, 2)\n        x = x.view(-1, 4 * 4 * 50)\n        x = nn_func.relu(self.fc1(x))\n        x = self.fc2(x)\n        return nn_func.log_softmax(x, dim=1)\n\n\nmodel = Net()\nopt = torch.optim.Adam(model.parameters(), lr=learning_rate)\ncriterion = torch.nn.NLLLoss()\n\n# Train and evaluate the model\nfor round in range(n_rounds):\n    # train model\n    model.train()\n\n    for batch_idx, (data, labels) in enumerate(train_dataloader):\n        opt.zero_grad()\n\n        # Data needs to be on same device as model\n        data = data.to(device)\n        labels = labels.to(device)\n\n        output = model(data)\n\n        loss = criterion(output, labels)\n        loss.backward()\n        opt.step()\n\n    # evaluate model\n    model.eval()\n    total_score = 0\n    all_labels = []\n    all_outputs = []\n    with torch.no_grad():\n        for batch_idx, (data, labels) in enumerate(test_dataloader):\n            if batch_idx == num_test_batches:\n                break\n            data = data.to(device)\n            labels = labels.to(device)\n            output = model(data)\n            total_score += criterion(output, labels)\n    avg_loss = float(total_score / (num_test_batches * batch_size))\n    print(f\"Average loss at round {round} is {avg_loss}\")\n</code></pre> <p>There are three steps:</p> <ol> <li>Load the data</li> <li>Define the model</li> <li>Train the model</li> </ol> <p>In this tutorial we are going to see how to modify each step to use collective learning. We'll end up with code like this:</p> <pre><code># ------------------------------------------------------------------------------\n#\n#   Copyright 2021 Fetch.AI Limited\n#\n#   Licensed under the Creative Commons Attribution-NonCommercial International\n#   License, Version 4.0 (the \"License\"); you may not use this file except in\n#   compliance with the License. You may obtain a copy of the License at\n#\n#       http://creativecommons.org/licenses/by-nc/4.0/legalcode\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\n#\n# ------------------------------------------------------------------------------\nimport os\n\nfrom typing_extensions import TypedDict\nimport torch.nn as nn\nimport torch.nn.functional as nn_func\nimport torch.utils.data\nfrom torchsummary import summary\nfrom torchvision import transforms, datasets\n\nfrom colearn.training import initial_result, collective_learning_round, set_equal_weights\nfrom colearn.utils.plot import ColearnPlot\nfrom colearn.utils.results import Results, print_results\nfrom colearn_pytorch.utils import categorical_accuracy\nfrom colearn_pytorch.pytorch_learner import PytorchLearner\n\n\"\"\"\nMNIST training example using PyTorch\n\nUsed dataset:\n- MNIST is set of 60 000 black and white hand written digits images of size 28x28x1 in 10 classes\n\nWhat script does:\n- Loads MNIST dataset from torchvision.datasets\n- Randomly splits dataset between multiple learners\n- Does multiple rounds of learning process and displays plot with results\n\"\"\"\n\n# define some constants\nn_learners = 5\nbatch_size = 64\n\ntesting_mode = bool(os.getenv(\"COLEARN_EXAMPLES_TEST\", \"\"))  # for testing\nn_rounds = 20 if not testing_mode else 1\nvote_threshold = 0.5\ntrain_fraction = 0.9\nvote_fraction = 0.05\nlearning_rate = 0.001\nheight = 28\nwidth = 28\nn_classes = 10\nvote_batches = 2\nscore_name = \"categorical accuracy\"\n\nno_cuda = False\ncuda = not no_cuda and torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if cuda else \"cpu\")\nDataloaderKwargs = TypedDict('DataloaderKwargs', {'num_workers': int, 'pin_memory': bool}, total=False)\nkwargs: DataloaderKwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n\n# Load the data and split for each learner.\nDATA_DIR = os.environ.get('PYTORCH_DATA_DIR',\n                          os.path.expanduser(os.path.join('~', 'pytorch_datasets')))\ndata = datasets.MNIST(DATA_DIR, transform=transforms.ToTensor(), download=True)\nn_train = int(train_fraction * len(data))\nn_vote = int(vote_fraction * len(data))\nn_test = len(data) - n_train - n_vote\ntrain_data, vote_data, test_data = torch.utils.data.random_split(data, [n_train, n_vote, n_test])\n\ndata_split = [len(train_data) // n_learners] * n_learners\nlearner_train_data = torch.utils.data.random_split(train_data, data_split)\nlearner_train_dataloaders = [torch.utils.data.DataLoader(\n    ds,\n    batch_size=batch_size, shuffle=True, **kwargs) for ds in learner_train_data]\n\ndata_split = [len(vote_data) // n_learners] * n_learners\nlearner_vote_data = torch.utils.data.random_split(vote_data, data_split)\nlearner_vote_dataloaders = [torch.utils.data.DataLoader(\n    ds,\n    batch_size=batch_size, shuffle=True, **kwargs) for ds in learner_vote_data]\n\ndata_split = [len(test_data) // n_learners] * n_learners\nlearner_test_data = torch.utils.data.random_split(test_data, data_split)\nlearner_test_dataloaders = [torch.utils.data.DataLoader(\n    ds,\n    batch_size=batch_size, shuffle=True, **kwargs) for ds in learner_test_data]\n\n\n# Define the model\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n        self.fc1 = nn.Linear(4 * 4 * 50, 500)\n        self.fc2 = nn.Linear(500, n_classes)\n\n    def forward(self, x):\n        x = nn_func.relu(self.conv1(x.view(-1, 1, height, width)))\n        x = nn_func.max_pool2d(x, 2, 2)\n        x = nn_func.relu(self.conv2(x))\n        x = nn_func.max_pool2d(x, 2, 2)\n        x = x.view(-1, 4 * 4 * 50)\n        x = nn_func.relu(self.fc1(x))\n        x = self.fc2(x)\n        return nn_func.log_softmax(x, dim=1)\n\n\n# Make n instances of PytorchLearner with model and torch dataloaders\nall_learner_models = []\nfor i in range(n_learners):\n    model = Net().to(device)\n    opt = torch.optim.Adam(model.parameters(), lr=learning_rate)\n    learner = PytorchLearner(\n        model=model,\n        train_loader=learner_train_dataloaders[i],\n        vote_loader=learner_vote_dataloaders[i],\n        test_loader=learner_test_dataloaders[i],\n        device=device,\n        optimizer=opt,\n        criterion=torch.nn.NLLLoss(),\n        num_test_batches=vote_batches,\n        vote_criterion=categorical_accuracy,\n        minimise_criterion=False\n    )\n\n    all_learner_models.append(learner)\n\n# Ensure all learners starts with exactly same weights\nset_equal_weights(all_learner_models)\n\nsummary(all_learner_models[0].model, input_size=(width, height), device=str(device))\n\n# Train the model using Collective Learning\nresults = Results()\nresults.data.append(initial_result(all_learner_models))\n\nplot = ColearnPlot(score_name=score_name)\n\nfor round_index in range(n_rounds):\n    results.data.append(\n        collective_learning_round(all_learner_models,\n                                  vote_threshold, round_index)\n    )\n    print_results(results)\n\n    plot.plot_results_and_votes(results)\n\nplot.block()\n\nprint(\"Colearn Example Finished!\")\n</code></pre> <p>The first thing is to modify the data loading code. Each learner needs to have their own training and testing set from the data. This is easy to do with the pytorch random_split utility:</p> <pre><code>data_split = [len(test_data) // n_learners] * n_learners\nlearner_test_data = torch.utils.data.random_split(test_data, data_split)\n</code></pre> <p>The model definition is the same as before. To use collective learning, we need to create an object that implements the MachineLearningInterface. To make it easier to use the <code>MachineLearningInterface</code> with pytorch, we've defined <code>PytorchLearner</code>. <code>PytorchLearner</code> implements standard training and evaluation routines as well as the MachineLearningInterface methods.</p> <pre><code># ------------------------------------------------------------------------------\n#\n#   Copyright 2021 Fetch.AI Limited\n#\n#   Licensed under the Creative Commons Attribution-NonCommercial International\n#   License, Version 4.0 (the \"License\"); you may not use this file except in\n#   compliance with the License. You may obtain a copy of the License at\n#\n#       http://creativecommons.org/licenses/by-nc/4.0/legalcode\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\n#\n# ------------------------------------------------------------------------------\nfrom typing import Optional, Callable\nfrom collections import OrderedDict, defaultdict\n\ntry:\n    import torch\nexcept ImportError:\n    raise Exception(\n        \"Pytorch is not installed. To use the pytorch \"\n        \"add-ons please install colearn with `pip install colearn[pytorch]`.\"\n    )\n\nimport torch.nn\nimport torch.optim\nimport torch.utils\nimport torch.utils.data\nfrom torch.nn.modules.loss import _Loss\n\nfrom colearn.ml_interface import (\n    MachineLearningInterface,\n    Weights,\n    ProposedWeights,\n    ColearnModel,\n    convert_model_to_onnx,\n    ModelFormat,\n    DiffPrivBudget,\n    DiffPrivConfig,\n    TrainingSummary,\n    ErrorCodes,\n)\n\nfrom opacus import PrivacyEngine\n\n_DEFAULT_DEVICE = torch.device(\"cpu\")\n\n\nclass PytorchLearner(MachineLearningInterface):\n\"\"\"\n    Pytorch learner implementation of machine learning interface\n    \"\"\"\n\n    def __init__(\n        self,\n        model: torch.nn.Module,\n        optimizer: torch.optim.Optimizer,\n        train_loader: torch.utils.data.DataLoader,\n        vote_loader: torch.utils.data.DataLoader,\n        test_loader: Optional[torch.utils.data.DataLoader] = None,\n        need_reset_optimizer: bool = True,\n        device=_DEFAULT_DEVICE,\n        criterion: Optional[_Loss] = None,\n        minimise_criterion=True,\n        vote_criterion: Optional[Callable[[torch.Tensor, torch.Tensor], float]] = None,\n        num_train_batches: Optional[int] = None,\n        num_test_batches: Optional[int] = None,\n        diff_priv_config: Optional[DiffPrivConfig] = None,\n    ):\n\"\"\"\n        :param model: Pytorch model used for training\n        :param optimizer: Training optimizer\n        :param train_loader: Train dataset\n        :param test_loader: Optional test dataset - subset of training set will be used if not specified\n        :param need_reset_optimizer: True to clear optimizer history before training, False to kepp history.\n        :param device: Pytorch device - CPU or GPU\n        :param criterion: Loss function\n        :param minimise_criterion: True to minimise value of criterion, False to maximise\n        :param vote_criterion: Function to measure model performance for voting\n        :param num_train_batches: Number of training batches\n        :param num_test_batches: Number of testing batches\n        :param diff_priv_config: Contains differential privacy (dp) budget related configuration\n        \"\"\"\n\n        # Model has to be on same device as data\n        self.model: torch.nn.Module = model.to(device)\n        self.optimizer: torch.optim.Optimizer = optimizer\n        self.criterion = criterion\n        self.train_loader: torch.utils.data.DataLoader = train_loader\n        self.vote_loader: torch.utils.data.DataLoader = vote_loader\n        self.test_loader: Optional[torch.utils.data.DataLoader] = test_loader\n        self.need_reset_optimizer = need_reset_optimizer\n        self.device = device\n        self.num_train_batches = num_train_batches or len(train_loader)\n        self.num_test_batches = num_test_batches\n        self.minimise_criterion = minimise_criterion\n        self.vote_criterion = vote_criterion\n\n        self.dp_config = diff_priv_config\n        self.dp_privacy_engine = PrivacyEngine()\n\n        if diff_priv_config is not None:\n            (\n                self.model,\n                self.optimizer,\n                self.train_loader,\n            ) = self.dp_privacy_engine.make_private(\n                module=self.model,\n                optimizer=self.optimizer,\n                data_loader=self.train_loader,\n                max_grad_norm=diff_priv_config.max_grad_norm,\n                noise_multiplier=diff_priv_config.noise_multiplier,\n            )\n\n        self.vote_score = self.test(self.vote_loader)\n\n    def mli_get_current_weights(self) -&gt; Weights:\n\"\"\"\n        :return: The current weights of the model\n        \"\"\"\n\n        current_state_dict = OrderedDict()\n        for key in self.model.state_dict():\n            current_state_dict[key] = self.model.state_dict()[key].clone()\n        w = Weights(\n            weights=current_state_dict, training_summary=self.get_training_summary()\n        )\n\n        return w\n\n    def mli_get_current_model(self) -&gt; ColearnModel:\n\"\"\"\n        :return: The current model and its format\n        \"\"\"\n\n        return ColearnModel(\n            model_format=ModelFormat(ModelFormat.ONNX),\n            model_file=\"\",\n            model=convert_model_to_onnx(self.model),\n        )\n\n    def set_weights(self, weights: Weights):\n\"\"\"\n        Rewrites weight of current model\n        :param weights: Weights to be stored\n        \"\"\"\n\n        self.model.load_state_dict(weights.weights)\n\n    def reset_optimizer(self):\n\"\"\"\n        Clear optimizer state, such as number of iterations, momentums.\n        This way, the outdated history can be erased.\n        \"\"\"\n\n        self.optimizer.__setstate__({\"state\": defaultdict(dict)})\n\n    def train(self):\n\"\"\"\n        Trains the model on the training dataset\n        \"\"\"\n\n        if self.need_reset_optimizer:\n            # erase the outdated optimizer memory (momentums mostly)\n            self.reset_optimizer()\n\n        self.model.train()\n\n        for batch_idx, (data, labels) in enumerate(self.train_loader):\n            if batch_idx == self.num_train_batches:\n                break\n            self.optimizer.zero_grad()\n\n            # Data needs to be on same device as model\n            data = data.to(self.device)\n            labels = labels.to(self.device)\n\n            output = self.model(data)\n\n            loss = self.criterion(output, labels)\n            loss.backward()\n            self.optimizer.step()\n\n    def mli_propose_weights(self) -&gt; Weights:\n\"\"\"\n        Trains model on training set and returns new weights after training\n        - Current model is reverted to original state after training\n        :return: Weights after training\n        \"\"\"\n\n        current_weights = self.mli_get_current_weights()\n        training_summary = current_weights.training_summary\n        if (\n            training_summary is not None\n            and training_summary.error_code is not None\n            and training_summary.error_code == ErrorCodes.DP_BUDGET_EXCEEDED\n        ):\n            return current_weights\n\n        self.train()\n        new_weights = self.mli_get_current_weights()\n        self.set_weights(current_weights)\n\n        training_summary = new_weights.training_summary\n        if (\n            training_summary is not None\n            and training_summary.error_code is not None\n            and training_summary.error_code == ErrorCodes.DP_BUDGET_EXCEEDED\n        ):\n            current_weights.training_summary = training_summary\n            return current_weights\n\n        return new_weights\n\n    def mli_test_weights(self, weights: Weights) -&gt; ProposedWeights:\n\"\"\"\n        Tests given weights on training and test set and returns weights with score values\n        :param weights: Weights to be tested\n        :return: ProposedWeights - Weights with vote and test score\n        \"\"\"\n\n        current_weights = self.mli_get_current_weights()\n        self.set_weights(weights)\n\n        vote_score = self.test(self.vote_loader)\n\n        if self.test_loader:\n            test_score = self.test(self.test_loader)\n        else:\n            test_score = 0\n        vote = self.vote(vote_score)\n\n        self.set_weights(current_weights)\n        return ProposedWeights(\n            weights=weights, vote_score=vote_score, test_score=test_score, vote=vote\n        )\n\n    def vote(self, new_score) -&gt; bool:\n\"\"\"\n        Compares current model score with proposed model score and returns vote\n        :param new_score: Proposed score\n        :return: bool positive or negative vote\n        \"\"\"\n\n        if self.minimise_criterion:\n            return new_score &lt; self.vote_score\n        else:\n            return new_score &gt; self.vote_score\n\n    def test(self, loader: torch.utils.data.DataLoader) -&gt; float:\n\"\"\"\n        Tests performance of the model on specified dataset\n        :param loader: Dataset for testing\n        :return: Value of performance metric\n        \"\"\"\n\n        if not self.criterion:\n            raise Exception(\"Criterion is unspecified so test method cannot be used\")\n\n        self.model.eval()\n        total_score = 0\n        all_labels = []\n        all_outputs = []\n        batch_idx = 0\n        total_samples = 0\n        with torch.no_grad():\n            for batch_idx, (data, labels) in enumerate(loader):\n                total_samples += labels.shape[0]\n                if self.num_test_batches and batch_idx == self.num_test_batches:\n                    break\n                data = data.to(self.device)\n                labels = labels.to(self.device)\n                output = self.model(data)\n                if self.vote_criterion is not None:\n                    all_labels.append(labels)\n                    all_outputs.append(output)\n                else:\n                    total_score += self.criterion(output, labels).item()\n        if batch_idx == 0:\n            raise Exception(\"No batches in loader\")\n        if self.vote_criterion is None:\n            return float(total_score / total_samples)\n        else:\n            return self.vote_criterion(\n                torch.cat(all_outputs, dim=0), torch.cat(all_labels, dim=0)\n            )\n\n    def mli_accept_weights(self, weights: Weights):\n\"\"\"\n        Updates the model with the proposed set of weights\n        :param weights: The new weights\n        \"\"\"\n\n        self.set_weights(weights)\n        self.vote_score = self.test(self.vote_loader)\n\n    def get_training_summary(self) -&gt; Optional[TrainingSummary]:\n\"\"\"\n        Differential Privacy Budget\n        :return: the target and consumed epsilon so far\n        \"\"\"\n\n        if self.dp_config is None:\n            return None\n\n        delta = self.dp_config.target_delta\n        target_epsilon = self.dp_config.target_epsilon\n        consumed_epsilon = self.dp_privacy_engine.get_epsilon(delta)\n\n        budget = DiffPrivBudget(\n            target_epsilon=target_epsilon,\n            consumed_epsilon=consumed_epsilon,\n            target_delta=delta,\n            consumed_delta=delta,  # delta is constatnt per training\n        )\n\n        err = (\n            ErrorCodes.DP_BUDGET_EXCEEDED\n            if consumed_epsilon &gt;= target_epsilon\n            else None\n        )\n\n        return TrainingSummary(\n            dp_budget=budget,\n            error_code=err,\n        )\n</code></pre> <p>We create a set of PytorchLearners by passing in the model and the datasets:</p> <pre><code>all_learner_models = []\nfor i in range(n_learners):\n    model = Net()\n    opt = torch.optim.Adam(model.parameters(), lr=learning_rate)\n    learner = PytorchLearner(\n        model=model,\n        train_loader=learner_train_dataloaders[i],\n        vote_loader=learner_vote_dataloaders[i],\n        test_loader=learner_test_dataloaders[i],\n        device=device,\n        optimizer=opt,\n        criterion=torch.nn.NLLLoss(),\n        num_test_batches=vote_batches,\n        vote_criterion=categorical_accuracy,\n        minimise_criterion=False\n    )\n\n    all_learner_models.append(learner)\n</code></pre> <p>Then we give all the models the same weights to start off with:</p> <pre><code>set_equal_weights(all_learner_models)\n</code></pre> <p>And then we can move on to the final stage, which is training with Collective Learning. The function <code>collective_learning_round</code> performs one round of collective learning. One learner is selected to train and propose an update. The other learners vote on the update, and if the vote passes then the update is accepted. Then a new round begins.</p> <pre><code># Train the model using Collective Learning\nresults = Results()\nresults.data.append(initial_result(all_learner_models))\n\nfor round in range(n_rounds):\n    results.data.append(\n        collective_learning_round(all_learner_models,\n                                  vote_threshold, round)\n    )\n\n    plot_results(results, n_learners, score_name=score_name)\n    plot_votes(results)\n\n# Plot the final result with votes\nplot_results(results, n_learners, score_name=score_name)\nplot_votes(results, block=True)\n</code></pre>"},{"location":"mli_factory/","title":"MLI Factory","text":"<p>The machine learning interface factory are the minimum methods a client needs to implement to work with the GRPC Server (and become a Learner).</p> <p>There are two main types of functions:</p> <ul> <li>Supported Systems (get_models, get_dataloaders, get_compatibilities)</li> <li>Get a MachineLearningInterface (get_mli)</li> </ul> <p>When the GRPC server is connected to the Orchestrator, it will query the supported system functions to know what the MLI Factory can serve.</p> <p>Later when the Orchestrator wants to run something on this Learner it will call get_mli with a model_arch_name, a dataloader_name and more parameters for both. The object returned is then used to run the experiment through the MLI.</p>"},{"location":"mli_factory/#supported-systems","title":"Supported Systems","text":"<p>The supported systems functions get_models and get_dataloaders should return a set of  which will be stored (not currently implemented) in the api database. The idea being that the user can change these values on the UI while preparing to start/join an experiment."},{"location":"mli_factory/#examplemlifactory","title":"ExampleMliFactory","text":"<p>An example MLIFactory that will implement all the tasks in run_demo. This is the one used by contract_learn.</p>"},{"location":"tasks/","title":"1. CIFAR10 dataset","text":""},{"location":"tasks/#11-information-and-installation","title":"1.1. Information and installation","text":""},{"location":"tasks/#111-information-about-the-dataset","title":"1.1.1. Information about the dataset","text":"<ul> <li>The CIFAR-10 dataset consists of 60000 32x32x3 colour images in 10 classes, with 6000 images per class.</li> <li>The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks</li> <li>Input for NN are raw 32x32 3 channels GRB images</li> <li> <p>NN output is distribution of probabilities for each class i.e. 10 values that sums up to 1</p> </li> <li> <p>Code folder: here</p> </li> <li>Invoke parameter: -t CIFAR10</li> </ul>"},{"location":"tasks/#112-requirements","title":"1.1.2. Requirements","text":"<ul> <li>Cifar dataset is loaded from tensorflow.keras.datasets.cifar10 and no stored data are required</li> </ul>"},{"location":"tasks/#12-models","title":"1.2. Models","text":""},{"location":"tasks/#121-cifar10conv-keras-model","title":"1.2.1. CIFAR10Conv Keras model","text":"<pre><code>_________________________________________________________________\nLayer (type)                    Output Shape        Param #   \n=================================================================\nInput (InputLayer)              (32, 32, 3)         0             \n_________________________________________________________________\nConv1_1 (Conv2D)                (32, 32, 64)        1792          \nbn1_1 (BatchNormalization)      (32, 32, 64)        256           \nConv1_2 (Conv2D)                (32, 32, 64)        36928         \nbn1_2 (BatchNormalization)      (32, 32, 64)        256           \npool1 (MaxPooling2D)            (16, 16, 64)        0             \n_________________________________________________________________\nConv2_1 (Conv2D)                (16, 16, 128        73856         \nbn2_1 (BatchNormalization)      (16, 16, 128        512           \nConv2_2 (Conv2D)                (16, 16, 128        147584    \nbn2_2 (BatchNormalization)      (16, 16, 128        512           \npool2 (MaxPooling2D)            (8, 8, 128)         0             \n_________________________________________________________________\nConv3_1 (Conv2D)                (8, 8, 256)         295168    \nbn3_1 (BatchNormalization)      (8, 8, 256)         1024          \nConv3_2 (Conv2D)                (8, 8, 256)         590080    \nbn3_2 (BatchNormalization)      (8, 8, 256)         1024          \nConv3_3 (Conv2D)                (8, 8, 256)         590080    \nbn3_3 (BatchNormalization)      (8, 8, 256)         1024          \n_________________________________________________________________\nflatten (Flatten)               (16384)             0             \nfc1 (Dense)                     (100)               1638500   \nfc2 (Dense)                     (10)                1010          \n=================================================================\nTotal params: 3,379,606\nTrainable params: 3,377,302\nNon-trainable params: 2,304\n_________________________________________________________________\n</code></pre>"},{"location":"tasks/#122-cifar10conv2-keras-model","title":"1.2.2. CIFAR10Conv2 Keras model","text":"<pre><code>_________________________________________________________\nLayer (type)                Output Shape        Param #   \n=========================================================\nInput (InputLayer)          (32, 32, 3)         0             \n_________________________________________________________\nConv1_1 (Conv2D)            (32, 32, 32)        896           \nConv1_2 (Conv2D)            (32, 32, 32)        9248          \npool1 (MaxPooling2D)        (16, 16, 32)        0             \n_________________________________________________________\nConv2_1 (Conv2D)            (16, 16, 64)        18496         \nConv2_2 (Conv2D)            (16, 16, 64)        36928         \npool2 (MaxPooling2D)        (8, 8, 64)          0             \n_________________________________________________________\nConv3_1 (Conv2D)            (8, 8, 128)         73856         \nConv3_2 (Conv2D)            (8, 8, 128)         147584    \npool3 (MaxPooling2D)        (4, 4, 128)         0             \n_________________________________________________________\nflatten (Flatten)           (2048)              0             \nfc1 (Dense)                 (128)               262272    \nfc2 (Dense)                 (10)                1290          \n=========================================================\nTotal params: 550,570\nTrainable params: 550,570\nNon-trainable params: 0\n_________________________________________________________\n</code></pre>"},{"location":"tasks/#123-cifar10resnet50-keras-model","title":"1.2.3. CIFAR10Resnet50 Keras model","text":"<pre><code>________________________________________________________\nLayer (type)                 Output Shape     Param #   \n========================================================\nInput (InputLayer)           (32, 32, 3)]     0             \n________________________________________________________\nresnet50 (Model)             (1, 1, 2048)     23587712  \n________________________________________________________\nGlobal_average_pooling2d     (2048)           0             \nflatten (Flatten)            (2048)           0             \nfc1 (Dense)                  (10)             20490         \n========================================================\nTotal params: 23,608,202\nTrainable params: 23,555,082\nNon-trainable params: 53,120\n________________________________________________________\n</code></pre>"},{"location":"tasks/#2-covid-x-ray-dataset","title":"2. Covid X-RAY dataset","text":""},{"location":"tasks/#21-information-and-installation","title":"2.1. Information and installation","text":""},{"location":"tasks/#211-information-about-the-dataset","title":"2.1.1. Information about the dataset","text":"<ul> <li>The Covid X-Ray dataset consists of grayscale images, there are 478 covid images and 203 normal images.</li> <li>To increase the number of images normal/pneumonia dataset is added</li> <li>Final dataset, which is a combination of two previously mentioned datasets, contains 1434 images, 478 images for each class.</li> <li>Images are cropped and resized to 512x512 pixel and spatial domain (Texture, GLDM, GLCM) and frequency domain (FFT and Wavelet) features are used to create 256 dimensional vector representation of each image. PCA is applied after to reduce dimensionality to 64 values which represents the first 64 highest eigenvalues of the covariance matrix.</li> <li>Input for NN are 64 values for each image</li> <li>NN output is distribution of probabilities for each class i.e. 3 values</li> <li>Code folder: here</li> <li>Invoke parameter: -t COVID</li> </ul>"},{"location":"tasks/#212-requirements","title":"2.1.2 Requirements","text":"<ul> <li>Download Covid dataset: here</li> <li>Download pneumonia dataset: here</li> </ul>"},{"location":"tasks/#22-models","title":"2.2. Models","text":""},{"location":"tasks/#221-covid-xray-keras-model","title":"2.2.1. Covid XRAY Keras model","text":"<pre><code>_________________________________________________________\nLayer (type)              Output Shape        Param #   \n=========================================================\ninput_1 (InputLayer)      (64)                0             \n_________________________________________________________\ndense (Dense)             (128)               8320          \ndropout (Dropout)         (128)               0             \n_________________________________________________________\ndense_1 (Dense)           (16)                2064          \ndropout_1 (Dropout)       (16)                0             \n_________________________________________________________\ndense_2 (Dense)           (3)                 51            \n=========================================================\nTotal params: 10,435\nTrainable params: 10,435\nNon-trainable params: 0\n_________________________________________________________\n</code></pre>"},{"location":"tasks/#3-fraud-dataset","title":"3. FRAUD dataset","text":""},{"location":"tasks/#31-information-and-installation","title":"3.1. Information and installation","text":""},{"location":"tasks/#311-information-about-the-dataset","title":"3.1.1. Information about the dataset","text":"<ul> <li>EEE-CIS Fraud Detection, contains multiple files with credit card transactions</li> <li>Raw dataset files are automatically merged and pre-processed and input files for neural network are created</li> <li>X.csv with data - has 431 values for each transaction</li> <li> <p>Y.csv with labels - v has 1 value for each transaction</p> <ul> <li>0 = not a fraud</li> <li>1 = fraud</li> </ul> </li> <li> <p>Code folder: here</p> </li> <li>Invoke parameter: -t FRAUD</li> </ul>"},{"location":"tasks/#312-requirements","title":"3.1.2. Requirements","text":"<ul> <li>Download dataset: here</li> </ul>"},{"location":"tasks/#32-models","title":"3.2. Models","text":""},{"location":"tasks/#321-frauddense1-keras-model","title":"3.2.1. FraudDense1 Keras model","text":"<pre><code>_________________________________________________________\nLayer (type)             Output Shape          Param #   \n=========================================================\nInput (InputLayer)       (431)                 0             \n_________________________________________________________\ndense (Dense)            (512)                 221184    \nBatch_normalization      (512)                 2048          \n_________________________________________________________\ndense_1 (Dense)          (512)                 262656    \nBatch_normalization_1    (512)                 2048          \n_________________________________________________________\ndense_2 (Dense)          (512)                 262656    \nBatch_normalization_2    (512)                 2048          \n_________________________________________________________\nfc1 (Dense)              (1)                   513           \n=========================================================\nTotal params: 753,153\nTrainable params: 750,081\nNon-trainable params: 3,072\n_________________________________________________________\n</code></pre>"},{"location":"tasks/#322-fraudsvm-scikit-learn-model","title":"3.2.2. FraudSVM Scikit-learn model","text":"<ul> <li>Model is defined as SGDClassifier(max_iter=1, verbose=0, loss=\"modified_huber\")</li> <li>Which is support vector machine linear classifier</li> </ul>"},{"location":"tasks/#4-mnist","title":"4. MNIST","text":""},{"location":"tasks/#41-information-and-installation","title":"4.1. Information and installation","text":""},{"location":"tasks/#411-information-about-the-dataset","title":"4.1.1. Information about the dataset","text":"<ul> <li>This is a dataset of 70,000 28x28x1 grayscale images of the 10 digits</li> <li>Input for NN are raw 28x28 1 channel images</li> <li> <p>NN output is distribution of probabilities for each class i.e. 10 values that sums up to 1</p> </li> <li> <p>Code folder: here</p> </li> <li>Invoke parameter: -t MNIST</li> </ul>"},{"location":"tasks/#412-requirements","title":"4.1.2 Requirements","text":"<ul> <li>MNIST dataset is loaded from tensorflow.keras.datasets.cifar10 and no stored data are required</li> </ul>"},{"location":"tasks/#42-models","title":"4.2. Models","text":""},{"location":"tasks/#421-mnistconv-keras-model","title":"4.2.1. MNISTConv Keras model","text":"<pre><code>_________________________________________________________\nLayer (type)                   Output Shape       Param #   \n=========================================================\nInput (InputLayer)             (28, 28, 1)        0             \n_________________________________________________________\nConv1_1 (Conv2D)               (28, 28, 64)       640           \nbn1 (BatchNormalization)       (28, 28, 64)       256           \npool1 (MaxPooling2D)           (14, 14, 64)       0             \n_________________________________________________________\nConv2_1 (Conv2D)               (14, 14, 128)      73856         \nbn4 (BatchNormalization)       (14, 14, 128)      512           \npool2 (MaxPooling2D)           (7, 7, 128)        0             \n_________________________________________________________\nflatten (Flatten)              (6272)             0             \nfc1 (Dense)                    (10)               62730         \n=========================================================\nTotal params: 137,994\nTrainable params: 137,610\nNon-trainable params: 384\n_________________________________________________________\n</code></pre>"},{"location":"tasks/#422-mnist-pytorch-model","title":"4.2.2. MNIST Pytorch model","text":"<pre><code>---------------------------------------------------------\nLayer (type)           Output Shape             Param #\n=========================================================\nInput                  [28,28,1]                0\nConv2d-1               [20, 24, 24]             520\nConv2d-2               [50, 8, 8]               25,050\nLinear-3               [500]                    400,500\nLinear-4               [10]                     5,010\n=========================================================\nTotal params: 431,080\nTrainable params: 431,080\nNon-trainable params: 0\n---------------------------------------------------------\n</code></pre>"},{"location":"tasks/#423-mnistsupermini-keras-model","title":"4.2.3. MNISTSupermini Keras model","text":"<pre><code>________________________________________________________________________________________\nLayer (type)                Output Shape    Param #      Connected to                         \n========================================================================================\ninput_1 (InputLayer)        (28, 28, 1)     0                                                \n________________________________________________________________________________________\nconv2d (Conv2D)             (26, 26, 8)     80           input_1[0][0]                        \nBatch_normalization         (26, 26, 8)     32           conv2d[0][0]                         \nMax_pooling2d               (13, 13, 8)     0            batch_normalization[0][0]            \ndropout (Dropout)           (13, 13, 8)     0            max_pooling2d[0][0]                  \n________________________________________________________________________________________\nSeparable_conv2d            (11, 11, 26)    306          dropout[0][0]                        \nbatch_normalization_1       (11, 11, 26)    104          separable_conv2d[0][0]               \ndropout_1 (Dropout)         (11, 11, 26)    0            batch_normalization_1[0][0]          \n________________________________________________________________________________________\nSeparable_conv2d_1          (11, 11, 26)    936          dropout_1[0][0]                      \n                                                         dropout_2[0][0]                      \n                                                         dropout_3[0][0]                      \n________________________________________________________________________________________\nBatch_normalization_2        (11, 11, 26)   104          separable_conv2d_1[0][0]             \ndropout_2 (Dropout)          (11, 11, 26)   0            batch_normalization_2[0][0]          \n________________________________________________________________________________________\nBatch_normalization_3        (11, 11, 26)   104          separable_conv2d_1[1][0]             \ndropout_3 (Dropout)          (11, 11, 26)   0            batch_normalization_3[0][0]          \n________________________________________________________________________________________\nBatch_normalization_4        (11, 11, 26)   104          separable_conv2d_1[2][0]             \ndropout_4 (Dropout)          (11, 11, 26)   0            batch_normalization_4[0][0]          \n________________________________________________________________________________________\nGlobal_average_pooling2d     (26)           0            dropout_4[0][0]                      \ndense (Dense)                (16)           432          global_average_pooling2d[0][0]   \nBatch_normalization_5        (16)           64           dense[0][0]                          \ndropout_5 (Dropout)          (16)           0            batch_normalization_5[0][0]          \ndense_1 (Dense)              (10)           170          dropout_5[0][0]                      \n========================================================================================\nTotal params: 2,436\nTrainable params: 2,180\nNon-trainable params: 256\n________________________________________________________________________________________\n</code></pre>"},{"location":"tasks/#5-pneumonia-xray","title":"5. Pneumonia XRAY","text":""},{"location":"tasks/#51-information-and-installation","title":"5.1. Information and installation","text":""},{"location":"tasks/#511-information-about-the-dataset","title":"5.1.1. Information about the dataset","text":"<ul> <li>The Chest X-Ray Images (Pneumonia) dataset consists of 5856 grayscale images of various sizes in 2 classes (normal/pneumonia).</li> <li>Labels are determined by folder name - NORMAL or PNEUMONIA</li> <li>Input for NN are raw resized 128x128 1 channel images</li> <li> <p>NN output is distribution of probabilities for each class i.e. 2 values</p> </li> <li> <p>Code folder: here</p> </li> <li>Invoke parameter: -t XRAY</li> </ul>"},{"location":"tasks/#512-requirements","title":"5.1.2 Requirements","text":"<ul> <li>Download dataset: here</li> </ul>"},{"location":"tasks/#52-models","title":"5.2. Models","text":""},{"location":"tasks/#521-xraysupermini-keras-model","title":"5.2.1. XraySupermini Keras model","text":"<pre><code>_________________________________________________________________\nLayer (type)                     Output Shape            Param #   \n=================================================================\nInput (InputLayer)               [(128, 128, 1)]         0             \n_________________________________________________________________\nConv1_1 (Conv2D)                 (128, 128, 32)          320           \n_________________________________________________________________\nbn1 (BatchNormalization)         (128, 128, 32)          128           \n_________________________________________________________________\npool1 (MaxPooling2D)             (32, 32, 32)            0             \n_________________________________________________________________\nConv2_1 (Conv2D)                 (32, 32, 64)            18496         \n_________________________________________________________________\nbn2 (BatchNormalization)         (32, 32, 64)            256           \n_________________________________________________________________\nGlobal_max_pooling2d             (64)                    0             \n_________________________________________________________________\nfc1 (Dense)                      (1)                     65            \n=================================================================\nTotal params: 19,265\nTrainable params: 19,073\nNon-trainable params: 192\n_________________________________________________________________\n</code></pre>"},{"location":"tasks/#522-xrayresnet50-keras-model","title":"5.2.2. XrayResnet50 Keras model","text":"<pre><code>_________________________________________________________________\nLayer (type)                     Output Shape            Param #   \n=================================================================\nInput (InputLayer)               [(128, 128, 1)]         0             \n_________________________________________________________________\nresnet50 (Model)                 (4, 4, 2048)            23581440  \n_________________________________________________________________\nglobal_average_pooling2d         (2048)                  0             \n_________________________________________________________________\nflatten (Flatten)                (2048)                  0             \n_________________________________________________________________\nfc1 (Dense)                      (1)                     2049          \n=================================================================\nTotal params: 23,583,489\nTrainable params: 23,530,369\nNon-trainable params: 53,120\n_________________________________________________________________\n</code></pre>"},{"location":"tasks/#523-xraypretrainedresnet50-keras-model","title":"5.2.3. XrayPretrainedResnet50 Keras model","text":"<pre><code>_____________________________________________________________________________________\nLayer (type)                Output Shape    Param #   Connected to                \n=====================================================================================\nInput (InputLayer)          (128, 128, 1)   0                                       \n_____________________________________________________________________________________\nconcatenate (Concatenate)   (128, 128, 3)   0         Input[0][0]                                                                                     Input[0][0]                                                                                    Input[0][0]                 \n_____________________________________________________________________________________\ntf_op_layer_mul             (128, 128, 3)  0          concatenate[0][0]           \ntf_op_layer_strided_slice   (128, 128, 3)  0          tf_op_layer_mul[0][0]       \ntf_op_layer_BiasAdd         (128, 128, 3)  0          tf_op_layer_strided_slice[0][0]  \n_____________________________________________________________________________________\nresnet50 (Model)            (4, 4, 2048)   23587712   tf_op_layer_BiasAdd[0][0]            \n_____________________________________________________________________________________\nglobal_average_pooling2d    (2048)         0          resnet50[1][0]              \nflatten (Flatten)           (2048)         0          global_average_pooling2d[0][0]   \n_____________________________________________________________________________________\nfc1 (Dense)                 (1)            2049       flatten[0][0]              \n=====================================================================================\nTotal params: 23,589,761\nTrainable params: 23,536,641\nNon-trainable params: 53,120\n_____________________________________________________________________________________\n</code></pre>"},{"location":"tasks/#524-xraydropout-keras-model","title":"5.2.4. XrayDropout Keras model","text":"<pre><code>_________________________________________________________________\nLayer (type)                     Output Shape            Param #   \n=================================================================\nInput (InputLayer)               [(128, 128, 1)]         0             \n_________________________________________________________________\nConv1_1 (Conv2D)                 (128, 128, 128)         1280          \nbn1 (BatchNormalization)         (128, 128, 128)         512           \npool1 (MaxPooling2D)             (32, 32, 128)           0             \n_________________________________________________________________\nConv2_1 (Conv2D)                 (32, 32, 256)           295168    \nbn2 (BatchNormalization)         (32, 32, 256)           1024          \npool2 (MaxPooling2D)             (8, 8, 256)             0             \n_________________________________________________________________\nflatten (Flatten)                (16384)                 0             \nfc1 (Dense)                      (128)                   2097280   \nbn3 (BatchNormalization)         (128)                   512           \ndropout (Dropout)                (128)                   0             \n_________________________________________________________________\nfc2 (Dense)                      (64)                    8256          \nbn4 (BatchNormalization)         (64)                    256           \ndropout_1 (Dropout)              (64)                    0             \n_________________________________________________________________\nfc3 (Dense)                      (1)                     65            \n=================================================================\nTotal params: 2,404,353\nTrainable params: 2,403,201\nNon-trainable params: 1,152\n_________________________________________________________________\n</code></pre>"},{"location":"tasks/#525-xraydropout2-keras-model","title":"5.2.5. XrayDropout2 Keras model","text":"<pre><code>_________________________________________________________________\nLayer (type)                     Output Shape            Param #   \n=================================================================\nInput (InputLayer)               (128, 128, 1)           0             \n_________________________________________________________________\nConv1_1 (Conv2D)                 (128, 128, 64)          640           \nbn1 (BatchNormalization)         (128, 128, 64)          256           \npool1 (MaxPooling2D)             (64, 64, 64)            0             \n_________________________________________________________________\nConv2_1 (Conv2D)                 (64, 64, 128)           73856         \nbn2 (BatchNormalization)         (64, 64, 128)           512           \npool2 (MaxPooling2D)             (32, 32, 128)           0             \n_________________________________________________________________\nConv3_1 (Conv2D)                 (32, 32, 256)           295168    \nbn3 (BatchNormalization)         (32, 32, 256)           1024          \npool3 (MaxPooling2D)             (16, 16, 256)           0             \n_________________________________________________________________\nConv4_1 (Conv2D)                 (16, 16, 512)           1180160   \nbn4 (BatchNormalization)         (16, 16, 512)           2048          \npool4 (MaxPooling2D)             (8, 8, 512)             0             \n_________________________________________________________________\nConv5_1 (Conv2D)                 (8, 8, 512)             2359808   \nbn5 (BatchNormalization)         (8, 8, 512)             2048          \npool5 (MaxPooling2D)             (4, 4, 512)             0             \n_________________________________________________________________\nflatten (Flatten)                (8192)                  0             \nfc1 (Dense)                      (256)                   2097408   \nbn6 (BatchNormalization)         (256)                   1024          \ndropout (Dropout)                (256)                   0             \n_________________________________________________________________\nfc2 (Dense)                      (128)                   32896         \nbn7 (BatchNormalization)         (128)                   512           \ndropout_1 (Dropout)              (128)                   0             \n_________________________________________________________________\nfc3 (Dense)                      (64)                    8256          \nbn8 (BatchNormalization)         (64)                    256           \ndropout_2 (Dropout)              (64)                    0             \n_________________________________________________________________\nfc4 (Dense)                      (1)                     65            \n=================================================================\nTotal params: 6,055,937\nTrainable params: 6,052,097\nNon-trainable params: 3,840\n_________________________________________________________________\n</code></pre>"},{"location":"tasks/#526-xrayvgg16-keras-model","title":"5.2.6. XrayVGG16 Keras model","text":"<pre><code>_____________________________________________________________________________________\nLayer (type)                 Output Shape     Param #    Connected to                \n=====================================================================================\nInput (InputLayer)           (128, 128, 1)    0                  \n_____________________________________________________________________________________\nconcatenate (Concatenate)    (128, 128, 3)    0          Input[0][0]                 \n                                                         Input[0][0]                 \n                                                         Input[0][0]                 \n_____________________________________________________________________________________\ntf_op_layer_mul               (128, 128, 3)    0         concatenate[0][0]           \nTf_op_layer_strided_slice     (28, 128, 3)     0         tf_op_layer_mul[0][0]       \ntf_op_layer_BiasAdd           (128, 128, 3)    0         tf_op_layer_strided_slice[0][0]  \n_____________________________________________________________________________________\nvgg16 (Model)                 (4, 4, 512)      14714688  tf_op_layer_BiasAdd[0][0]            \n_____________________________________________________________________________________\nflatten (Flatten)             (8192)           0         vgg16[1][0]                  \nfc1 (Dense)                   (1)              8193      flatten[0][0]                \n=====================================================================================\nTotal params: 14,722,881\nTrainable params: 14,722,881\nNon-trainable params: 0\n_____________________________________________________________________________________\n</code></pre>"},{"location":"tasks/#527-xraymini-keras-model","title":"5.2.7. XrayMini Keras model","text":"<pre><code>_________________________________________________________________\nLayer (type)                     Output Shape            Param #   \n=================================================================\nInput (InputLayer)               [(128, 128, 1)]         0             \n_________________________________________________________________\nConv1_1 (Conv2D)                 (128, 128, 128)         1280          \nbn1 (BatchNormalization)         (128, 128, 128)         512           \npool1 (MaxPooling2D)             (32, 32, 128)           0             \n_________________________________________________________________\nConv2_1 (Conv2D)                 (32, 32, 256)           295168    \nbn2 (BatchNormalization)         (32, 32, 256)           1024          \npool2 (MaxPooling2D)             (8, 8, 256)             0             \n_________________________________________________________________\nflatten (Flatten)                (16384)                 0             \nfc1 (Dense)                      (1)                     16385         \n=================================================================\nTotal params: 314,369\nTrainable params: 313,601\nNon-trainable params: 768\n_________________________________________________________________\n</code></pre>"},{"location":"tasks/#527-xrayonemb-keras-model","title":"5.2.7. XrayOneMB Keras model","text":"<pre><code>_________________________________________________________________\nLayer (type)                   Output Shape            Param #   \n=================================================================\nInput (InputLayer)             (128, 128, 1)           0             \n_________________________________________________________________\nConv1_1 (Conv2D)               (128, 128, 64)          640           \nbn1_1 (BatchNormalization)     (128, 128, 64)          256           \nConv1_2 (Conv2D)               (128, 128, 64)          36928         \nbn1_2 (BatchNormalization)     (128, 128, 64)          256           \npool1 (MaxPooling2D)           (64, 64, 64)            0             \n_________________________________________________________________\nConv2_1 (Conv2D)               (64, 64, 64)            36928         \nbn2_1 (BatchNormalization)     (64, 64, 64)            256           \nConv2_2 (Conv2D)               (64, 64, 64)            36928         \nbn2_2 (BatchNormalization)     (64, 64, 64)            256           \npool2 (MaxPooling2D)           (32, 32, 64)            0             \n_________________________________________________________________\nConv3_1 (Conv2D)               (32, 32, 128)           73856         \nbn3_1 (BatchNormalization)     (32, 32, 128)           512           \nConv3_2 (SeparableConv2D)      (32, 32, 128)           17664         \nbn3_2 (BatchNormalization)     (32, 32, 128)           512           \npool3 (MaxPooling2D)           (16, 16, 128)           0             \n_________________________________________________________________\nConv4_1 (SeparableConv2D)      (16, 16, 128)           17664         \nbn4_1 (BatchNormalization)     (16, 16, 128)           512           \n_________________________________________________________________\nConv4_2 (SeparableConv2D)      (16, 16, 128)           17664         \nbn4_2 (BatchNormalization)     (16, 16, 128)           512           \n_________________________________________________________________\npool4 (AveragePooling2D)       (4, 4, 128)             0             \nflatten (Flatten)              (2048)                  0             \n_________________________________________________________________\nfc1 (Dense)                    (1)                     2049          \n=================================================================\nTotal params: 243,393\nTrainable params: 241,857\nNon-trainable params: 1,536\n_________________________________________________________________\n</code></pre>"}]}